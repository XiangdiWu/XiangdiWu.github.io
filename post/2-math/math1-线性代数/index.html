<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="Xiangdi Blog"><meta property="og:type" content="article"><meta property="og:image" con ’tent=https://images.pexels.com/photos/4778611/pexels-photo-4778611.jpeg><meta property="twitter:image" content="https://images.pexels.com/photos/4778611/pexels-photo-4778611.jpeg"><meta name=title content="量化数学基础：线性代数"><meta property="og:title" content="量化数学基础：线性代数"><meta property="twitter:title" content="量化数学基础：线性代数"><meta name=description content="本文主要介绍线性代数基础知识，包括向量和向量空间、矩阵、线性映射、矩阵操作、矩阵的逆、矩阵的特征值、矩阵的分解、矩阵的运算、矩阵的应用、矩阵的应用。"><meta property="og:description" content="本文主要介绍线性代数基础知识，包括向量和向量空间、矩阵、线性映射、矩阵操作、矩阵的逆、矩阵的特征值、矩阵的分解、矩阵的运算、矩阵的应用、矩阵的应用。"><meta property="twitter:description" content="本文主要介绍线性代数基础知识，包括向量和向量空间、矩阵、线性映射、矩阵操作、矩阵的逆、矩阵的特征值、矩阵的分解、矩阵的运算、矩阵的应用、矩阵的应用。"><meta property="twitter:card" content="summary"><meta property="og:url" content="https://xiangdiwu.github.io/post/2-math/math1-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"><meta name=keyword content="吴湘菂, WuXiangdi, XiangdiWu, 吴湘菂的网络日志, 吴湘菂的博客, Xiangdi Blog, 博客, 个人网站, Quant, 量化投资, 金融, 投资, 理财, 股票, 期货, 基金, 期权, 外汇, 比特币"><link rel="shortcut icon" href=/img/favicon.ico><title>量化数学基础：线性代数-吴湘菂的博客 | Xiangdi Blog</title><link rel=canonical href=/post/2-math/math1-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=/css/zanshang.min.css><link rel=stylesheet href=/css/font-awesome.all.min.css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script><script src=/js/lazysizes.min.js></script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-R757MDJ6Y6"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-R757MDJ6Y6")}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"\\[",right:"\\]",display:!0},{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1})})</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type=text/javascript></script><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class=navbar-brand href=/>Xiangdi Blog</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>All Posts</a></li><li><a href=/categories/quant/>quant</a></li><li><a href=/categories/reading/>reading</a></li><li><a href=/categories/tech/>tech</a></li><li><a href=/archive//>ARCHIVE</a></li><li><a href=/vibe//>Vibe</a></li><li><a href=/travel//>TRAVEL</a></li><li><a href=/about//>ABOUT</a></li><li><a href=/search><i class="fa fa-search"></i></a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");$toggle.addEventListener("click",handleMagic);function handleMagic(){$navbar.className.indexOf("in")>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script><style type=text/css>header.intro-header{background-image:url(https://images.pexels.com/photos/4778611/pexels-photo-4778611.jpeg)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/quant title=Quant>Quant
</a><a class=tag href=/tags/math title=Math>Math</a></div><h1>量化数学基础：线性代数</h1><h2 class=subheading>Foundations of Quantitative Mathematics: Linear Algebra</h2><span class=meta>Posted by
XiangdiWu
on
Wednesday, September 23, 2020</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><h1 id=向量和向量空间>向量和向量空间</h1><h2 id=向量>向量</h2><p><b>标量(scalar)</b>是一个实数，一般用斜体小写字母$a,b,c$来表示。<b>向量(vector)</b>是由一组实数组成的有序数组，一个<em>n</em>维向量$\boldsymbol a$由<em>n</em>个有序实数组成，表示为$\boldsymbol{a}=\left[a_{1}, a_{2}, \cdots, a_{n}\right]$，其中$a_{i}$称为向量$\boldsymbol{a}$的第$i$个分量(第$i$维)。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy库常用于实现线性代数中向量和矩阵的基本操作</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> numpy <span style=color:#ff79c6>as</span> np
</span></span><span style=display:flex><span><span style=color:#6272a4># numpy中向量的定义</span>
</span></span><span style=display:flex><span>v_1 <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>array([<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>3</span>, <span style=color:#bd93f9>4</span>, <span style=color:#bd93f9>5</span>])
</span></span><span style=display:flex><span>v_2 <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>array([<span style=color:#bd93f9>5.6</span>, <span style=color:#bd93f9>4.6</span>, <span style=color:#bd93f9>3.6</span>, <span style=color:#bd93f9>2.6</span>, <span style=color:#bd93f9>1.6</span>])
</span></span></code></pre></div><h2 id=向量空间>向量空间</h2><p><strong>向量空间(vector space)<strong>也称</strong>线性空间(linear space)</strong>，是指由向量组成的集合，并满足以下两个条件：</p><p>(1) <strong>向量加法封闭性</strong>：向量空间$\mathcal V$中的任意两个向量$\boldsymbol a$和$\boldsymbol b$，它们的和$\boldsymbol a+\boldsymbol b$也属于向量空间$\mathcal V$；</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy实现向量加法</span>
</span></span><span style=display:flex><span>v_a <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>add(v_1, v_2)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(v_a, v_a<span style=color:#ff79c6>.</span>shape)  <span style=color:#6272a4># 结果为向量</span>
</span></span></code></pre></div><p>(2) <strong>标量乘法封闭性</strong>：向量空间$\mathcal V$中的任一向量$\boldsymbol a$和任一标量$c$，它们的乘积$c\boldsymbol a$也属于向量空间$\mathcal V$。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy实现向量与标量相乘</span>
</span></span><span style=display:flex><span>k <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>2.0</span>
</span></span><span style=display:flex><span>v_k2 <span style=color:#ff79c6>=</span> k <span style=color:#ff79c6>*</span> v_1
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(v_k2, v_k2<span style=color:#ff79c6>.</span>shape)  <span style=color:#6272a4># 结果为向量</span>
</span></span></code></pre></div><p>一个常用的线性空间是<strong>欧式空间(Euclidean space)</strong>，常表示为$\mathbb R^n$，其中$n$为空间<strong>维度(dimension)</strong>。欧式空间中的向量加法和标量乘法定义为：</p>$$
\begin{aligned}
\left[a_{1}, a_{2}, \cdots, a_{n}\right]+\left[b_{1}, b_{2}, \cdots, b_{n}\right] &=\left[a_{1}+b_{1}, a_{2}+b_{2}, \cdots, a_{n}+b_{n}\right] \\
c \cdot\left[a_{1}, a_{2}, \cdots, a_{n}\right] &=\left[c a_{1}, c a_{2}, \cdots, c a_{n}\right]
\end{aligned}
$$<p><strong>线性子空间</strong>：向量空间$\mathcal V$的线性子空间$\mathcal U$是$\mathcal V$的一个子集，并且满足向量空间的条件。</p><p>设$v_1,v_2,\cdots,v_n$为向量空间$\mathcal V$中的向量，则其线性组合$a_1v_1+a_2v_2+\cdots+a_nv_n$构成$\mathcal V$的子空间，并将其称为向量$v_1,v_2,\cdots,v_n$<strong>张成(span)</strong> 的子空间，或$v_1,v_2,\cdots,v_n$的张成，记作$\operatorname{span}(v_1,v_2,\cdots,v_n)$。</p><p><strong>线性无关</strong>：线性空间$\mathcal V$中的一组向量</p>$$\left\{\boldsymbol{v}_{1}, \boldsymbol{v}_{2}, \cdots, \boldsymbol{v}_{n}\right\}$$<p>，如果对任意的一组标量$\lambda_{1}, \lambda_{2}, \cdots, \lambda_{n}$，若$\sum_i \lambda_i \boldsymbol v_i=0$，则必然$\lambda_1=\lambda_2=\cdots=\lambda_n=0$，那么</p>$$\left\{\boldsymbol{v}_{1}, \boldsymbol{v}_{2}, \cdots, \boldsymbol{v}_{n}\right\}$$<p>是线性无关的，也称为线性独立的。</p><p><strong>基向量</strong>：线性空间$\mathcal V$的<strong>基(base)</strong>$\mathcal B=\left\{\boldsymbol{e}_{1}, \boldsymbol{e}_{2}, \cdots, \boldsymbol{e}_{n}\right\}$是$\mathcal V$的有限子集，<strong>其元素之间线性无关</strong>。向量空间$\mathcal V$中的所有向量都可以按唯一的方式表达为$\mathcal B$中向量的线性组合。即对任意$v \in \mathcal V$，存在一组标量$(\lambda_1,\lambda_2,\cdots,\lambda_n)$，使得：</p>$$
\boldsymbol{v}=\lambda_{1} \boldsymbol{e}_{1}+\lambda_{2} \boldsymbol{e}_{2}+\cdots+\lambda_{n} \boldsymbol{e}_{n}
$$<p>$\mathcal B$中的向量称为<b>基向量(base vector)</b>。$(\lambda_1,\lambda_2,\cdots,\lambda_n)$称为向量$\boldsymbol v$关于基$\mathcal B$的<strong>坐标(coordinate)</strong>。向量空间中基的个数即向量空间的维数。</p><p><strong>内积(inner product)</strong>：一个$n$维线性空间中的两个向量$\boldsymbol a$和$\boldsymbol b$，其内积(也称<strong>点积</strong>)为：</p>$$
\langle\boldsymbol{a}, \boldsymbol{b}\rangle=\boldsymbol a^\text T \boldsymbol b=\sum_{i=1}^{n} a_{i} b_{i}
$$<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy实现向量内积</span>
</span></span><span style=display:flex><span>v_i <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>inner(v_1, v_2)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(v_i, v_i<span style=color:#ff79c6>.</span>shape)  <span style=color:#6272a4># 结果为标量</span>
</span></span></code></pre></div><p>向量内积实际上是矩阵乘法的一种特例。向量$\boldsymbol a$和$\boldsymbol b$的<b>外积(outer product)</b>定义为：</p>$$
\boldsymbol a \boldsymbol b^{\text T}=\left[\begin{array}{c}
a_{1} \\
a_{2} \\
\vdots \\
a_{m}
\end{array}\right]\left[\begin{array}{llll}
b_{1} & b_{2} & \cdots & b_{n}
\end{array}\right]=\left[\begin{array}{cccc}
a_{1} b_{1} & a_{1} b_{2} & \cdots & a_{1} b_{n} \\
a_{2} b_{1} & a_{2} b_{2} & \cdots & a_{2} b_{n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m} b_{1} & a_{m} b_{2} & \cdots & a_{m} b_{n}
\end{array}\right]
$$<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy实现向量外积</span>
</span></span><span style=display:flex><span>v_o <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>outer(v_1, v_2)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(v_o, v_o<span style=color:#ff79c6>.</span>shape)  <span style=color:#6272a4># 结果为矩阵</span>
</span></span></code></pre></div><p><strong>正交(orthogonal)</strong>：如果两个向量的内积为0，则它们正交。如果一个向量$\boldsymbol v$与子空间$\mathcal U$中的每个向量都正交，那么向量$\boldsymbol v$与子空间$\mathcal U$正交。</p><h2 id=范数>范数</h2><p><b>范数(norm)</b>是一个表示向量“长度”的函数，为向量空间内所有向量赋予非零的正长度或大小。对$n$维向量$\boldsymbol v$，一个常见的范数函数为$\ell_p$范数：</p>$$
\ell_{p}(\boldsymbol{v}) \equiv\|\boldsymbol{v}\|_{p}=\left(\sum_{i=1}^{n}\left|v_{i}\right|^{p}\right)^{1 / p}
$$<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy实现L2范数</span>
</span></span><span style=display:flex><span>v_1_2 <span style=color:#ff79c6>=</span> v_1 <span style=color:#ff79c6>*</span> v_1  <span style=color:#6272a4># &#39;*&#39;运算符代表向量对应位置相乘(即内积)</span>
</span></span><span style=display:flex><span>sum_l2 <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>sum(v_1_2)
</span></span><span style=display:flex><span>l2 <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>sqrt(sum_l2)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(l2)
</span></span></code></pre></div><p>其中$p \geqslant 0$为一个标量的参数。当$p=1$时，$\ell_1$范数为向量的各元素绝对值之和，称为<strong>曼哈顿距离</strong>；$p=2$时，$\ell_2$范数为向量的各元素的平方和再开平方，称为<strong>欧氏距离</strong>。$\ell_{\infty}$范数为向量的各个元素的最大绝对值。下图给出了常见范数的示例，其中红线表示不同范数$\ell_p=1$的点：</p><div align=center><img src=/Kimages/1/image-20200509111542485.png style=zoom:40%></div><h1 id=矩阵>矩阵</h1><h2 id=线性映射>线性映射</h2><p><strong>线性映射(linear mapping)<strong>是指从线性空间$\mathcal V$到线性空间$\mathcal W$的一个映射函数$f:\mathcal V \rightarrow \mathcal W$，并满足：对于$\mathcal V$中任何两个向量$\boldsymbol u$和$\boldsymbol v$以及任何标量$c$，有：
$$
\begin{aligned}
f(\boldsymbol{u}+\boldsymbol{v}) &=f(\boldsymbol{u})+f(\boldsymbol{v}) \\
f(c \boldsymbol{v}) &=c f(\boldsymbol{v})
\end{aligned}
$$
即该函数对加法和数量乘法封闭。两个有限维欧式空间的映射函数$f:\mathbb R^n \rightarrow \mathbb R^m$可以表示为：
$$
y=A x \triangleq\left[\begin{array}{c}
a_{11} x_{1}+a_{12} x_{2}+\cdots+a_{1 n} x_{n} \\
a_{21} x_{1}+a_{22} x_{2}+\cdots+a_{2 n} x_{n} \\
\vdots \\
a_{m 1} x_{1}+a_{m 2} x_{2}+\cdots+a_{m n} x_{n}
\end{array}\right]
$$
其中$A$定义为$m \times n$的</strong>矩阵(matrix)</strong>，是一个由$m$行$n$列元素排列成的矩形阵列。一个矩阵$A$从左上角数起的第$i$行第$j$列上的元素称为第$i,j$项，通常记为$[A_{ij}]$或$a_{ij}$。矩阵$A$定义了一个从$\mathbb R^n$到$\mathbb R^m$的线性映射，向量$\boldsymbol x$和$\boldsymbol y$分别为两个空间中的<strong>列向量</strong>，即大小为$n \times 1$或$m \times 1$的矩阵：</p>$$
\boldsymbol{x}=\left[\begin{array}{c}
x_{1} \\
x_{2} \\
\vdots \\
x_{n}
\end{array}\right], \quad \boldsymbol{y}=\left[\begin{array}{c}
y_{1} \\
y_{2} \\
\vdots \\
y_{m}
\end{array}\right]
$$<p><strong>在没有特殊说明的情况下，向量默认为列向量</strong>，且行向量表示为$[x_1,x_2,\cdots,x_n]$，列向量表示为$[x_1;x_2;\cdots;x_n]$或行向量的转置$[x_1,x_2,\dots,x_n]^\text T$。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy中矩阵的定义</span>
</span></span><span style=display:flex><span>A <span style=color:#ff79c6>=</span> [[<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>3</span>, <span style=color:#bd93f9>4</span>],
</span></span><span style=display:flex><span>     [<span style=color:#bd93f9>5</span>, <span style=color:#bd93f9>6</span>, <span style=color:#bd93f9>7</span>, <span style=color:#bd93f9>8</span>],
</span></span><span style=display:flex><span>     [<span style=color:#bd93f9>9</span>, <span style=color:#bd93f9>10</span>, <span style=color:#bd93f9>11</span>, <span style=color:#bd93f9>12</span>]]  <span style=color:#6272a4># (3,4)</span>
</span></span><span style=display:flex><span>A <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>array(A)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(A<span style=color:#ff79c6>.</span>shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>B <span style=color:#ff79c6>=</span> [[<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>3</span>, <span style=color:#bd93f9>4</span>, <span style=color:#bd93f9>5</span>],
</span></span><span style=display:flex><span>     [<span style=color:#bd93f9>6</span>, <span style=color:#bd93f9>7</span>, <span style=color:#bd93f9>8</span>, <span style=color:#bd93f9>9</span>, <span style=color:#bd93f9>10</span>],
</span></span><span style=display:flex><span>     [<span style=color:#bd93f9>11</span>, <span style=color:#bd93f9>12</span>, <span style=color:#bd93f9>13</span>, <span style=color:#bd93f9>14</span>, <span style=color:#bd93f9>15</span>],
</span></span><span style=display:flex><span>     [<span style=color:#bd93f9>16</span>, <span style=color:#bd93f9>17</span>, <span style=color:#bd93f9>18</span>, <span style=color:#bd93f9>19</span>, <span style=color:#bd93f9>20</span>]]  <span style=color:#6272a4># (4,5)</span>
</span></span><span style=display:flex><span>B <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>array(B)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(B<span style=color:#ff79c6>.</span>shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 满秩矩阵</span>
</span></span><span style=display:flex><span>X <span style=color:#ff79c6>=</span> [[<span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>6</span>, <span style=color:#bd93f9>9</span>],
</span></span><span style=display:flex><span>     [<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>9</span>, <span style=color:#bd93f9>3</span>],
</span></span><span style=display:flex><span>     [<span style=color:#bd93f9>7</span>, <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>4</span>]]
</span></span></code></pre></div><h2 id=矩阵操作>矩阵操作</h2><p>(1) <b>加法</b>：</p>$$[A+B]_{ij}=a_{ij}+b_{ij}$$<p>，必须保证运算的两个矩阵的大小相同。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy实现矩阵加法</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(np<span style=color:#ff79c6>.</span>add(A, A))
</span></span></code></pre></div><p>(2) <strong>乘积</strong>：</p>$$[AB]_{ij}=\sum_{k=1}^ma_{ik}b_{kj}$$<p>，必须保证第一个矩阵的列数和第二个矩阵的行数相等。矩阵的乘积表示一个复合线性映射，即先完成线性映射$B$，再完成线性映射$A$。如果$A$是$k \times m$阶矩阵，$B$是$m \times n$阶矩阵，则其乘积$AB$是一个$k \times n$阶矩阵。矩阵乘法满足结合律和分配率：</p><p><strong>结合律</strong>：$(AB)C=A(BC)$，</p><p><strong>分配率</strong>：$(A+B)C=AC+BC,C(A+B)=CA+CB$。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy实现矩阵乘法</span>
</span></span><span style=display:flex><span>C <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>dot(A, B)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(C, C<span style=color:#ff79c6>.</span>shape)  <span style=color:#6272a4># (3,4) * (4,5) = (3,5)</span>
</span></span></code></pre></div><p>(3) <strong>Hadamard积</strong>：</p>$$[A \odot B]_{i j}=a_{i j} b_{i j}$$<p>，即$A$和$B$中对应的元素相乘，必须保证运算的两个矩阵的大小相同。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy实现Hadamard积</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(np<span style=color:#ff79c6>.</span>multiply(A, A))
</span></span></code></pre></div><p>(4) <strong>转置(transposition)</strong>：</p>$$[A^\text T]_{ij}=[A]_{ji}。$$<p>显然，$(A+B)^\text T =A^\text T + B^\text T$，$(AB)^\text T=B^\text T A^\text T$。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy实现矩阵转置</span>
</span></span><span style=display:flex><span>A_T <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>transpose(A)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(A_T, A_T<span style=color:#ff79c6>.</span>shape)
</span></span></code></pre></div><p>(5) <strong>迹(trace)</strong>：对于$n$阶<strong>方阵</strong>$A$，它的迹为主对角线上的元素之和，记作$\text{tr}(A)=\sum_{i=1}^n A_{ii}$。迹有如下性质：</p>$$
\begin{aligned}
\text{tr}(A^\text T)&=\text{tr}(A)\\
\text{tr}(A+B)&=\text{tr}(A)+\text{tr}(B)\\
\text{tr}(AB)&=\text{tr}(BA)\\
\text{tr}(ABC)&=\text{tr}(BCA)=\text{tr}(CAB)
\end{aligned}
$$<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy计算方阵的迹</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(np<span style=color:#ff79c6>.</span>trace(A))  <span style=color:#6272a4># 结果为标量</span>
</span></span></code></pre></div><p>(6) <strong>行列式(determinant)</strong>：$n$阶方阵$A$的行列式定义为$\det(A)=\sum_{\sigma \in S_n}\text{par}(\sigma)A_{1\sigma_1 A_2\sigma_2 \cdots A_n\sigma_n}$，其中$S_n$为所有$n$阶排列(permutation)的集合，$\text{par}(\sigma)$的值为-1或+1取决于$\sigma$为及排列或偶排列，即其中出现降序的次数为奇数或偶数，例如$(1,3,2)$中降序次数为1，$(3,1,2)$中降序次数为2。单位阵的行列式为$\det(I)=1$。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy计算方阵的行列式</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(np<span style=color:#ff79c6>.</span>linalg<span style=color:#ff79c6>.</span>det(X))
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(np<span style=color:#ff79c6>.</span>linalg<span style=color:#ff79c6>.</span>det(A))  <span style=color:#6272a4># 报错，计算行列式的矩阵必须为方阵</span>
</span></span></code></pre></div><p>$n$阶方阵$A$的行列式有如下<strong>性质</strong>：</p><p>如果行列式中<strong>有一行为零，或有两行相同，或有两行成比例</strong>，那么行列式为零；</p><p><strong>对换</strong>行列式中两行的位置，行列式<strong>反号</strong>；</p><p><strong>把一行的倍数加到另一行，行列式不变</strong>；</p><p>行列式的其他运算性质如下：</p>$$
\begin{aligned}
\det(cA)&=c^n\det(A)\\
\det(A^\text T)&=\det(A)\\
\det(AB)&=\det(A)\det(B)\\
\det(A^{-1})&=\det(A)^{-1}\\
\det(A^{n})&=\det(A)^{n}
\end{aligned}
$$<p>低维矩阵的行列式计算举例如下：</p>$$
\begin{aligned}
\left|\left[a_{11}\right]\right|&=a_{11}\\
\left|\left[\begin{array}{ll}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{array}\right]\right|&=a_{11} a_{22}-a_{12} a_{21}\\
\left|\left[\begin{array}{lll}
a_{11} & a_{12} & a_{13} \\
a_{21} & a_{22} & a_{23} \\
a_{31} & a_{32} & a_{33}
\end{array}\right]\right|&=\begin{array}{c}
a_{11} a_{22} a_{33}+a_{12} a_{23} a_{31}+a_{13} a_{21} a_{32} \\
-a_{11} a_{23} a_{32}-a_{12} a_{21} a_{33}-a_{13} a_{22} a_{31}
\end{array}
\end{aligned}
$$<p>(7) <strong>秩(rank)</strong>：一个矩阵$A$的列秩是$A$的线性无关的列向量的数量，行秩是$A$的线性无关的行向量数量。<strong>一个矩阵的列秩和行秩总是相等的</strong>，简称为秩。一个$m \times n$阶矩阵$A$的秩最大为$\min(m,n)$。若$\text{rank}(A)=\min(m,n)$，则称矩阵$A$是<strong>满秩</strong>的。<strong>如果一个矩阵不满秩，说明其包含线性相关的列向量或行向量，其行列式为0</strong>。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy计算矩阵的秩</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(np<span style=color:#ff79c6>.</span>linalg<span style=color:#ff79c6>.</span>matrix_rank(X))
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(np<span style=color:#ff79c6>.</span>linalg<span style=color:#ff79c6>.</span>matrix_rank(A))
</span></span></code></pre></div><p>两个矩阵的乘积$AB$的秩$\text{rank}(AB) \leqslant \min(\text{rank}(A),\text{rank}(B))$。</p><p>矩阵$A$的秩=矩阵$A$的列秩=矩阵$A$的行秩，<strong>矩阵的初等变换皆不改变矩阵的秩、行秩和列秩</strong>。</p><p>(8) <strong>范数(norm)</strong>：与向量的范数相似，矩阵常用的$\ell_p$范数定义为：</p>$$
\|A\|_{p}=\left(\sum_{i=1}^{m} \sum_{j=1}^{n}\left|a_{i j}\right|^{p}\right)^{1 / p}
$$<p>(9) <strong>矩阵的逆(inverse matrix)</strong>：对于$n \times n$的<strong>方阵</strong>$A$，如果存在另一个方块矩阵$B$使得$AB=BA=I_n$，其中$I_n$为单位矩阵，则称$A$是可逆的。矩阵$B$称为矩阵$A$的逆矩阵，记为$A^{-1}$。矩阵的逆满足如下性质：</p>$$
\begin{aligned}
(A^{-1})^{-1}&=A \\
(A B)^{-1}&=B^{-1} A^{-1} \\
(A^{-1})^{T}&=(A^{T})^{-1}
\end{aligned}
$$<p><strong>一个方阵的行列式等于0当且仅当该方阵不可逆</strong>。不可逆矩阵也称<strong>奇异矩阵</strong>，可逆矩阵也称<strong>非奇异矩阵</strong>。对非方阵或奇异矩阵，可以计算其<strong>伪逆</strong>。</p><p>求$A^{-1}$的算法：构造增广矩阵$[A,I]$，进行行化简，若$A$行等价于$I$，则$[A,I]$行等价于$[I,A^{-1}]$，否则$A$没有逆。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy计算方阵的逆</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(np<span style=color:#ff79c6>.</span>linalg<span style=color:#ff79c6>.</span>inv(X))  <span style=color:#6272a4># print(X.I)也可以</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(np<span style=color:#ff79c6>.</span>linalg<span style=color:#ff79c6>.</span>inv(A))  <span style=color:#6272a4># 报错，计算逆的矩阵必须为方阵</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># numpy计算矩阵的伪逆</span>
</span></span><span style=display:flex><span>M <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>zeros((<span style=color:#bd93f9>4</span>, <span style=color:#bd93f9>4</span>))  <span style=color:#6272a4># 定义一个奇异阵M</span>
</span></span><span style=display:flex><span>M[<span style=color:#bd93f9>0</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1</span>] <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>1</span>
</span></span><span style=display:flex><span>M[<span style=color:#ff79c6>-</span><span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>0</span>] <span style=color:#ff79c6>=</span> <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1</span>
</span></span><span style=display:flex><span>M <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>matrix(M)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(M)
</span></span><span style=display:flex><span><span style=color:#6272a4># print(M.I)  # 将报错，矩阵M为奇异矩阵，不可逆</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(np<span style=color:#ff79c6>.</span>linalg<span style=color:#ff79c6>.</span>pinv(M))  <span style=color:#6272a4># 求矩阵M的伪逆(广义逆矩阵)</span>
</span></span></code></pre></div><p>(10) <strong>初等行变换</strong>：对于矩阵$A$，把$A$的某一行所有元素乘以一非零元素，或把$A$的两行互换，或把$A$的某一行换乘它本身与另一行的倍数的和，这三种操作称为矩阵$A$的初等行变换。若矩阵$A$经过有限次初等行变换后可以转化为矩阵$B$，则称矩阵$A$和矩阵$B$是<strong>行等价</strong>的。</p><p>定理：$n \times n$矩阵$A$是可逆的，当且仅当$A$行等价于单位矩阵$I_n$。这时，将$A$化简为$I_n$的一系列初等行变换也可以将$I_n$转换为$A^{-1}$。</p><p>证明：$A \sim E_1A \sim E_2(E_1A) \sim \cdots \sim E_p(E_{p-1} \cdots E_1A)=I_n$，因此$E_p E_{p-1} \cdots E_1 I_n=A^{-1}$。</p><p>(11) <strong>Numpy中矩阵运算的广播机制</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># 通常情况下，numpy两个数组的相加、相减以及相乘都是对应元素之间的操作</span>
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>array([[<span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>3</span>], [<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>3</span>]])
</span></span><span style=display:flex><span>y <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>array([[<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>3</span>], [<span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>4</span>]])
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(x <span style=color:#ff79c6>*</span> y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 当两个张量维度不同，numpy可以自动使用广播机制使得运算得以完成。例如：</span>
</span></span><span style=display:flex><span>arr <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>random<span style=color:#ff79c6>.</span>randn(<span style=color:#bd93f9>4</span>, <span style=color:#bd93f9>3</span>)  <span style=color:#6272a4># (4,3)</span>
</span></span><span style=display:flex><span>arr_mean <span style=color:#ff79c6>=</span> arr<span style=color:#ff79c6>.</span>mean(axis<span style=color:#ff79c6>=</span><span style=color:#bd93f9>0</span>)  <span style=color:#6272a4># shape(3,)</span>
</span></span><span style=display:flex><span>demeaned <span style=color:#ff79c6>=</span> arr <span style=color:#ff79c6>-</span> arr_mean  <span style=color:#6272a4># (4,3) - (3,)</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(demeaned)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 广播的原则：如果两个数组的后缘维度（trailing dimension，即从末尾开始算起的维度）的轴长度相符，或其中的一方的长度为1，</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 则认为它们是广播兼容的。广播会在缺失和(或)长度为1的维度上进行。</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 广播主要发生在两种情况，一种是两个数组的维数不相等，但是它们的后缘维度的轴长相符，另外一种是有一方的长度为1。</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 1. 数组维度不同，后缘维度的轴长相符</span>
</span></span><span style=display:flex><span>arr1 <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>array([[<span style=color:#bd93f9>0</span>, <span style=color:#bd93f9>0</span>, <span style=color:#bd93f9>0</span>], [<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>1</span>], [<span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>2</span>], [<span style=color:#bd93f9>3</span>, <span style=color:#bd93f9>3</span>, <span style=color:#bd93f9>3</span>]])  <span style=color:#6272a4># (4,3)</span>
</span></span><span style=display:flex><span>arr2 <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>array([<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>3</span>])  <span style=color:#6272a4># (3,)</span>
</span></span><span style=display:flex><span>arr_sum <span style=color:#ff79c6>=</span> arr1 <span style=color:#ff79c6>+</span> arr2
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(arr_sum)
</span></span><span style=display:flex><span><span style=color:#6272a4># 在上例中，(4,3) + (3,) = (4,3)。类似的例子还有：(3,4,2) + (4,2) = (3,4,2)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 2. 有一方的长度为1</span>
</span></span><span style=display:flex><span>arr1 <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>array([[<span style=color:#bd93f9>0</span>, <span style=color:#bd93f9>0</span>, <span style=color:#bd93f9>0</span>], [<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>1</span>], [<span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>2</span>], [<span style=color:#bd93f9>3</span>, <span style=color:#bd93f9>3</span>, <span style=color:#bd93f9>3</span>]])  <span style=color:#6272a4># (4,3)</span>
</span></span><span style=display:flex><span>arr2 <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>array([[<span style=color:#bd93f9>1</span>], [<span style=color:#bd93f9>2</span>], [<span style=color:#bd93f9>3</span>], [<span style=color:#bd93f9>4</span>]])  <span style=color:#6272a4># (4,1)</span>
</span></span><span style=display:flex><span>arr_sum <span style=color:#ff79c6>=</span> arr1 <span style=color:#ff79c6>+</span> arr2
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(arr_sum)
</span></span><span style=display:flex><span><span style=color:#6272a4># 在上例中，(4,3) + (4,1) = (4,3)类似的例子还有：(4,6) + (1,6) = (4,6)；(3,5,6) + (1,5,6) = (3,5,6)；</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># (3,5,6) + (3,1,6) = (3,5,6)；(3,5,6) + (3,5,1) = (3,5,6)等</span>
</span></span></code></pre></div><h2 id=矩阵类型>矩阵类型</h2><p>(1) <strong>对称矩阵(symmetric matrix)</strong>：转置等于其自己的矩阵，即满足$A=A^\text T$。若$A=-A^\text T$，则称矩阵$A$为<strong>反对称矩阵(anti-symmetric matrix)</strong>。易证，对于矩阵$A \in \mathbb R^{m \times n}$，$A+A^\text T$为对称矩阵，$A-A^\text T$为反对称矩阵。从以上结论又可以得出，任意<strong>方阵(square matrix)</strong>$A \in \mathbb R^{n \times n}$都可以由一个对称矩阵和一个反对称矩阵表示：</p>$$
A=\frac{1}{2}(A+A^{T})+\frac{1}{2}(A-A^{T})
$$<p>对称矩阵在实际应用中有很多良好的性质，通常将$n$维对称矩阵的集合记为$\mathbb S^n$。</p><p>(2) <strong>对角矩阵(diagonal matrix)</strong>：除了主对角线外的元素皆为0的矩阵，对角线上的元素可以为0或其他值。一个$n \times n$的对角矩阵$A$满足：$[A]_{ij}=0 \ \ \text{ if } i \not = j, \forall i,j \in \{1,\cdots,n\}$。</p><p>对角矩阵也可以记作$\text{diag}(\boldsymbol a)$，其中$\boldsymbol a$为一个$n$维向量，并满足$[A]_{ii}=a_i$。一个$n \times n$阶对角矩阵$A=\text{diag}(A)$和$n$维向量$\boldsymbol b$的乘积为一个$n$维向量：$A \boldsymbol{b}=\operatorname{diag}(\boldsymbol{a}) \boldsymbol{b}=\boldsymbol{a} \odot \boldsymbol{b}$，其中$\odot$表示点乘。</p><p>(3) <strong>单位矩阵(identity matrix)</strong>：一种特殊的对角矩阵，其主对角线元素为1，其余元素为0。$n$阶单位矩阵$I_n$是一个$n \times n$的方块矩阵，可以记为$I_n=\text{diag}(1,1,\cdots,1)$。</p><p>一个$m \times n$的矩阵$A$和单位矩阵的乘积(左乘积和右乘积)等于其本身：$AI_n=I_mA=A$。</p><p>(4) <strong>正定矩阵(positive-definite matrix)</strong>：对于一个$n \times n$阶的<strong>对称矩阵</strong>$A$，如果对于所有的非零向量$\boldsymbol x \in \mathbb R^n$，都满足$\boldsymbol x^\text T A \boldsymbol x>0$，则$A$为正定矩阵。如果$\boldsymbol x^\text T A \boldsymbol x\ \geqslant 0$，则$A$为<strong>半正定矩阵(positive-semidefinite matrix)</strong>。</p><p>(5) <strong>正交矩阵(orthogonal matrix)</strong>：对于方阵$U \in \mathbb R^{n \times n}$，如果$UU^T = I$或$U^TU = I$，则称$U$为正交矩阵。</p><p>(6) <strong>Gram矩阵</strong>：向量空间中一组向量$\boldsymbol v_1,\boldsymbol v_2,\cdots,\boldsymbol v_n$的Gram矩阵$G$是内积的对称矩阵，其元素$G_{ij}=\boldsymbol v_i^\text T \boldsymbol v_j$。</p><h1 id=相似矩阵与对角化>相似矩阵与对角化</h1><p>设$A$和$B$是$n \times n$矩阵，如果存在可逆矩阵$P$，使得$P^{-1}AP=B$，则称$A$相似于$B$，$B$也相似于$A$。将$A$变成$P^{-1}AP$的变换称为<strong>相似变换</strong>。</p><p>若$A$和$B$是相似的，那么它们有相同的特征多项式，有相同的特征值；但是有相同的特征值的矩阵并不一定相似。</p><p>证明：$P^{-1}AP=B$，则$|B-\lambda I|=|P^{-1}AP-\lambda I|=|P^{-1}(A-\lambda I)P|=|A-\lambda I|$。</p><p>若方阵$A$<strong>相似于对角矩阵</strong>，则称$A$<strong>可对角化</strong>。$n \times n$矩阵$A$可对角化的充分必要条件是$A$有$n$个线性无关的特征向量。</p><h2 id=二次型与正定矩阵>二次型与正定矩阵</h2><p>给定一个方阵$A \in \mathbb R^{n \times n}$和一个列向量$x \in \mathbb R^n$，标量$x^{T} A x$被称为一个<strong>二次型(quadratic form)</strong>。具体地：</p>$$
x^{\text T} A x=\sum_{i=1}^{n} x_{i}(A x)_{i}=\sum_{i=1}^{n} x_{i}\left(\sum_{j=1}^{n} A_{i j} x_{j}\right)=\sum_{i=1}^{n} \sum_{j=1}^{n} A_{i j} x_{i} x_{j}
$$<p>值得注意的是：</p>$$
x^{\text T} A x=(x^{\text T} A x)^{\text T}=x^{\text T} A^{\text T} x=x^{\text T}(\frac{1}{2} A+\frac{1}{2} A^{\text T}) x
$$<p>其中，第一个等式依据<strong>标量的转置等于其自身</strong>的事实，而第二个等式源自以下事实：我们<strong>对两个本身相等的量求平均</strong>。 据此可以得出结论，只有$A$的<strong>对称部分对二次形有帮助</strong>。 由于这个原因，我们经常<strong>隐式地假设以二次形式出现的矩阵是对称的</strong>。</p><p>正定矩阵、半正定矩阵、负定矩阵、半负定矩阵以及不定矩阵的定义如下：</p><div align=center><img src=/Kimages/1/image-20200602204800814.png style=zoom:35%></div><p>一个关于正定矩阵或负定矩阵的重要性质是，<strong>其总是满秩的，因此一定是可逆矩阵</strong>。证明如下：</p><p>假定一个矩阵$A \in \mathbb R^{n \times n}$是不满秩的，并假设$A$的第$j$列可以由其他$n-1$列进行线性表示，即$a_{j}=\sum_{i \neq j} x_{i} a_{i}$。其中，$x_{1}, \cdots, x_{j-1}, x_{j+1}, \cdots, x_{n} \in \mathbb{R}$是一系列标量。当设置$x_j=-1$时，有：</p>$$
A x=\sum_{i=1}^{n} x_{i} a_{i}=0
$$<p>对于某些非零向量$x$，上式会使得$x^{T} A x=0$，与正定或负定矩阵的定义矛盾。证毕。</p><h1 id=特征值与特征向量>特征值与特征向量</h1><p>对矩阵$A$，如果存在一个标量$\lambda$和一个<strong>非零向量</strong>$x$满足$Ax = \lambda x$，则$\lambda$和$x$分别称为矩阵$A$的<strong>特征值(eigenvalue)<strong>和</strong>特征向量(eigenvector)</strong>。对于任意特征向量$x$和标量$c$，$A (cx) = \lambda (cx)$，因此$cx$也是特征向量。因此，在通常情况下，<strong>仅讨论模为1的特征向量</strong>。矩阵$A$可以认为是一个变换，这个变换的特殊之处是，当它作用在特征向量$x$上的时候，$x$只产生了缩放变换，并没有产生旋转变换。</p><p>上式还可以变形为：</p>$$
(\lambda I-A)x=\boldsymbol 0,x \not = \boldsymbol 0
$$<p>这是含有$n$个未知数的$n$个方程的齐次线性方程组，它<strong>有非零解的充分必要条件</strong>是系数行列式$|(\lambda I-A)|=0$。将该等式变形，会得到关于$\lambda$的多项式。将多项式进行求解后，会得到最多$n$个特征值$\lambda$。将特征值分别代入原式，便可以得到最多$n$个特征向量。<strong>这种方式仅仅作为手工求解特征值和特征向量的方法，并不被实际应用</strong>。</p><p>以下是关于特征值的一些性质。其中$A \in \mathbb R^{n \times n}$，$\lambda_1\cdots,\lambda_n$是$n$个特征值，对应$n$个特征向量。$x_1,\cdots,x_n$。</p><div align=center><img src=/Kimages/1/image-20200602204800814.png style=zoom:35%></div><p>可以将所有特征向量和特征值合并成矩阵形式，并写为：$A X=X \Lambda$。其中，</p>$$
X \in \mathbb{R}^{n \times n}=\left[\begin{array}{cccc}
| & | & & | \\
x_{1} & x_{2} & \cdots & x_{n} \\
| & | & & |
\end{array}\right], \Lambda=\operatorname{diag}\left(\lambda_{1}, \ldots, \lambda_{n}\right)
$$<p>若矩阵$A$的特征向量线性无关，则矩阵$X$是可逆矩阵，则$A=X \Lambda X^{-1}$。该过程称为<strong>对角化(diagonalization)</strong>。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy实现矩阵特征值分解</span>
</span></span><span style=display:flex><span>X <span style=color:#ff79c6>=</span> [[<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>3</span>],
</span></span><span style=display:flex><span>     [<span style=color:#bd93f9>4</span>, <span style=color:#bd93f9>5</span>, <span style=color:#bd93f9>6</span>],
</span></span><span style=display:flex><span>     [<span style=color:#bd93f9>7</span>, <span style=color:#bd93f9>8</span>, <span style=color:#bd93f9>9</span>]]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>eigenvalues, eigenvectors <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>linalg<span style=color:#ff79c6>.</span>eig(X)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(<span style=color:#f1fa8c>&#34;eigenvalue: </span><span style=color:#f1fa8c>\n</span><span style=color:#f1fa8c>&#34;</span>, eigenvalues)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(<span style=color:#f1fa8c>&#34;eigenvector: </span><span style=color:#f1fa8c>\n</span><span style=color:#f1fa8c>&#34;</span>, eigenvectors)
</span></span></code></pre></div><h1 id=奇异值分解>奇异值分解</h1><h2 id=奇异值分解的定义与性质>奇异值分解的定义与性质</h2><p>任意一个$m \times n$阶矩阵，都可以表示为三个矩阵的乘积，分别是$m$阶正交矩阵、由降序排列的非负的对角线元素组成的$m \times n$阶对角矩阵和$n$阶正交矩阵，称为该矩阵的<strong>奇异值分解(singular value decomposition, SVD)</strong>。一个矩阵的奇异值分解<strong>一定存在，但不唯一</strong>。</p><p>奇异值分解可以看作是<strong>矩阵数据压缩</strong>的一种方法，即用因子分解的方式近似地表示原始矩阵，这种近似是<strong>在平方损失意义下的最优近似</strong>。</p><h3 id=定义与定理>定义与定理</h3><p>矩阵的奇异值分解是指将一个非零的$m \times n$阶实矩阵$A \in \mathbb R^{m \times n}$表示为三个实矩阵乘积形式的运算$A=U \Sigma V^\text T$。其中，$U$是$m$阶正交矩阵，$V$是$n$阶正交矩阵，$\Sigma$是<strong>降序排列的非负对角线元素</strong>组成的$m \times n$阶对角矩阵，满足$UU^\text T=I$，$VV^\text T=I$，$\Sigma=\text{diag}(\sigma_1,\sigma_2,\cdots,\sigma_p)$($\sigma_i$非负且降序排列)，$p=\min(m,n)$。$U \Sigma V^\text T$称为矩阵$A$的<strong>奇异值分解</strong>，$\sigma_i$称为矩阵$A$的<strong>奇异值</strong>，$U$的列向量称为<strong>左奇异向量</strong>，$V$的列向量称为<strong>右奇异向量</strong>。</p><p>注意：奇异值分解不要求$A$是方阵，事实上，<strong>奇异值分解可以看作方阵对角化的推广</strong>。</p><p><strong>奇异值分解基本定理</strong>：若$A$为<strong>实矩阵</strong>，则$A$的奇异值分解一定存在。</p><h3 id=紧奇异值分解与截断奇异值分解>紧奇异值分解与截断奇异值分解</h3><p>$A=U \Sigma V^\text T$又称为矩阵的完全奇异值分解，实际常用的是<strong>紧凑形式和截断形式</strong>。</p><p>(1) <strong>紧奇异值分解</strong>：设$m \times n$阶实矩阵$A$的秩$\text{rank}(A)=r,r \leqslant \min(m, n)$，则称$U_r \Sigma_r V_r^\text T$为矩阵$A$的紧奇异值分解。其中$U_r$是$m \times r$矩阵，$V_r$是$n \times r$矩阵，$\Sigma_r$是$r$阶对角矩阵。</p><p>(2) <strong>截断奇异值分解</strong>：在矩阵的奇异值分解中，只取最大的$k$个奇异值($k<r$，$r$为矩阵的秩)对应的部分，就得到矩阵的截断奇异值分解。<strong>实际应用中提到矩阵的奇异值分解时，通常指截断奇异值分解</strong>。此时$\Sigma k$是$k$阶对角矩阵。</p><h3 id=几何解释>几何解释</h3><p>三个矩阵(对应一个线性变换)可以理解为<strong>三个线性变换的步骤</strong>：一个坐标系的<strong>旋转</strong>变换、一个坐标轴的<strong>缩放</strong>变换和一个坐标系的<strong>旋转</strong>或反射变换。</p><h2 id=奇异值分解的计算>奇异值分解的计算</h2><p>奇异值分解的计算过程如下：</p><p>(1) 首先求$A^\text T A$的<strong>特征值</strong>，记作$\lambda_1,\cdots,\lambda_n$，共有$n$个，然后求解出对应的特征向量$x_1,\cdots,x_n$。</p><p>(2) 求$n$阶<strong>正交矩阵</strong>$V$：将特征向量<strong>单位化</strong>，得到单位特征向量$v_1,\cdots,v_n$构成$n$阶正交矩阵$V=[v_1 \ v_2 \ \cdots \ v_n]$。</p><p>(3) 求$m \times n$阶对角矩阵$\Sigma$：计算$A$的奇异值$\sigma_i=\sqrt{\lambda_i},i=1,2,\cdots,n$(奇异值就是$A^\text T A$的特征向量的平方根)，构造$m \times n$阶对角矩阵$\Sigma$，主对角线元素是奇异值，其余元素为0。</p><p>(4) 求$m$阶正交矩阵$U$：对$A$的前$r$个正奇异值，令$u_j=(1/\sigma_j)Av_j,j=1,2,\cdots,r$，得到$U_1=[u_1 \ u2 \cdots \ u_r]$。求$A^\text T$的零空间(即$A^\text T x=0$的解空间)一组标准正交基$\{u_{r+1},u_{r+2},\cdots,u_m\}$，令$U_2=[u_{r+1},u_{r+2},\cdots,u_m]$并令$U=[U_1 \ U_2]$，得到正交矩阵$U$。</p><p>从上述算法可以看出，奇异值分解的关键在于的$A^\text T A$特征值的计算。实际应用中的奇异值分解算法是通过求解$A^\text T A$的特征值，但不直接计算$A^\text T A$。按照这个思路，产生了许多矩阵奇异值分解的有效算法。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy实现矩阵的奇异值分解</span>
</span></span><span style=display:flex><span>U, Sigma, V <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>linalg<span style=color:#ff79c6>.</span>svd(X, )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(<span style=color:#f1fa8c>&#34;U: </span><span style=color:#f1fa8c>\n</span><span style=color:#f1fa8c>&#34;</span>, U)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(<span style=color:#f1fa8c>&#34;Sigma: </span><span style=color:#f1fa8c>\n</span><span style=color:#f1fa8c>&#34;</span>, Sigma)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(<span style=color:#f1fa8c>&#34;V: </span><span style=color:#f1fa8c>\n</span><span style=color:#f1fa8c>&#34;</span>, V)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 通过截断奇异值分解重建矩阵X</span>
</span></span><span style=display:flex><span>Sigma[<span style=color:#bd93f9>1</span>:] <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>
</span></span><span style=display:flex><span>X_rebuild <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>mat(U) <span style=color:#ff79c6>*</span> np<span style=color:#ff79c6>.</span>mat(np<span style=color:#ff79c6>.</span>diag(Sigma)) <span style=color:#ff79c6>*</span> np<span style=color:#ff79c6>.</span>mat(V)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X_rebuild)  <span style=color:#6272a4># 矩阵X的近似</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 奇异值分解在图像处理中的应用</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> matplotlib.pyplot <span style=color:#ff79c6>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>lenna <span style=color:#ff79c6>=</span> plt<span style=color:#ff79c6>.</span>imread(<span style=color:#f1fa8c>&#39;lenna.jpg&#39;</span>)  <span style=color:#6272a4># 需要预先将图片lenna.jpg放入当前目录中</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(lenna<span style=color:#ff79c6>.</span>shape)  <span style=color:#6272a4># (2318,1084,3)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>lenna <span style=color:#ff79c6>=</span> lenna[:<span style=color:#bd93f9>1000</span>, :<span style=color:#bd93f9>1000</span>, <span style=color:#bd93f9>2</span>]  <span style=color:#6272a4># 将图像大小调整为(1000,1000)，且仅选取一个通道</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(lenna<span style=color:#ff79c6>.</span>shape)  <span style=color:#6272a4># (1000,1000)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>U, Sigma, V <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>linalg<span style=color:#ff79c6>.</span>svd(lenna)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(U<span style=color:#ff79c6>.</span>shape, Sigma<span style=color:#ff79c6>.</span>shape, V<span style=color:#ff79c6>.</span>shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 通过截断奇异值分解重建莱娜图，观察k取不同值时的重建结果</span>
</span></span><span style=display:flex><span>k <span style=color:#ff79c6>=</span> [<span style=color:#bd93f9>1000</span>, <span style=color:#bd93f9>500</span>, <span style=color:#bd93f9>300</span>, <span style=color:#bd93f9>200</span>, <span style=color:#bd93f9>100</span>, <span style=color:#bd93f9>50</span>]
</span></span><span style=display:flex><span><span style=color:#ff79c6>for</span> i <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(<span style=color:#8be9fd;font-style:italic>len</span>(k)):
</span></span><span style=display:flex><span>    Sigma_k <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>copy(Sigma)
</span></span><span style=display:flex><span>    Sigma_k[k[i]:] <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>
</span></span><span style=display:flex><span>    lenna_rebuild <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>mat(U) <span style=color:#ff79c6>*</span> np<span style=color:#ff79c6>.</span>mat(np<span style=color:#ff79c6>.</span>diag(Sigma_k)) <span style=color:#ff79c6>*</span> np<span style=color:#ff79c6>.</span>mat(V)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    plt<span style=color:#ff79c6>.</span>subplot(<span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>3</span>, i <span style=color:#ff79c6>+</span> <span style=color:#bd93f9>1</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#ff79c6>.</span>title(<span style=color:#f1fa8c>&#39;truncated k=</span><span style=color:#f1fa8c>{}</span><span style=color:#f1fa8c>&#39;</span><span style=color:#ff79c6>.</span>format(k[i]))
</span></span><span style=display:flex><span>    plt<span style=color:#ff79c6>.</span>imshow(lenna_rebuild)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>show()
</span></span></code></pre></div><h1 id=lu分解>LU分解</h1><p><strong>LU分解(LU decomposition)<strong>是矩阵分解的一种，可以将一个矩阵分解为一个</strong>单位下三角矩阵</strong>和一个<strong>上三角矩阵</strong>的乘积(有时是它们和一个置换矩阵的乘积)。LU分解主要应用在数值分析中，用来解线性方程、求反矩阵或计算行列式。本质上，LU分解是<strong>高斯消元的一种表达方式</strong>。首先，对矩阵$A$通过初等行变换将其变为一个<strong>上三角矩阵</strong>；然后，将原始矩阵$A$变为上三角矩阵的过程，<strong>对应的变换矩阵为一个下三角矩阵</strong>。这中间的过程，就是<strong>Doolittle algorithm(杜尔里特算法)</strong>。</p><div align=center><img src=/Kimages/1/image-20200930222845239.png style=zoom:35%></div><p>在求解线性方程组$Ax=b$时，求解时间为$\frac{2}{3}n^3$。将矩阵$A$进行LU分解(复杂度$\frac{2}{3}n^3$)后，可以将线性方程组转换为$L y=b$和$U x=y$，二者的计算复杂度均为$n^2$，运算速度显著提升。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># numpy实现矩阵LU分解</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> numpy <span style=color:#ff79c6>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>lu_decomposition</span>(A):
</span></span><span style=display:flex><span>    n <span style=color:#ff79c6>=</span> <span style=color:#8be9fd;font-style:italic>len</span>(A[<span style=color:#bd93f9>0</span>])
</span></span><span style=display:flex><span>    L <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>zeros([n, n])
</span></span><span style=display:flex><span>    U <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>zeros([n, n])
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> i <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(n):
</span></span><span style=display:flex><span>        L[i][i] <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>1</span>
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>if</span> i <span style=color:#ff79c6>==</span> <span style=color:#bd93f9>0</span>:
</span></span><span style=display:flex><span>            U[<span style=color:#bd93f9>0</span>][<span style=color:#bd93f9>0</span>] <span style=color:#ff79c6>=</span> A[<span style=color:#bd93f9>0</span>][<span style=color:#bd93f9>0</span>]
</span></span><span style=display:flex><span>            <span style=color:#ff79c6>for</span> j <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(<span style=color:#bd93f9>1</span>, n):
</span></span><span style=display:flex><span>                U[<span style=color:#bd93f9>0</span>][j] <span style=color:#ff79c6>=</span> A[<span style=color:#bd93f9>0</span>][j]
</span></span><span style=display:flex><span>                L[j][<span style=color:#bd93f9>0</span>] <span style=color:#ff79c6>=</span> A[j][<span style=color:#bd93f9>0</span>] <span style=color:#ff79c6>/</span> U[<span style=color:#bd93f9>0</span>][<span style=color:#bd93f9>0</span>]
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>else</span>:
</span></span><span style=display:flex><span>            <span style=color:#ff79c6>for</span> j <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(i, n):  <span style=color:#6272a4># U</span>
</span></span><span style=display:flex><span>                temp <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>
</span></span><span style=display:flex><span>                <span style=color:#ff79c6>for</span> k <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(<span style=color:#bd93f9>0</span>, i):
</span></span><span style=display:flex><span>                    temp <span style=color:#ff79c6>=</span> temp <span style=color:#ff79c6>+</span> L[i][k] <span style=color:#ff79c6>*</span> U[k][j]
</span></span><span style=display:flex><span>                U[i][j] <span style=color:#ff79c6>=</span> A[i][j] <span style=color:#ff79c6>-</span> temp
</span></span><span style=display:flex><span>            <span style=color:#ff79c6>for</span> j <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(i <span style=color:#ff79c6>+</span> <span style=color:#bd93f9>1</span>, n):  <span style=color:#6272a4># L</span>
</span></span><span style=display:flex><span>                temp <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>
</span></span><span style=display:flex><span>                <span style=color:#ff79c6>for</span> k <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(<span style=color:#bd93f9>0</span>, i):
</span></span><span style=display:flex><span>                    temp <span style=color:#ff79c6>=</span> temp <span style=color:#ff79c6>+</span> L[j][k] <span style=color:#ff79c6>*</span> U[k][i]
</span></span><span style=display:flex><span>                L[j][i] <span style=color:#ff79c6>=</span> (A[j][i] <span style=color:#ff79c6>-</span> temp) <span style=color:#ff79c6>/</span> U[i][i]
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> L, U
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>A <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>array([[<span style=color:#bd93f9>4.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>],
</span></span><span style=display:flex><span>              [<span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#bd93f9>4.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>],
</span></span><span style=display:flex><span>              [<span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#bd93f9>4.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>],
</span></span><span style=display:flex><span>              [<span style=color:#bd93f9>0.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#bd93f9>4.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>],
</span></span><span style=display:flex><span>              [<span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#bd93f9>4.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#bd93f9>0.</span>],
</span></span><span style=display:flex><span>              [<span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#bd93f9>4.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>],
</span></span><span style=display:flex><span>              [<span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#bd93f9>4.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>],
</span></span><span style=display:flex><span>              [<span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#bd93f9>0.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1.</span>, <span style=color:#bd93f9>4.</span>]])
</span></span><span style=display:flex><span>L, U <span style=color:#ff79c6>=</span> lu_decomposition(A)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(L<span style=color:#ff79c6>.</span>tolist())
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(U<span style=color:#ff79c6>.</span>tolist())
</span></span></code></pre></div><h1 id=参考资料>参考资料</h1><ul><li><p>李航. 统计学习方法. 北京: 清华大学出版社, 2019.</p></li><li><p>周志华. 机器学习. 北京: 清华大学出版社, 2016.</p></li><li><p>邱锡鹏. 神经网络与深度学习. 北京: 机械工业出版社, 2020.</p></li><li><p>Stanford University机器学习课程：http://cs229.stanford.edu/</p></li><li><p>Numpy官方文档：https://numpy.org/doc/stable/index.html#</p></li></ul><hr><ul class=pager><li class=previous><a href=/post/2-math/math0-%E5%9F%BA%E7%A1%80%E7%BB%9F%E8%AE%A1%E5%AD%A6%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/ data-toggle=tooltip data-placement=top title=基础统计学名词解释>&larr;
Previous Post</a></li><li class=next><a href=/post/2-math/math2-%E5%BE%AE%E7%A7%AF%E5%88%86/ data-toggle=tooltip data-placement=top title=量化数学基础：微积分>Next
Post &rarr;</a></li></ul><script src=https://giscus.app/client.js data-repo=XiangdiWu/XiangdiWu.github.io data-repo-id=R_kgDOP0pDUQ data-category=Announcements data-category-id=DIC_kwDOP0pDUc4CvwjG data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=light data-lang=zh-CN crossorigin=anonymous async></script></div><div class="col-lg-2 col-lg-offset-0
visible-lg-block
sidebar-container
catalog-container"><div class=side-catalog><hr class="hidden-sm hidden-xs"><h5><a class=catalog-toggle href=#>CATALOG</a></h5><ul class=catalog-body></ul></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/deep-learning title="deep learning">deep learning
</a><a href=/tags/machine-learning title="machine learning">machine learning
</a><a href=/tags/math title=math>math
</a><a href=/tags/model title=model>model
</a><a href=/tags/nlp title=nlp>nlp
</a><a href=/tags/quant title=quant>quant</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href=https://www.factorwar.com/data/factor-models/>GetAstockFactors</a></li><li><a target=_blank href=https://datawhalechina.github.io/whale-quant/#/>Whale-Quant</a></li></ul></section></div></div></div></article><script type=module>  
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs'; 
    mermaid.initialize({ startOnLoad: true });  
</script><script>Array.from(document.getElementsByClassName("language-mermaid")).forEach(e=>{e.parentElement.outerHTML=`<div class="mermaid">${e.innerHTML}</div>`})</script><style>.mermaid svg{display:block;margin:auto}</style><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href=mailto:bernicewu2000@outlook.com><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/wechat_qrcode.jpg><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-weixin fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/xiangdiwu><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a href rel=alternate type=application/rss+xml title="Xiangdi Blog"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; Xiangdi Blog 2025</p></div></div></div></footer><script>function loadAsync(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(null,e)},!1),i.parentNode.insertBefore(n,i)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,a=$(_containerSelector),r=a.find("h1,h2,h3,h4,h5,h6");return $(e).html(""),r.each(function(){n=$(this).prop("tagName").toLowerCase(),o="#"+$(this).prop("id"),t=$(this).text(),i=$('<a href="'+o+'" rel="nofollow" title="'+t+'">'+t+"</a>"),s=$('<li class="'+n+'_nav"></li>').append(i),$(e).append(s)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script><style>.markmap>svg{width:100%;height:300px}</style><script>window.markmap={autoLoader:{manual:!0,onReady(){const{autoLoader:e,builtInPlugins:t}=window.markmap;e.transformPlugins=t.filter(e=>e.name!=="prism")}}}</script><script src=https://cdn.jsdelivr.net/npm/markmap-autoloader></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css integrity="sha512-r2+FkHzf1u0+SQbZOoIz2RxWOIWfdEzRuYybGjzKq18jG9zaSfEy9s3+jMqG/zPtRor/q4qaUCYQpmSjTw8M+g==" crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js integrity="sha512-INps9zQ2GUEMCQD7xiZQbGUVnqnzEvlynVy6eqcTcHN4+aQiLo9/uaQqckDpdJ8Zm3M0QBs+Pktg4pz0kEklUg==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/mhchem.min.js integrity="sha512-mxjNw/u1lIsFC09k/unscDRY3ofIYPVFbWkP8slrePcS36ht4d/OZ8rRu5yddB2uiqajhTcLD8+jupOWuYPebg==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js integrity="sha512-YJVxTjqttjsU3cSvaTRqsSl0wbRgZUNF+NGGCgto/MUbIvaLdXQzGTCQu4CvyJZbZctgflVB0PXw9LLmTWm5/w==" crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"},{display:!0,left:"\\[",right:"\\]"}],errorcolor:"#CD5C5C",throwonerror:!1})'></script></body></html>