<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="Xiangdi Blog"><meta property="og:type" content="article"><meta property="og:image" con ’tent=https://images.pexels.com/photos/267582/pexels-photo-267582.jpeg><meta property="twitter:image" content="https://images.pexels.com/photos/267582/pexels-photo-267582.jpeg"><meta name=title content="量化数学基础：概率统计"><meta property="og:title" content="量化数学基础：概率统计"><meta property="twitter:title" content="量化数学基础：概率统计"><meta name=description content="本文主要介绍概率统计的基本概念。"><meta property="og:description" content="本文主要介绍概率统计的基本概念。"><meta property="twitter:description" content="本文主要介绍概率统计的基本概念。"><meta property="twitter:card" content="summary"><meta property="og:url" content="https://xiangdiwu.github.io/post/2-math/math4-%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/"><meta name=keyword content="吴湘菂, WuXiangdi, XiangdiWu, 吴湘菂的网络日志, 吴湘菂的博客, Xiangdi Blog, 博客, 个人网站, Quant, 量化投资, 金融, 投资, 理财, 股票, 期货, 基金, 期权, 外汇, 比特币"><link rel="shortcut icon" href=/img/favicon.ico><title>量化数学基础：概率统计-吴湘菂的博客 | Xiangdi Blog</title><link rel=canonical href=/post/2-math/math4-%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=/css/zanshang.min.css><link rel=stylesheet href=/css/font-awesome.all.min.css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script><script src=/js/lazysizes.min.js></script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-R757MDJ6Y6"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-R757MDJ6Y6")}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"\\[",right:"\\]",display:!0},{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1})})</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type=text/javascript></script><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class=navbar-brand href=/>Xiangdi Blog</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>All Posts</a></li><li><a href=/categories/quant/>quant</a></li><li><a href=/categories/reading/>reading</a></li><li><a href=/categories/tech/>tech</a></li><li><a href=/archive//>ARCHIVE</a></li><li><a href=/vibe//>Vibe</a></li><li><a href=/travel//>TRAVEL</a></li><li><a href=/about//>ABOUT</a></li><li><a href=/search><i class="fa fa-search"></i></a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");$toggle.addEventListener("click",handleMagic);function handleMagic(){$navbar.className.indexOf("in")>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script><style type=text/css>header.intro-header{background-image:url(https://images.pexels.com/photos/267582/pexels-photo-267582.jpeg)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/quant title=Quant>Quant
</a><a class=tag href=/tags/math title=Math>Math</a></div><h1>量化数学基础：概率统计</h1><h2 class=subheading>Foundations of Quantitative Mathematics: Probability and Statistics</h2><span class=meta>Posted by
XiangdiWu
on
Saturday, September 26, 2020</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><h1 id=概率统计的基本概念>概率统计的基本概念</h1><h2 id=样本空间与随机事件>样本空间与随机事件</h2><p><strong>样本空间(sample space)<strong>是一个随机试验</strong>所有可能结果的集合</strong>。例如，如果抛一枚硬币，那么样本空间的集合就是{正面, 反面}；如果抛一个骰子，那么样本空间就是{1, 2, 3, 4, 5, 6}。随机试验中的每个可能结果称为<strong>样本点</strong>。</p><p>一般称试验$E$的样本空间$S$的子集为$E$的<strong>随机事件</strong>，简称事件。在每次试验中，当且仅当这一子集中的一个样本点出现时，称这一事件发生。</p><p>有些试验有<strong>两个或多个可能的样本空间</strong>。例如，从52张扑克牌中随机抽出一张，样本空间可以是数字(A到K)，也可以是花色(黑桃, 红桃, 梅花, 方块)。如果要完整地描述一张牌，就需要同时给出数字和花色，这时样本空间可以通过构建上述两个样本空间的<strong>笛卡儿乘积</strong>来得到。具体选用什么样的样本空间，由任务需求来决定。</p><h2 id=计数原理>计数原理</h2><p><strong>计数(counting)<strong>是样本空间的基本概念。计数的基本原理是</strong>加法原理(sum rule)<strong>和</strong>乘法原理(product rule)</strong>。加法原理指的是：做一件事情，完成它有$n$类方式，第一类方式有$m_1$种方法，第二类方式有$m_2$种方法，以此类推，第$n$类方式有$m_n$种方法，那么完成这件事情共有$m_1+m_2+\cdots+m_n$种方法。乘法原理指的是：做一件事，完成它需要分成$n$个步骤，做第一 步有$m_1$种不同的方法，做第二步有$m_2$种不同的方法，以此类推，做第$n$步有$m_n$种不同的方法。那么完成这件事共有$N=m_1 \times m_2 \times \cdots \times m_n$种不同的方法。</p><h2 id=排列与组合>排列与组合</h2><p>下图为<strong>排列(permutation)数</strong>、<strong>组合(combination)数</strong>以及将物体放入桶中问题的计算方法：</p><div align=center><img src=/Kimages/1/image-20200603225257471.png style=zoom:30%></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># scipy实现阶乘和组合数的计算</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> math
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> scipy <span style=color:#ff79c6>import</span> special
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> scipy <span style=color:#ff79c6>import</span> stats
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 计算阶乘</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(math<span style=color:#ff79c6>.</span>factorial(<span style=color:#bd93f9>20</span>))
</span></span><span style=display:flex><span><span style=color:#6272a4># 计算组合数</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(special<span style=color:#ff79c6>.</span>binom(<span style=color:#bd93f9>5</span>, <span style=color:#bd93f9>3</span>))
</span></span></code></pre></div><h2 id=概率的公理>概率的公理</h2><p>将事件$E$发生的概率定义为$P(E)$，全集为$S$，则概率$P(E)$满足如下三条公理：</p><p>(1) $0 \leqslant P(E) \leqslant 1$；</p><p>(2) $P(S)=1$；</p><p>(3) 若事件$E$和事件$F$无交集，即$(E \cap F=\varnothing)$，则$P(E \cup F)=P(E)+P(F)$。</p><h2 id=概率的推论>概率的推论</h2><p>设事件$E$的对立事件为$\bar E$，概率存在以下三个基本的推论：</p><p>(1) $P(\bar E)=1-P(E)$；</p><p>(2) 若$E \subseteq F$，则$P(E) \leqslant P(F)$；</p><p>(3) $P(E \cap F)=P(E)+P(F)-P(E \cup F)$。</p><h1 id=随机变量与概率分布>随机变量与概率分布</h1><h2 id=随机变量>随机变量</h2><p>在随机试验中，试验的结果可以用一个数$X$来表示，这个数$X$是随着试验结果而不断变化的，是<strong>定义在样本空间上的实值单值函数</strong>。我们把这种数称为<strong>随机变量(random variable)</strong>。例如，随机掷一个骰子，得到的点数就可以看成一个随机变量$X$，$X$的取值为$\{1, 2, 3, 4, 5, 6\}$。如果随机掷两个骰子，整个样本空间$\Omega$可以由36个元素组成：</p>$$
\Omega=\{(i,j)|i=1,\cdots,6;j=1,\cdots,6\}
$$<p>随机变量分为<strong>离散型随机变量</strong>和<strong>连续型随机变量</strong>。如果随机变量$X$所可能取的值为有限可列举的，有$n$个有限值，则称$X$为离散型随机变量。要了解$X$的统计规律，就必须知道它取每种可能值$x_i$的概率，即：</p>$$
P(X=x_i)=p(x_i), \ \ \forall i \in \{1,\cdots,n\}
$$<p>$p(x_1),\cdots,p(x_n)$称为离散型随机变量$X$的<strong>概率分布(probability distribution)</strong>，并且满足：</p>$$
\sum_{i=1}^{n}p(x_i)=1, \ \ \ \ \ \ p(x_i) \geqslant 0
$$<p>常见的离散型随机变量的概率分布有：</p><h3 id=伯努利分布bernoulli-distribution>伯努利分布(Bernoulli distribution)</h3><p>在一次试验中，事件A出现的概率为$\mu$，不出现的概率为$1-\mu$。若用变量$X$表示事件A出现的次数，则$X$的取值为0和1，其相应的分布为：$p(x)=\mu^x(1-\mu)^{1-x}$。伯努利分布又称<strong>两点分布</strong>或<strong>0-1分布</strong>。</p><h3 id=二项分布binomial-distribution>二项分布(binomial distribution)</h3><p>在$n$次伯努利试验中，若以变量$X$表示事件$A$出现的次数，则$X$的取值为$\{0,\cdots,n\}$，其相应的分布为二项分布：</p>$$
P(X=k)=\binom{n}{k}\mu^k(1-\mu)^{n-k}, \ \ k=1,\cdots,n
$$<p>一些随机变量$X$的取值是不可列举的，由全部实数或者由一部分区间组成。这种随机变量称为<strong>连续型随机变量</strong>。连续型随机变量的取值不可数的。对于连续型随机变量$X$，其取一个具体值$x_i$的<strong>概率为0</strong>，这和离散型随机变量截然不同。因此<strong>无法列举</strong>。连续型随机变量$X$的概率分布一般用<strong>概率密度函数(probability density function, PDF)</strong>$p(x)$进行描述。$p(x)$是可积函数，并满足：</p>$$
\int_{-\infty}^{+\infty} p(x) \text{d}x=1, \ \ \ \ \ \ \ p(x) \geqslant 0
$$<p>给定该利率密度函数$p(x)$，便可以计算出随机变量落入某一个区域的概率。令$\mathcal R$表示$x$的非常小的邻近区域，$|\mathcal R|$表示$\mathcal R$的大小，则$p(x)|\mathcal R|$可以反映随机变量处于区域$\mathcal R$的概率大小。</p><p>常见的连续型随机变量的概率分布有：</p><h3 id=均匀分布uniform-distribution>均匀分布(uniform distribution)</h3><p>若$a,b$为有限数，$[a,b]$上的均匀分布的概率密度函数定义为：</p>$$
p(x) =
\begin{cases}
\frac{1}{b - a}, & a \leq x \leq b \\
0, & \text{其他情况}
\end{cases}
$$<h3 id=正态分布normal-distribution>正态分布(normal distribution)</h3><p>正态分布，又名<strong>高斯分布(Gaussian distribution)</strong>，是自然界最常见的一种分布，并且具有很多良好的性质，在许多领域都有非常重要的影响力。其概率密度函数为：</p>$$p(x)=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right)$$<p>其中，$\delta>0$，$\mu$和$\delta$均为常数。若随机变量$X$服从一个参数为$\mu$和$\delta$的概率分布，则记为$X \sim \mathcal N(\mu,\sigma^2)$。当$\mu=0,\sigma=1$时，称为<strong>标准正态分布(standard normal distribution)</strong>。</p><p>下图展示了均匀分布和正态分布的概率密度函数：</p><div align=center><img src=/Kimages/1/image-20200525155242858.png style=zoom:35%></div><p>对于一个随机变量$X$，其<b>累积分布函数(cumulative distribution function, CDF)</b>是随机变量$X$的取值小于等于$x$的概率：$\text{cdf}(x)=P(X \leqslant x)$。以连续型随机变量$X$为例，累积分布函数定义为：</p>$$
\text{cdf}(x)=\int_{-\infty}^{x}p(t)\text{d}t
$$<p>其中，$p(t)$为概率密度函数。下图给出了标准正态分布的概率密度函数和累积分布函数：</p><div align=center><img src=/Kimages/1/image-20200525160426151.png style=zoom:30%></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#6272a4># 常用的离散型随机变量</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 二项分布</span>
</span></span><span style=display:flex><span>X <span style=color:#ff79c6>=</span> stats<span style=color:#ff79c6>.</span>binom(<span style=color:#bd93f9>10</span>, <span style=color:#bd93f9>0.2</span>)  <span style=color:#6272a4># Declare X to be a binomial random variable X~Bin(10, 0.2)</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X<span style=color:#ff79c6>.</span>pmf(<span style=color:#bd93f9>3</span>))  <span style=color:#6272a4># P(X = 3)</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X<span style=color:#ff79c6>.</span>cdf(<span style=color:#bd93f9>4</span>))  <span style=color:#6272a4># P(X &lt;= 4)</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X<span style=color:#ff79c6>.</span>mean())  <span style=color:#6272a4># E[X]</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X<span style=color:#ff79c6>.</span>var())  <span style=color:#6272a4># Var(X)</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X<span style=color:#ff79c6>.</span>std())  <span style=color:#6272a4># Std(X)</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X<span style=color:#ff79c6>.</span>rvs())  <span style=color:#6272a4># Get a random sample from X</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X<span style=color:#ff79c6>.</span>rvs(<span style=color:#bd93f9>10</span>))  <span style=color:#6272a4># Get 10 random samples form X</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 泊松分布</span>
</span></span><span style=display:flex><span>X <span style=color:#ff79c6>=</span> stats<span style=color:#ff79c6>.</span>poisson(<span style=color:#bd93f9>2</span>)  <span style=color:#6272a4># Declare X to be a poisson random variable</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X<span style=color:#ff79c6>.</span>pmf(<span style=color:#bd93f9>3</span>))  <span style=color:#6272a4># P(X = 3)</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X<span style=color:#ff79c6>.</span>rvs())  <span style=color:#6272a4># Get a random sample from X</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 几何分布</span>
</span></span><span style=display:flex><span>X <span style=color:#ff79c6>=</span> stats<span style=color:#ff79c6>.</span>geom(<span style=color:#bd93f9>0.75</span>)  <span style=color:#6272a4># Declare X to be a geometric random variable</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X<span style=color:#ff79c6>.</span>pmf(<span style=color:#bd93f9>3</span>))  <span style=color:#6272a4># P(X = 3)</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X<span style=color:#ff79c6>.</span>rvs())  <span style=color:#6272a4># Get a random sample from X</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 常用的连续型随机变量</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 正态分布</span>
</span></span><span style=display:flex><span>A <span style=color:#ff79c6>=</span> stats<span style=color:#ff79c6>.</span>norm(<span style=color:#bd93f9>3</span>, math<span style=color:#ff79c6>.</span>sqrt(<span style=color:#bd93f9>16</span>))  <span style=color:#6272a4># Declare A to be a normal random variable</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(A<span style=color:#ff79c6>.</span>pdf(<span style=color:#bd93f9>4</span>))  <span style=color:#6272a4># f(3), the probability density at 3</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(A<span style=color:#ff79c6>.</span>cdf(<span style=color:#bd93f9>2</span>))  <span style=color:#6272a4># F(2), which is also P(A &lt; 2)</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(A<span style=color:#ff79c6>.</span>rvs())  <span style=color:#6272a4># Get a random sample from A</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 指数分布</span>
</span></span><span style=display:flex><span>B <span style=color:#ff79c6>=</span> stats<span style=color:#ff79c6>.</span>expon(<span style=color:#bd93f9>4</span>)  <span style=color:#6272a4># Declare B to be a normal random variable</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(B<span style=color:#ff79c6>.</span>pdf(<span style=color:#bd93f9>1</span>))  <span style=color:#6272a4># f(1), the probability density at 1</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(B<span style=color:#ff79c6>.</span>cdf(<span style=color:#bd93f9>2</span>))  <span style=color:#6272a4># F(2) which is also P(B &lt; 2)</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(B<span style=color:#ff79c6>.</span>rvs())  <span style=color:#6272a4># Get a random sample from B</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># beta分布</span>
</span></span><span style=display:flex><span>X <span style=color:#ff79c6>=</span> stats<span style=color:#ff79c6>.</span>beta(<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>3</span>)  <span style=color:#6272a4># Declare X to be a beta random variable</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X<span style=color:#ff79c6>.</span>pdf(<span style=color:#bd93f9>0.5</span>))  <span style=color:#6272a4># f(0.5), the probability density at 1</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X<span style=color:#ff79c6>.</span>cdf(<span style=color:#bd93f9>0.7</span>))  <span style=color:#6272a4># F(0.7) which is also P(X &lt; 0.7)</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X<span style=color:#ff79c6>.</span>rvs())  <span style=color:#6272a4># Get a random sample from X</span>
</span></span></code></pre></div><h2 id=随机向量>随机向量</h2><p><strong>随机向量</strong>是指一组随机变量构成的向量。如果$X_1,X_2,\cdots,X_n$为$n$个随机变量，那么称$[X_1,X_2,\cdots,X_n]$为一个$n$维随机向量。一维随机向量称为随机变量。</p><p>随机向量也分为<strong>离散型随机向量</strong>和<strong>连续型随机向量</strong>。</p><p>离散型随机向量的<b>联合概率分布(joint probability distribution)</b>为：</p>$$
P(X_{1}=x_{1}, X_{2}=x_{2}, \cdots, X_{n}=x_{n})=p(x_{1}, x_{2}, \cdots, x_{n})
$$<p>其中$x_i \in \omega_i$为变量$X_i$的取值，$\omega_i$为变量$X_i$的样本空间。</p><p>一个常见的离散型随机向量的概率分布是<strong>多项分布(multinomial distribution)</strong>。多项分布式二项分布在随机向量的推广。假设一个袋子中装了很多球，总共有$K$种不同的颜色。从袋子中取出$n$个球，每次取出一个球时，就在袋子中放入一个同样颜色的球，这样保证同一颜色的球在不同试验中被取出的概率是相等的，相当于<strong>不放回抽样</strong>。令$\boldsymbol X$为一个$K$维的随机向量，每个元素$X_k(k=1,\cdots,K)$为取出的$n$个球中颜色为$k$的球的数量，则$X$服从多项分布，其概率分布为：</p>$$
p(x_{1}, \ldots, x_{K} | \boldsymbol{\mu})=\frac{n !}{x_{1} ! \cdots x_{K} !} \mu_{1}^{x_{1}} \cdots \mu_{K}^{x_{K}}
$$<p>其中$\boldsymbol \mu=[\mu_1,\cdots,\mu_K]^\text{T}$分别为每次抽取的球的颜色为$1,\cdots,K$的概率；$x_1,\cdots,x_K$为非负整数，其和为$n$。</p><p>多项分布的概率分布也可以用gamma函数表示：</p>$$
p(x_{1}, \cdots, x_{K} | \boldsymbol{\mu})=\frac{\Gamma(\sum_{k} x_{k}+1)}{\prod_{k} \Gamma(x_{k}+1)} \prod_{k=1}^{K} \mu_{k}^{x_{k}}
$$<p>其中$\Gamma(z)=\int_0^\infty \frac{t^{z-1}}{\exp(t)}\text{d}t$为gamma函数。这种表示形式和<strong>狄利克雷分布(Dirichlet distribution)<strong>类似，而</strong>狄利克雷分布可以作为多项分布的共轭先验</strong>。一个$n$维随机向量$\boldsymbol X$的狄利克雷分布为：</p>$$
p(\boldsymbol{x} | \boldsymbol{\alpha})=\frac{\Gamma(\alpha_{0})}{\Gamma(\alpha_{1}) \cdots \Gamma(\alpha_{n})} \prod_{i=1}^{n} x_{i}^{\alpha_{i}-1}
$$<p>其中$\boldsymbol \alpha=[\alpha_1,\cdots,\alpha_K]^\text T$为狄利克雷分布的参数。</p><p>连续型随机向量的联合概率密度函数满足：</p>$$
\begin{aligned}
p(\boldsymbol{x})=p(x_{1}, \cdots, x_{n}) \geq 0 \\
\int_{-\infty}^{+\infty} \cdots \int_{-\infty}^{+\infty} p(x_{1}, \cdots, x_{n}) d x_{1} \cdots d x_{n}=1
\end{aligned}
$$<p>一个常见的连续型随机向量分布为<strong>多元正态分布(multivariate normal distribution)</strong>，也称<strong>多元高斯分布</strong>。若$n$维向量$\boldsymbol X=[X_1,\cdots,X_n]^\text T$服从$n$元正态分布，其密度函数为：</p>$$
p(\boldsymbol{x})=\frac{1}{(2 \pi)^{n / 2}|\Sigma|^{1 / 2}} \exp \left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^{\mathrm{T}} \Sigma^{-1}(\boldsymbol{x}-\boldsymbol{\mu})\right)
$$<p>其中$\boldsymbol \mu$为多元正态分布的均值向量，$\Sigma$为多元正态分布的协方差矩阵，$|\Sigma|$表示$\Sigma$的行列式。如果一个多元高斯分布的协方差矩阵$\Sigma=\delta^2I$，即每一维随机变量都独立并且方差相同，那么这个高斯分布称为<strong>各向同性高斯分布</strong>。</p><h2 id=边际分布>边际分布</h2><p>对于<strong>二维离散型随机向量</strong>$(X,Y)$，假设$X$的取值空间为$\Omega_x$，$Y$的取值空间为$\Omega_y$。其联合概率分布满足：</p>$$
p(x, y) \geq 0, \quad \sum_{x \in \Omega_{x}} \sum_{y \in \Omega_{y}} p(x_{i}, y_{j})=1
$$<p>对于联合概率分布$p(x,y)$，我们可以分别对$x$和$y$进行求和：</p><p>(1) 对于固定的$x$，$\sum_{y \in \Omega_{y}} p(x, y)=P(X=x)=p(x)$；</p><p>(2) 对于固定的$y$，$\sum_{x \in \Omega_{x}} p(x, y)=P(Y=y)=p(y)$。</p><p>由离散型随机向量$(X,Y)$的联合概率分布，对$Y$的所有取值进行求和得到$X$的概率分布，而对$X$的所有取值进行求和得到$Y$的概率分布。这里的$p(x)$和$p(y)$称为$p(x,y)$的<strong>边际分布(marginal distribution)</strong>。</p><p>对于<strong>二维连续型随机向量</strong>$(X,Y)$，其边际分布为：</p>$$
p(x)=\int_{-\infty}^{+\infty} p(x, y) d y \\
p(y)=\int_{-\infty}^{+\infty} p(x, y) d x
$$<p>一个二元正态分布的边际分布仍为正态分布。</p><h2 id=条件概率分布>条件概率分布</h2><p>对于离散型随机向量$(X,Y)$，已知$X=x$的条件下，随机变量$Y=y$的<strong>条件概率(conditional probability)<strong>为：
$$
p(y | x)=P(Y=y | X=x)=\frac{p(x, y)}{p(x)}
$$
这个公式定义了随机变量$Y$关于随机变量$X$的</strong>条件概率分布</strong>，简称条件分布。</p><p>对于连续型随机向量$(X,Y)$，已知$X=x$的条件下，随机变量$Y=y$的<strong>条件概率密度函数</strong>为：</p>$$
p(y | x)=\frac{p(x, y)}{p(x)}
$$<p>同理，在已知$Y=y$的条件下，随机变量$X=x$的条件概率密度函数为：</p>$$
p(x | y)=\frac{p(x, y)}{p(y)}
$$<h2 id=贝叶斯定理>贝叶斯定理</h2><p><strong>贝叶斯定理(Bayes&rsquo; theorem)</strong> 或贝叶斯公式描述了两个条件概率$p(x|y)$和$p(y|x)$之间的关系：</p>$$
p(y | x)=\frac{p(x | y) p(y)}{p(x)}
$$<h2 id=独立与条件独立>独立与条件独立</h2><p>对于两个离散型(或连续型)随机变量$X$和$Y$，若其联合分布(或联合概率密度函数)$p(x,y)$满足$p(x,y)=p(x)p(y)$，则称$X$和$Y$相互独立(independent)，记为$X \perp Y$。对于三个离散型(或连续型)随机变量$X,Y,Z$，若琪条件概率(或联合条件概率密度函数)$p(x,y|z)$满足$p(x, y | z)=P(X=x, Y=y | Z=z)=p(x | z) p(y | z)$，则称在给定变量$Z$时，$X$和$Y$条件独立(conditional independent)，记为$X \perp Y | Z$。</p><h2 id=期望与方差>期望与方差</h2><p>对于离散型随机变量$X$，其概率分布为$p(x_1),p(x_2),\cdots,p(x_n)$，$X$的<strong>期望(expectation)</strong> 或均值定义为：</p>$$
\mathbb{E}[X]=\sum_{i=1}^{n} x_{i} p(x_{i})
$$<p>对于连续型随机变量$X$，其概率密度函数为$p(x)$，其期望定义为：</p>$$
\mathbb{E}[X]=\int_{\mathbb{R}} x p(x) d x
$$<p>随机变量$X$的<strong>方差(variance)</strong> 用来定义它的概率分布的离散程度，定义为：</p>$$
\operatorname{var}(X)=\mathbb{E}[(X-\mathbb{E}[X])^{2}]
$$<p>随机变量$X$的方差也称为它的二阶矩。$\sqrt{\text{var}(X)}$则称为$X$的根方差或<strong>标准差</strong>。</p><p>两个连续随机变量$X$和$Y$的<strong>协方差(covariance)</strong> 用来衡量两个随机变量的分布之间的总体变化性，定义为：</p>$$
\operatorname{cov}(X, Y)=\mathbb{E}[(X-\mathbb{E}[X])(Y-\mathbb{E}[Y])]
$$<p>协方差经常也用来衡量两个随机变量之间的<strong>线性相关性</strong>。如果两个随机变量的协方差为0，那么称这两个随机变量是<strong>线性不相关</strong>。 两个随机变量之间没有线性相关性，并非表示它们之间是独立的，可能存在某种非线性的函数关系。反之，如果$X$与$Y$是统计独立的，那么它们之间的<strong>协方差一定为0</strong>。</p><p>两个$m$维和$n$维的连续型随机向量$\boldsymbol X$和$\boldsymbol Y$，它们的协方差为$m \times n$的矩阵，定义为：</p>$$
\operatorname{cov}(\boldsymbol{X}, \boldsymbol{Y})=\mathbb{E}[(\boldsymbol{X}-\mathbb{E}[\boldsymbol{X}])(\boldsymbol{Y}-\mathbb{E}[\boldsymbol{Y}])^{\mathrm{T}}]
$$<p>协方差矩阵$\operatorname{cov}(\boldsymbol{X}, \boldsymbol{Y})$的第$(i,j)$个元素等于随机变量$X_i$和$Y_j$的协方差。两个随机向量的协方差矩阵$\operatorname{cov}(\boldsymbol{X}, \boldsymbol{Y})$和$\operatorname{cov}(\boldsymbol{Y}, \boldsymbol{X})$互为转置关系。如果两个随机向量的协方差矩阵为<strong>对角阵</strong>，那么称这两个随机向量是无关的。</p><p>单个随机向量$\boldsymbol X$的协方差矩阵定义为$\operatorname{cov}(\boldsymbol{X})=\operatorname{cov}(\boldsymbol{X}, \boldsymbol{X})$。</p><h2 id=jensen不等式>Jensen不等式</h2><p>如果$X$是随机变量，$g$是凸函数，则$g(\mathbb E[X]) \leqslant \mathbb E[g(X)]$。等式当且仅当$X$是一个常数或者$g$是线性时成立。这个性质被称为Jensen不等式。特别地，对于凸函数$g$定义域上的任意两点$x_1,x_2$以及一个标量$\lambda \in [0,1]$，有：</p>$$
g(\lambda x_{1}+(1-\lambda) x_{2}) \leqslant \lambda g(x_{1})+(1-\lambda) g(x_{2})
$$<p>即凸函数$g$上的<strong>任意两点的连线位</strong>于这两点之间<strong>函数曲线的上方</strong>。该性质在凸优化中有着重要作用。</p><h1 id=参数估计>参数估计</h1><p>所有概率分布都含有<strong>参数(parameter)</strong>，当参数未知时，通过已有数据来对参数进行估计，叫做<strong>参数估计</strong>任务。常见的分布以及其参数如下所示：</p><div align=center><img src=/Kimages/1/image-20200604173424521.png style=zoom:22%></div><p>参数估计对于人工智能领域起到重要的作用。<strong>许多机器学习算法的工作原理都是先定义一个含参数的概率模型，然后使用已有数据对模型参数进行学习</strong> 。<strong>极大似然估计(maximum likelihood estimation, MLE)</strong> 和 <strong>最大后验估计(maximum a posteriori, MAP)</strong> 是两种常用的参数估计方法。</p><h2 id=极大似然估计>极大似然估计</h2><p>MLE的思想是，<strong>选择使得观测数据出现可能性最大的参数</strong>$\theta$。假设数据为$X_1,\cdots,X_n$，并且满足独立同分布。<strong>所有数据的联合可能性(似然, likelihood)</strong> 可以写为：</p>$$
L(\theta)=\prod_{i=1}^{n} f(X_{i}|\theta)
$$<p>该函数是关于参数$\theta$的函数，记作似然函数。MLE的目标是寻找参数$\theta$，满足：</p>$$
\hat{\theta}=\underset{\theta}{\arg \max } L(\theta)
$$<p>为了方便计算，通常取对数似然函数：</p>$$
L L(\theta)=\log L(\theta)=\log \prod_{i=1}^{n} f(X_{i} | \theta)=\sum_{i=1}^{n} \log f(X_{i} | \theta)
$$<p>使用<strong>求导</strong>的方式，便可得到对数似然函数的极值，从而得到似然函数的极值。</p><h2 id=最大后验估计>最大后验估计</h2><p>MAP的思想是，在给定的数据下，选择<strong>可能性最大的参数值</strong>；而MLE是选择使<strong>数据可能性最大</strong>的参数值。给定独立同分布的随机变量$X_1,\cdots,X_n$，MAP的目标是：</p>$$
\begin{aligned}
\theta_{\mathrm{MAP}} &=\arg \max _{\theta} f(\theta | X_{1}, X_{2}, \ldots X_{n}) \\
&=\arg \max _{\theta} \frac{f(X_{1}, X_{2}, \ldots, X_{n} | \theta) g(\theta)}{h(X_{1}, X_{2}, \ldots X_{n})}
\end{aligned}
$$<p>其中，第一步到第二步的过渡利用了<strong>贝叶斯定理</strong>，函数$f,g,h$均为概率密度函数。接下来，首先由于数据是独立同分布的，其次上式中的分母与参数$\theta$无关，因此可以继续简化为：</p>$$
\begin{aligned}
\theta_{\mathrm{MAP}} &=\underset{\theta}{\arg \max } \frac{\prod_{i=1}^{n} f(X_{i} | \theta) g(\theta)}{h(X_{1}, X_{2}, \ldots X_{n})} \\
&=\underset{\theta}{\arg \max } \prod_{i=1}^{n} f(X_{i} | \theta) g(\theta)
\end{aligned}
$$<p>变为对数形式：</p>$$
\theta_{\mathrm{MAP}}=\underset{\theta}{\operatorname{argmax}}\left(\log (g(\theta))+\sum_{i=1}^{n} \log \left(f\left(X_{i} | \theta\right)\right)\right)
$$<p>可以看出，MAP所要最大化的目标是MLE中的<strong>似然函数</strong>与参数$\theta$的一个<strong>先验分布</strong>$g(\theta)$<strong>之和</strong>。</p><h1 id=参考资料>参考资料</h1><ul><li><p>邱锡鹏. 神经网络与深度学习. 北京: 机械工业出版社, 2020.</p></li><li><p>Stanford University概率统计课程：http://web.stanford.edu/class/cs109/</p></li></ul><hr><ul class=pager><li class=previous><a href=/post/2-math/math3-%E6%95%B0%E5%AD%A6%E4%BC%98%E5%8C%96/ data-toggle=tooltip data-placement=top title=量化数学基础：数学优化>&larr;
Previous Post</a></li><li class=next><a href=/post/2-math/math5-%E4%BF%A1%E6%81%AF%E8%AE%BA/ data-toggle=tooltip data-placement=top title=量化数学基础：信息论>Next
Post &rarr;</a></li></ul><script src=https://giscus.app/client.js data-repo=XiangdiWu/XiangdiWu.github.io data-repo-id=R_kgDOP0pDUQ data-category=Announcements data-category-id=DIC_kwDOP0pDUc4CvwjG data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=light data-lang=zh-CN crossorigin=anonymous async></script></div><div class="col-lg-2 col-lg-offset-0
visible-lg-block
sidebar-container
catalog-container"><div class=side-catalog><hr class="hidden-sm hidden-xs"><h5><a class=catalog-toggle href=#>CATALOG</a></h5><ul class=catalog-body></ul></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/deep-learning title="deep learning">deep learning
</a><a href=/tags/machine-learning title="machine learning">machine learning
</a><a href=/tags/math title=math>math
</a><a href=/tags/model title=model>model
</a><a href=/tags/nlp title=nlp>nlp
</a><a href=/tags/quant title=quant>quant</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href=https://www.factorwar.com/data/factor-models/>GetAstockFactors</a></li><li><a target=_blank href=https://datawhalechina.github.io/whale-quant/#/>Whale-Quant</a></li></ul></section></div></div></div></article><script type=module>  
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs'; 
    mermaid.initialize({ startOnLoad: true });  
</script><script>Array.from(document.getElementsByClassName("language-mermaid")).forEach(e=>{e.parentElement.outerHTML=`<div class="mermaid">${e.innerHTML}</div>`})</script><style>.mermaid svg{display:block;margin:auto}</style><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href=mailto:bernicewu2000@outlook.com><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/wechat_qrcode.jpg><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-weixin fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/xiangdiwu><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a href rel=alternate type=application/rss+xml title="Xiangdi Blog"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; Xiangdi Blog 2025</p></div></div></div></footer><script>function loadAsync(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(null,e)},!1),i.parentNode.insertBefore(n,i)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,a=$(_containerSelector),r=a.find("h1,h2,h3,h4,h5,h6");return $(e).html(""),r.each(function(){n=$(this).prop("tagName").toLowerCase(),o="#"+$(this).prop("id"),t=$(this).text(),i=$('<a href="'+o+'" rel="nofollow" title="'+t+'">'+t+"</a>"),s=$('<li class="'+n+'_nav"></li>').append(i),$(e).append(s)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script><style>.markmap>svg{width:100%;height:300px}</style><script>window.markmap={autoLoader:{manual:!0,onReady(){const{autoLoader:e,builtInPlugins:t}=window.markmap;e.transformPlugins=t.filter(e=>e.name!=="prism")}}}</script><script src=https://cdn.jsdelivr.net/npm/markmap-autoloader></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css integrity="sha512-r2+FkHzf1u0+SQbZOoIz2RxWOIWfdEzRuYybGjzKq18jG9zaSfEy9s3+jMqG/zPtRor/q4qaUCYQpmSjTw8M+g==" crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js integrity="sha512-INps9zQ2GUEMCQD7xiZQbGUVnqnzEvlynVy6eqcTcHN4+aQiLo9/uaQqckDpdJ8Zm3M0QBs+Pktg4pz0kEklUg==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/mhchem.min.js integrity="sha512-mxjNw/u1lIsFC09k/unscDRY3ofIYPVFbWkP8slrePcS36ht4d/OZ8rRu5yddB2uiqajhTcLD8+jupOWuYPebg==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js integrity="sha512-YJVxTjqttjsU3cSvaTRqsSl0wbRgZUNF+NGGCgto/MUbIvaLdXQzGTCQu4CvyJZbZctgflVB0PXw9LLmTWm5/w==" crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"},{display:!0,left:"\\[",right:"\\]"}],errorcolor:"#CD5C5C",throwonerror:!1})'></script></body></html>