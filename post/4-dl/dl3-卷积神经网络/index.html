<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="Xiangdi Blog"><meta property="og:type" content="article"><meta property="og:image" con ’tent=https://images.pexels.com/photos/220301/pexels-photo-220301.jpeg><meta property="twitter:image" content="https://images.pexels.com/photos/220301/pexels-photo-220301.jpeg"><meta name=title content="深度学习：卷积神经网络"><meta property="og:title" content="深度学习：卷积神经网络"><meta property="twitter:title" content="深度学习：卷积神经网络"><meta name=description content="本文主要介绍神经网络，包括神经网络的基本结构、激活函数、前馈神经网络、反向传播算法、卷积神经网络、循环神经网络、图神经网络等。"><meta property="og:description" content="本文主要介绍神经网络，包括神经网络的基本结构、激活函数、前馈神经网络、反向传播算法、卷积神经网络、循环神经网络、图神经网络等。"><meta property="twitter:description" content="本文主要介绍神经网络，包括神经网络的基本结构、激活函数、前馈神经网络、反向传播算法、卷积神经网络、循环神经网络、图神经网络等。"><meta property="twitter:card" content="summary"><meta property="og:url" content="https://xiangdiwu.github.io/post/4-dl/dl3-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><meta name=keyword content="吴湘菂, WuXiangdi, XiangdiWu, 吴湘菂的网络日志, 吴湘菂的博客, Xiangdi Blog, 博客, 个人网站, Quant, 量化投资, 金融, 投资, 理财, 股票, 期货, 基金, 期权, 外汇, 比特币"><link rel="shortcut icon" href=/img/favicon.ico><title>深度学习：卷积神经网络-吴湘菂的博客 | Xiangdi Blog</title><link rel=canonical href=/post/4-dl/dl3-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=/css/zanshang.min.css><link rel=stylesheet href=/css/font-awesome.all.min.css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script><script src=/js/lazysizes.min.js></script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-R757MDJ6Y6"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-R757MDJ6Y6")}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"\\[",right:"\\]",display:!0},{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1})})</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type=text/javascript></script><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class=navbar-brand href=/>Xiangdi Blog</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>All Posts</a></li><li><a href=/categories/quant/>quant</a></li><li><a href=/categories/reading/>reading</a></li><li><a href=/categories/tech/>tech</a></li><li><a href=/archive//>ARCHIVE</a></li><li><a href=/vibe//>Vibe</a></li><li><a href=/travel//>TRAVEL</a></li><li><a href=/about//>ABOUT</a></li><li><a href=/search><i class="fa fa-search"></i></a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");$toggle.addEventListener("click",handleMagic);function handleMagic(){$navbar.className.indexOf("in")>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script><style type=text/css>header.intro-header{background-image:url(https://images.pexels.com/photos/220301/pexels-photo-220301.jpeg)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/quant title=Quant>Quant
</a><a class=tag href=/tags/model title=Model>Model
</a><a class=tag href=/tags/deep-learning title="Deep Learning">Deep Learning</a></div><h1>深度学习：卷积神经网络</h1><h2 class=subheading>CNN-Convolutional Neural Network</h2><span class=meta>Posted by
XiangdiWu
on
Tuesday, October 13, 2020</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><p><strong>卷积神经网络(convolutional neural network, CNN)</strong> 是一种具有局部连接、权重共享等特性的前馈神经网络。</p><p>卷积神经网络最早是主要用来处理图像信息。在用全连接前馈网络来处理图像时，会存在参数太多、局部特征不变形等缺陷。卷积神经网络利用<strong>局部连接、权重共享以及汇聚</strong>三大结构上的特性，使得数据具有一定程度上的平移、缩放和旋转不变性。和前馈神经网络相比，卷积神经网络的参数更少。</p><p>卷积神经网络主要使用在图像和视频分析的各种任务(如图像分类、人脸识别、物体识别、图像分割等)上，其准确率一般也远远超出了其它的神经网络模型。近年来卷积神经网络也广泛地应用到自然语言处理、推荐系统等领域。</p><h1 id=卷积>卷积</h1><h2 id=一维卷积>一维卷积</h2><p><strong>卷积(convolution)</strong> 操作是分析数学中一种重要的运算，在信号处理或图像处理领域应用广泛。一维卷积经常用在信号处理中，用于计算信号的延迟累积。假设一个信号发生器每个时刻$t$产生一个信号$x_t$，其信息的衰减率为$w_k$，即在$k-1$个时间步长后，信息为原来的$w_k$倍。假设$w_1=1,w_2=1/2,w_3=1/4$，那么在时刻$t$收到的信号$y_t$为当前时刻产生的信息和以前时刻延迟信息的叠加，即：</p>$$
\begin{aligned}
y_{t} &=1 \times x_{t}+1 / 2 \times x_{t-1}+1 / 4 \times x_{t-2} \\
&=w_{1} \times x_{t}+w_{2} \times x_{t-1}+w_{3} \times x_{t-2} \\
&=\sum_{k=1}^{3} w_{k} \cdot x_{t-k+1}
\end{aligned}
$$<p>我们将$w_1,w_2,\cdots$称为<strong>滤波器(filter)<strong>或</strong>卷积核(convolution kernel)</strong>。假设滤波器长度为$m$，它和一个信号序列$x_1,x_2,\cdots$的卷积运算可以写为：</p>$$
y_{t}=\sum_{k=1}^{m} w_{k} \cdot x_{t-k+1}
$$<p>写作<strong>向量形式</strong>：$\boldsymbol{y}=\boldsymbol{w} \otimes \boldsymbol{x}$，其中$\otimes$表示卷积运算。当滤波器$w_k=1/m,1\leqslant k \leqslant m$时，卷积相当于信号序列的简单<strong>移动平均(moving average, MA)</strong>，窗口大小为$m$。</p><p>一般情况下滤波器的长度$m$远小于信号序列的长度$n$。下图为一维卷积的示意图：</p><div align=center><img src=/Kimages/3/image-20200508144946346.png style=zoom:30%></div><h2 id=二维卷积>二维卷积</h2><p>在图像处理中，将一维卷积进行拓展，可以得到二维卷积。给定一个图像$X \in \mathbb R^{M \times N}$和滤波器$W \in \mathbb R^{m \times n}$(一般滤波器的规模远小于图像的规模)，其卷积为：</p>$$
y_{i j}=\sum_{u=1}^{m} \sum_{v=1}^{n} w_{u v} \cdot x_{i-u+1, j-v+1}
$$<p>下图给出了二维卷积的示例：</p><div align=center><img src=/Kimages/3/image-20200508145402520.png style=zoom:30%></div><p><strong>均值滤波(mean filter)</strong> 就是当前位置的像素值设为滤波器窗口中所有像素的平均值，也就是$w_{uv}=1/mn$。</p><p>在图像处理中，卷积经常作为<strong>特征提取</strong>的有效方法。一幅图像在经过卷积操作后得到结果称为<strong>特征映射(feature map)</strong>。下图给出在图像处理中几种常用的滤波器，以及其对应的特征映射。图中最上面的滤波器是常用的<strong>高斯滤波器</strong>，可以用来对图像进行<strong>平滑去噪</strong>；中间和最下面的滤波器可以用来<strong>提取边缘特征</strong>。</p><div align=center><img src=/Kimages/3/image-20200508145648460.png style=zoom:50%></div><h2 id=互相关>互相关</h2><p>在机器学习和图像处理领域，卷积的主要功能是在一个图像(或某种特征)上滑动一个卷积核(即滤波器)，通过卷积操作<strong>得到一组新的特征</strong>。在计算卷积的过程中，需要进行<strong>卷积核翻转</strong>。翻转就是从两个维度(从上到下、从左到右)颠倒次序，即旋转180度。在具体实现上，一般会以<strong>互相关</strong>操作来代替卷积，从而会减少不必要的或开销。</p><p><strong>互相关(cross-correlation)</strong> 是一个衡量两个序列相关性的函数，通常是用滑动窗口的点积计算来实现。给定一个图像$X \in \mathbb R^{M \times N}$和滤波器$W \in \mathbb R^{m \times n}$，它们的互相关为：</p>$$
y_{i j}=\sum_{u=1}^{m} \sum_{v=1}^{n} w_{u v} \cdot x_{i+u-1, j+v-1}
$$<p>写作向量形式：$Y=W \otimes X$。可以看出，互相关和卷积的区别仅在于卷积核是否进行翻转。因此互相关也可称为不翻转卷积。在神经网络中使用卷积是为了进行特征抽取，<strong>卷积核是否进行翻转和其特征抽取的能力无关</strong>。特别是当卷积核是可学习的参数时，卷积和互相关是等价的。<strong>因此，为了实现上(或描述上)的方便起见，我们用互相关来代替卷积</strong>。事实上，<strong>很多深度学习工具中卷积操作其实都是互相关操作</strong>。</p><h2 id=卷积的变种>卷积的变种</h2><p>在卷积的标准定义基础上，还可以引入滤波器的<strong>滑动步长(stride)<strong>和</strong>零填充(padding)</strong> 来增加卷积的多样性：</p><div align=center><img src=/Kimages/3/image-20200508150317109.png style=zoom:40%></div><p>假设卷积层的输入神经元个数为$n$，卷积大小为$m$，步长为$s$，输入神经元两端各填补$p$个零，那么该卷积层的神经元数量为$(n-m+2p)/s+1$。根据输出与输入的大小对比，卷积可以分为<strong>宽卷积</strong>、<strong>窄卷积</strong>和<strong>等宽卷积</strong>。</p><h1 id=卷积神经网络>卷积神经网络</h1><h2 id=卷积层>卷积层</h2><p>卷积层有两个重要的概念：</p><p>(1) <strong>局部连接</strong>：在卷积层(假设是第$l$层)中的每一个神经元都只和下一层(第$l-1$层)中<strong>某个局部窗口内的神经元</strong>相连接，构成一个<strong>局部连接网络</strong>。卷积层和下一层之间的<strong>连接数大大减少</strong>，由原来的$n^{(l)} \times n^{(l-1)}$个连接变为$n^{(l)} \times m$个连接，$m$为<strong>滤波器大小</strong>。</p><p>(2) <strong>权重共享</strong>：可以看出，作为参数的滤波器$w^{(l)}$对于第$l$层的<strong>所有的神经元都是相同的</strong>。权重共享可以理解为<strong>一个滤波器只捕捉输入数据中的一种特定的局部特征</strong>。因此，<strong>如果要提取多种特征就需要使用多个不同的滤波器</strong>。</p><p>卷积层的作用是提取一个局部区域的特征，<strong>不同的卷积核相当于不同的特征提取器</strong>。由于卷积网络主要应用在图像处理上，而图像为两维结构，因此为了更充分地利用图像的局部信息，通常将神经元组织为<strong>三维结构的神经层</strong> ，其大小为$M \times N \times D$，由$D$(深度)个$M \times N$大小的特征映射构成。</p><p><strong>特征映射(feature map)<strong>为</strong>一幅图像(或其它特征映射)在经过卷积提取到的特征</strong>，每个特征映射可以作为一类抽取的图像特征。为了提高卷积网络的表示能力，可以<strong>在每一层使用多个不同的特征映射</strong>，以更好地表示图像的特征。<strong>在输入层，特征映射就是图像本身</strong>。如果是灰度图像，就是有一个特征映射，输入层的深度$D=1$；如果是彩色图像，分别有RGB三个颜色通道的特征映射，输入层的深度$D=3$。</p><p>不失一般性，假设一个卷积层的结构如下：</p><p>(1) <strong>输入特征映射组</strong>：$\boldsymbol{X} \in \mathbb{R}^{M \times N \times D}$为三维张量(tensor)，其中每个切片矩阵$X^{d} \in \mathbb{R}^{M \times N}$为一个输入特征映射。</p><p>(2) <strong>输出特征映射组</strong>：$\boldsymbol{Y} \in \mathbb{R}^{M^{\prime} \times N^{\prime} \times P}$为三维张量，其中每个切片矩阵$Y^p \in \mathbb{R}^{M^{\prime} \times N^{\prime}}$为一个输出特征映射。</p><p>(3) <strong>卷积核</strong>：$\boldsymbol{W} \in \mathbb{R}^{m \times n \times D \times P}$为四维张量，其中每个切片矩阵$W^{p, d} \in \mathbb{R}^{m \times n}$为一个二维卷积核。</p><p>下图为卷积层的三维结构表示：</p><div align=center><img src=/Kimages/3/image-20200608225322191.png style=zoom:40%></div><p>为了计算输出特征映射$Y^p$，用卷积核$W^{p, 1}, W^{p, 2}, \cdots, W^{p, D}$分别对输入特征映射$X^{1}, X^{2}, \cdots, X^{D}$进行卷积，然后将卷积结果相加，并加上一个标量偏置$b$得到卷积层的<strong>净输入(指没有经过非线性激活函数的净活性值)</strong>，再经过非线性激活函数后得到输出特征映射$Y^p$。</p>$$
\begin{array}{l}
Z^{p}=\boldsymbol{W}^{p} \otimes \boldsymbol{X}+b^{p}=\sum_{d=1}^{D} W^{p, d} \otimes X^{d}+b^{p} \\
Y^{p}=f(Z^{p})
\end{array}
$$<p>整个计算过程如下图所示：</p><img src=/Kimages/3/image-20200609215408985.png style=zoom:30%><p>如果希望卷积层输出$P$个特征映射，可以将上述计算机过程重复$P$次，得到$P$个输出特征映射。</p><h2 id=池化层>池化层</h2><p><strong>池化层(pooling layer)</strong> 也叫<strong>子采样层(subsampling layer)<strong>或</strong>汇聚层</strong>，其作用是<strong>进行特征选择，降低特征数量，从而减少参数数量</strong>。卷积层虽然可以显著减少网络中连接的数量，但<strong>特征映射组</strong>中的神经元个数并没有显著减少。如果后面接一个<strong>分类器</strong>，分类器的输入维数依然很高，很容易出现过拟合。为了解决这个问题，可以在卷积层之后加上一个汇聚层，从而降低特征维度，避免过拟合。</p><p>假设汇聚层的输入特征映射组为$\boldsymbol{X} \in \mathbb{R}^{M \times N \times D}$，对于其中每一个特征映射$X^p$，可以将其划分为很多个区域，这些区域可以重叠，也可以不重叠。池化操作对每个区域分别进行下采样，通常有最大池化和平均池化两种方式。其中，<strong>最大池化(max pooling)<strong>一般是取一个区域内所有神经元的最大值，而</strong>平均池化(mean pooling)</strong>：一般是取区域内所有神经元的平均值。下图为最大池化示意图：</p><img src=/Kimages/3/image-20200609220046921.png style=zoom:40%><p>典型的汇聚层是将每个特征映射划分为$2 \times 2$大小的不重叠区域，然后使用<strong>最大汇聚</strong>的方式进行下采样。汇聚层也可以看做是一个<strong>特殊的卷积层</strong>，卷积核大小为$m \times m$，步长为$s \times s$，卷积核为max函数或mean函数。过大的采样区域会急剧减少神经元的数量，也会造成<strong>过多的信息损失</strong>。</p><h1 id=参数学习>参数学习</h1><p>在卷积网络中，<strong>参数为卷积核中权重以及偏置</strong>。和全连接前馈网络类似，卷积网络也可以通过误差反向传播算法来进行参数学习。在全连接前馈神经网络中，梯度主要通过每一层的误差项$\delta$进行反向传播，并进一步计算每层参数的梯度。在卷积神经网络中，主要有两种不同功能的神经层：<strong>卷积层和汇聚层</strong>。而参数为卷积核以及偏置，因此<strong>只需要计算卷积层中参数的梯度</strong>。</p><p>不失一般性，对第$l$层为卷积层，第$l-1$层的输入特征映射为$\boldsymbol{X}^{(l-1)} \in \mathbb{R}^{M \times N \times D}$。通过卷积计算得到第$l$层的特征映射净输入$\boldsymbol{Z}^{(l)} \in \mathbb{R}^{M^{\prime} \times N^{\prime} \times P}$。第$l$层的第$p$个个特征映射净输入为：</p>$$
Z^{(l, p)}=\sum_{d=1}^{D} W^{(l, p, d)} \otimes X^{(l-1, d)}+b^{(l, p)}
$$<p>其中$W^{(l,p,d)}$和$b^{(l,p)}$分别为卷积核为偏置。第$l$层中共有$P \times D$个权重和$P$ 个偏置，可以分别使用链式法则来计算其梯度。根据计算，损失函数关于第$l$层的卷积核$W^{(l,p,d)}$的偏导数为：</p>$$
\begin{aligned}
\frac{\partial \mathcal{L}(Y, \hat{Y})}{\partial W^{(l, p, d)}} &=\frac{\partial \mathcal{L}(Y, \hat{Y})}{\partial Z^{(l, p)}} \otimes X^{(l-1, d)} \\
&=\delta^{(l, p)} \otimes X^{(l-1, d)}
\end{aligned}
$$<p>其中，$\delta^{(l, p)}=\frac{\partial \mathcal{L}(Y, \hat{Y})}{\partial Z^{(l, p)}}$为为损失函数关于第$l$层的第$p$个特征映射净输入$Z^{(l,p)}$的偏导数。同理可得，损失函数关于第$l$层的第$p$个偏置$b^{(l,p)}$的偏导数为：</p>$$
\frac{\partial \mathcal{L}(Y, \hat{Y})}{\partial b^{(l, p)}}=\sum_{i, j}[\delta^{(l, p)}]_{i, j}
$$<p>在卷积网络中，每层参数的梯度依赖其所在层的误差项$\delta^{(l,p)}$。卷积层和汇聚层中误差项的计算有所不同，因此我们分别计算其误差项。</p><p>(1) <strong>汇聚层</strong>的误差项</p><p>当第$l+1$层为汇聚层时，因为汇聚层是下采样操作，$l+1$层的每个神经元的误差项$\delta$对应于第$l$层的相应特征映射的一个区域。$l$层的第$p$个特征映射中的每个神经元都有一条边和$l+1$层的第$p$个特征映射中的一个神经元相连。根据链式法则，第$l$层的一个特征映射的误差项$\delta^{(l,p)}$，只需要将$l+1$层对应特征映射的误差项进行上采样操作(和第$\delta^{(l+1,p)}$层的大小一样)，再和$l$层特征映射的激活值偏导数逐元素相乘，就得到了$\delta^{(l,p)}$。</p><p>第$l$层的第$p$个特征映射的误差项$\delta^{(l,p)}$的具体推导过程如下：</p>$$
\begin{aligned}
\delta^{(l, p)} & \triangleq \frac{\partial \mathcal{L}(Y, \hat{Y})}{\partial Z^{(l, p)}} \\
&=\frac{\partial X^{(l, p)}}{\partial Z^{(l, p)}} \cdot \frac{\partial Z^{(l+1, p)}}{\partial X^{(l, p)}} \cdot \frac{\partial \mathcal{L}(Y, \hat{Y})}{\partial Z^{(l+1, p)}} \\
&=f_{l}^{\prime}(Z^{(l, p)}) \odot \operatorname{up}(\delta^{(l+1, p)})
\end{aligned}
$$<p>其中$f_{l}^{\prime}(\cdot)$为第$l$层使用的激活函数导数，$\text{up}$为<strong>上采样函数，与汇聚层中使用的下采样操作刚好相反</strong>。如果下采样是最大汇聚，误差项中每个$\delta^{(l+1,p)}$值会直接传递到上一层对应区域中的最大值所对应的神经元，该区域中其它神经元的误差项都设为0。如果下采样是平均汇聚，误差项$\delta^{(l+1,p)}$中每个值会被平均分配到上一层对应区域中的所有神经元上。</p><p>(2) <strong>卷积层</strong>的误差项</p><p>当第$l+1$层为卷积层时，假设特征映射净输入$\boldsymbol{Z}^{(l+1)} \in \mathbb{R}^{M^{\prime} \times N^{\prime} \times P}$，其中第$p(1 \leqslant p \leqslant P)$个特征映射净输入</p>$$
Z^{(l+1, p)}=\sum_{d=1}^{D} W^{(l+1, p, d)} \otimes X^{(l, d)}+b^{(l+1, p)}
$$<p>其中$W^{(l+1,p,d)}$和$b^{(l+1,p)}$为第$l+1$层的卷积核以及偏置。第$l+1$层中共有$P \times D$个卷积核和$P$个偏置。</p><p>第$l$层的第$d$个特征映射的误差项$δ^{(l,d)}$的具体推导过程如下：</p>$$
\begin{aligned}
\delta^{(l, d)} & \triangleq \frac{\partial \mathcal{L}(Y, \hat{Y})}{\partial Z^{(l, d)}} \\
&=\frac{\partial X^{(l, d)}}{\partial Z^{(l, d)}} \cdot \frac{\partial \mathcal{L}(Y, \hat{Y})}{\partial X^{(l, d)}} \\
&=f_{l}^{\prime}(Z^{(l)}) \odot \sum_{p=1}^{P}\left(\operatorname{rot} 180(W^{(l+1, p, d)}) \tilde{\otimes} \frac{\partial \mathcal{L}(Y, \hat{Y})}{\partial Z^{(l+1, p)}}\right) \\
&=f_{l}^{\prime}(Z^{(l)}) \odot \sum_{p=1}^{P}\left(\operatorname{rot} 180(W^{(l+1, p, d)}) \tilde{\otimes} \delta^{(l+1, p)}\right)
\end{aligned}
$$<p>其中，$\tilde{\otimes}$为宽卷积。</p><h1 id=几种常见的卷积神经网络>几种常见的卷积神经网络</h1><h2 id=lenet-5>LeNet-5</h2><img src=/Kimages/3/image-20200609223620244.png style=zoom:35%><h2 id=alexnet>AlexNet</h2><img src=/Kimages/3/image-20200609225341639.png style=zoom:35%><h2 id=inception网络>Inception网络</h2><p>在Inception网络中，一个卷积层包含多个<strong>不同大小的卷积操作</strong>，称为Inception模块。Inception网络是由有多个Inception模块和少量的汇聚层堆叠而成。Inception模块同时使用$1 \times 1, 3 \times 3, 5 \times 5$等不同大小的卷积核，并将得到的特征映射在深度上拼接(堆叠)起来作为输出特征映射。</p><img src=/Kimages/3/image-20200609224126448.png style=zoom:30%><p>Inception网络最早的v1版本就是非常著名的<strong>GoogLeNet</strong>，其赢得了2014年ImageNet图像分类竞赛的冠军。 Inception网络有多个改进版本，其中比较有代表性的有<strong>Inception v3</strong>网络。Inception v3网络用多层的小卷积核来替换大的卷积核，以减少计算量和参数量，并保持感受野不变。具体包括：(1) 使用两层3×3的卷积来替换v1中的5×5的卷积；(2) 使用连续的n×1和1×n来替换n×n的卷积。此外，Inception v3网络同时也引入了标签平滑以及批量归一化等优化方法进行训练。</p><h2 id=残差网络>残差网络</h2><p><strong>残差网络(residual network, ResNet)</strong> 是通过给非线性的卷积层增加直连边的方式来提高信息的传播效率。假设在一个深度网络中，我们期望一个非线性单元(可以为一层或多层的卷积层)$f(\boldsymbol x;\theta)$去逼近一个目标函数$h(\boldsymbol x)$。可以将目标函数拆分成两部分：<strong>恒等函数(identity function)</strong>$\boldsymbol x$和<strong>残差函数(residue function)</strong>$h(\boldsymbol x) - \boldsymbol x$：$h(\boldsymbol x) = \boldsymbol x + h(\boldsymbol x) - \boldsymbol x$。</p><p>根据通用近似定理，一个由神经网络构成的非线性单元有足够的能力来近似逼近原始目标函数或残差函数，但<strong>实际中后者更容易学习</strong>。因此，原来的优化问题可以转换为：让非线性单元$f(\boldsymbol x;\theta)$去近似残差函数$h(\boldsymbol x) - \boldsymbol x$，并用$f(\boldsymbol x;\theta) + \boldsymbol x$去逼近$h(\boldsymbol x)$。</p><p>下图给出了一个典型的残差单元示例。残差单元由多个级联的卷积层和一个跨层的直连边组成，再经过ReLU激活后得到输出。</p><img src=/Kimages/3/image-20211226220035949.png style=zoom:45%><p>残差网络就是将很多个残差单元串联起来构成的一个非常深的网络。和残差网络类似的还有<strong>Highway Network</strong>等。</p><h1 id=其他卷积方式>其他卷积方式</h1><h2 id=转置卷积>转置卷积</h2><p>我们一般可以通过卷积操作来实现<strong>高维特征到低维特征的转换</strong>。比如在一维卷积中，一个5维的输入特征，经过一个大小为3的卷积核，其输出为3维特征。如果设置步长大于1，可以进一步降低输出特征的维数。但在一些任务中，我们需要<strong>将低维特征映射到高维特征</strong>，并且依然希望通过卷积操作来实现。假设有一个高维向量$\boldsymbol x \in \mathbb R^d$和一个低维向量$\boldsymbol z \in \mathbb R^p$，其中$p < d$。如果使用仿射变换来实现高维到低维的映射$\boldsymbol z=W \boldsymbol x$，可以很容易地通过转置$W$来实现低维到高维的反向映射，即$\boldsymbol x=W^\text T \boldsymbol z$。</p><p>在<strong>全连接网络</strong>中，<strong>忽略激活函数</strong>，<strong>前向计算和反向传播就是一种转置关系</strong>。比如前向计算时，第$l+1$层的净输入为$\boldsymbol{z}^{(l+1)}=W^{(l+1)} \boldsymbol{z}^{(l)}$，反向传播时，第$l$层的误差项为$\delta^{(l)}=(W^{(l+1)})^\text T \delta^{(l+1)}$。</p><p>卷积操作也可以写为仿射变换的形式。假设一个5维向量$\boldsymbol x$，经过大小为3的卷积核$\boldsymbol w=[w_1,w_2,w_3]^\text T$进行卷积，得到三维向量$\boldsymbol z$，卷积操作可以写为：</p>$$
\begin{aligned}
\boldsymbol{z} &=\boldsymbol{w} \otimes \boldsymbol{x} \\
&=\left[\begin{array}{lllll}
w_{1} & w_{2} & w_{3} & 0 & 0 \\
0 & w_{1} & w_{2} & w_{3} & 0 \\
0 & 0 & w_{1} & w_{2} & w_{3}
\end{array}\right] \cdot \boldsymbol{x} \\
&=C \boldsymbol{x}
\end{aligned}
$$<p>其中$C$是一个稀疏矩阵，其非零元素来自于卷积核$\boldsymbol w$中的元素。如果要实现3维向量$\boldsymbol z$到5维向量$\boldsymbol x$的映射，可以通过仿射矩阵的转置来实现，即$\boldsymbol x=C^\text T \boldsymbol z=\operatorname{rot} 180(\boldsymbol{w}) \tilde{\oplus} \boldsymbol{z}$。</p><p>从仿射变换的角度来看，两个卷积操作$\boldsymbol{z}=\boldsymbol{w} \otimes \boldsymbol{x}$和$\boldsymbol{x}=\operatorname{rot} 180(\boldsymbol{w}) \tilde{\oplus} \boldsymbol{z}$也是形式上的转置关系。因此，我们将低维特征映射到高维特征的卷积操作称为<strong>转置卷积(transposed convolution)</strong>，也称为<strong>反卷积(deconvolution)</strong>。</p><p>在卷积网络中，卷积层的前向计算和反向传播也是一种转置关系。对一个$n$维的向量$\boldsymbol z$，和大小为$m$的卷积核，如果希望通过卷积操作来映射 到更高维的向量，只需要对向量$\boldsymbol z$进行两端补零$p=m-1$，然后进行卷积，可以得到$n+m-1$维的向量。</p><p>转置卷积同样适用于二维卷积。下图给出了一个步长$s=1$，无零填充$p=0$的二维卷积和其对应的转置卷积：</p><img src=/Kimages/3/image-20200715153438844.png style=zoom:30%><p>我们可以通过增加卷积操作的步长$s>1$来实现对输入特征的下采样操作，大幅降低特征维数。同样，我们也可以通过减少转置卷积的步长$s<1$来实现上采样操作，大幅提高特征维数。步长$s<1$的转置卷积也称为<strong>微步卷积(fractionally-strided convolution)</strong>。为了实现微步卷积，我们可以在输入特征之间插入0来间接地使得步长变小。</p><p>如果卷积操作的步长为$s>1$，希望其对应的转置卷积的步长为$\frac{1}{s}$，需要在输入特征之间插入$s-1$个0来使得其移动的速度变慢。</p><p>以一维转置卷积为例，对一个$n$维的向量$\boldsymbol z$，和大小为$m$的卷积核，通过对向量$\boldsymbol z$进行两端补零$p=m-1$，并且在每两个向量元素之间插入$d$个0，然后进行步长为1的卷积，可以得到$(d+1) \times (n-1)+m$维的向量。</p><p>下图给出了一个步长$s=2$，无零填充$p=0$的二维卷积和其对应的转置卷积：</p><img src=/Kimages/3/image-20200715154106926.png style=zoom:30%><h2 id=空洞卷积>空洞卷积</h2><p><strong>空洞卷积(atrous convolution)</strong> 是一种不增加参数数量，同时增加输出单元感受野的一种方法，也称为<strong>膨胀卷积(dilated convolution)</strong>。空洞卷积通过<strong>给卷积核插入“空洞”</strong> 来变相地增加其大小。下图为空洞卷积的示例：</p><img src=/Kimages/3/image-20200715154412178.png style=zoom:30%><h1 id=tensorflow实现卷积神经网络进行fashion-mnist衣物识别>Tensorflow实现卷积神经网络进行Fashion MNIST衣物识别</h1><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> tensorflow <span style=color:#ff79c6>as</span> tf
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(tf<span style=color:#ff79c6>.</span>__version__)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 下载Fashion MNIST数据并进行归一化</span>
</span></span><span style=display:flex><span>(X_train, y_train), (X_test, y_test) <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>datasets<span style=color:#ff79c6>.</span>fashion_mnist<span style=color:#ff79c6>.</span>load_data()
</span></span><span style=display:flex><span>X_train, X_test <span style=color:#ff79c6>=</span> X_train <span style=color:#ff79c6>/</span> <span style=color:#bd93f9>255.0</span>, X_test <span style=color:#ff79c6>/</span> <span style=color:#bd93f9>255.0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X_train<span style=color:#ff79c6>.</span>shape, X_test<span style=color:#ff79c6>.</span>shape, y_train<span style=color:#ff79c6>.</span>shape, y_test<span style=color:#ff79c6>.</span>shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>X_train <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>expand_dims(X_train, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1</span>)  <span style=color:#6272a4># 扩展通道这一维度</span>
</span></span><span style=display:flex><span>X_test <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>expand_dims(X_test, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1</span>)  <span style=color:#6272a4># 扩展通道这一维度</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(X_train<span style=color:#ff79c6>.</span>shape, X_test<span style=color:#ff79c6>.</span>shape, y_train<span style=color:#ff79c6>.</span>shape, y_test<span style=color:#ff79c6>.</span>shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 将数据转化为tf.data.Dataset类型</span>
</span></span><span style=display:flex><span>train_ds <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>data<span style=color:#ff79c6>.</span>Dataset<span style=color:#ff79c6>.</span>from_tensor_slices((X_train, y_train))<span style=color:#ff79c6>.</span>shuffle(<span style=color:#bd93f9>10000</span>)<span style=color:#ff79c6>.</span>batch(<span style=color:#bd93f9>64</span>)
</span></span><span style=display:flex><span>test_ds <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>data<span style=color:#ff79c6>.</span>Dataset<span style=color:#ff79c6>.</span>from_tensor_slices((X_test, y_test))<span style=color:#ff79c6>.</span>batch(<span style=color:#bd93f9>64</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>class</span> <span style=color:#50fa7b>ConvNeuralNetwork</span>(tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>Model):
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> <span style=color:#50fa7b>__init__</span>(<span style=font-style:italic>self</span>):
</span></span><span style=display:flex><span>        <span style=color:#8be9fd;font-style:italic>super</span>(ConvNeuralNetwork, <span style=font-style:italic>self</span>)<span style=color:#ff79c6>.</span><span style=color:#50fa7b>__init__</span>()
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>conv1 <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(<span style=color:#bd93f9>64</span>, (<span style=color:#bd93f9>5</span>, <span style=color:#bd93f9>5</span>), activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>)
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>pool1 <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>AveragePooling2D((<span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>2</span>))
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>conv2 <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(<span style=color:#bd93f9>128</span>, (<span style=color:#bd93f9>3</span>, <span style=color:#bd93f9>3</span>), activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>)
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>pool2 <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>AveragePooling2D((<span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>2</span>))
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>flatten <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Flatten()
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>dense1 <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Dense(<span style=color:#bd93f9>256</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>)
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>dense2 <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Dense(<span style=color:#bd93f9>10</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;softmax&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> <span style=color:#50fa7b>call</span>(<span style=font-style:italic>self</span>, x):
</span></span><span style=display:flex><span>        x_conv1 <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>conv1(x)
</span></span><span style=display:flex><span>        x_pool1 <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>pool1(x_conv1)
</span></span><span style=display:flex><span>        x_conv2 <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>conv2(x_pool1)
</span></span><span style=display:flex><span>        x_pool2 <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>pool2(x_conv2)
</span></span><span style=display:flex><span>        x_flatten <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>flatten(x_pool2)
</span></span><span style=display:flex><span>        x_dense1 <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>dense1(x_flatten)
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>return</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>dense2(x_dense1)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cnn_model <span style=color:#ff79c6>=</span> ConvNeuralNetwork()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 定义损失函数和优化器</span>
</span></span><span style=display:flex><span>loss_function <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>losses<span style=color:#ff79c6>.</span>SparseCategoricalCrossentropy()
</span></span><span style=display:flex><span>optimizer <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>optimizers<span style=color:#ff79c6>.</span>Adam()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 评价指标</span>
</span></span><span style=display:flex><span>train_loss <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>metrics<span style=color:#ff79c6>.</span>Mean(name<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;train_loss&#39;</span>)
</span></span><span style=display:flex><span>train_accuracy <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>metrics<span style=color:#ff79c6>.</span>SparseCategoricalAccuracy(name<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;train_accuracy&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>test_loss <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>metrics<span style=color:#ff79c6>.</span>Mean(name<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;test_loss&#39;</span>)
</span></span><span style=display:flex><span>test_accuracy <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>metrics<span style=color:#ff79c6>.</span>SparseCategoricalAccuracy(name<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;test_accuracy&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 定义训练步</span>
</span></span><span style=display:flex><span>@tf.function
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>train_step</span>(images, labels):
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>with</span> tf<span style=color:#ff79c6>.</span>GradientTape() <span style=color:#ff79c6>as</span> tape:
</span></span><span style=display:flex><span>        predictions <span style=color:#ff79c6>=</span> cnn_model(images)
</span></span><span style=display:flex><span>        loss <span style=color:#ff79c6>=</span> loss_function(labels, predictions)
</span></span><span style=display:flex><span>    gradients <span style=color:#ff79c6>=</span> tape<span style=color:#ff79c6>.</span>gradient(loss, cnn_model<span style=color:#ff79c6>.</span>trainable_variables)
</span></span><span style=display:flex><span>    optimizer<span style=color:#ff79c6>.</span>apply_gradients(<span style=color:#8be9fd;font-style:italic>zip</span>(gradients, cnn_model<span style=color:#ff79c6>.</span>trainable_variables))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    train_loss(loss)
</span></span><span style=display:flex><span>    train_accuracy(labels, predictions)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 定义测试步</span>
</span></span><span style=display:flex><span>@tf.function
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>test_step</span>(images, labels):
</span></span><span style=display:flex><span>    predictions <span style=color:#ff79c6>=</span> cnn_model(images)
</span></span><span style=display:flex><span>    loss <span style=color:#ff79c6>=</span> loss_function(labels, predictions)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    test_loss(loss)
</span></span><span style=display:flex><span>    test_accuracy(labels, predictions)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>EPOCHS <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>10</span>  <span style=color:#6272a4># 训练轮次</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>for</span> epoch <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(EPOCHS):
</span></span><span style=display:flex><span>    train_loss<span style=color:#ff79c6>.</span>reset_states()
</span></span><span style=display:flex><span>    train_accuracy<span style=color:#ff79c6>.</span>reset_states()
</span></span><span style=display:flex><span>    test_loss<span style=color:#ff79c6>.</span>reset_states()
</span></span><span style=display:flex><span>    test_accuracy<span style=color:#ff79c6>.</span>reset_states()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> images, labels <span style=color:#ff79c6>in</span> train_ds:
</span></span><span style=display:flex><span>        train_step(images, labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> test_images, test_labels <span style=color:#ff79c6>in</span> test_ds:
</span></span><span style=display:flex><span>        test_step(test_images, test_labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    template <span style=color:#ff79c6>=</span> <span style=color:#f1fa8c>&#39;Epoch </span><span style=color:#f1fa8c>{}</span><span style=color:#f1fa8c>, Loss: </span><span style=color:#f1fa8c>{}</span><span style=color:#f1fa8c>, Accuracy: </span><span style=color:#f1fa8c>{}</span><span style=color:#f1fa8c>, Test Loss: </span><span style=color:#f1fa8c>{}</span><span style=color:#f1fa8c>, Test Accuracy: </span><span style=color:#f1fa8c>{}</span><span style=color:#f1fa8c>&#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#8be9fd;font-style:italic>print</span>(template<span style=color:#ff79c6>.</span>format(epoch <span style=color:#ff79c6>+</span> <span style=color:#bd93f9>1</span>, train_loss<span style=color:#ff79c6>.</span>result(), train_accuracy<span style=color:#ff79c6>.</span>result() <span style=color:#ff79c6>*</span> <span style=color:#bd93f9>100</span>,
</span></span><span style=display:flex><span>                          test_loss<span style=color:#ff79c6>.</span>result(), test_accuracy<span style=color:#ff79c6>.</span>result() <span style=color:#ff79c6>*</span> <span style=color:#bd93f9>100</span>))
</span></span></code></pre></div><h1 id=pytorch实现卷积神经网络进行fashion-mnist衣物识别>Pytorch实现卷积神经网络进行Fashion MNIST衣物识别</h1><p>整体框架与全连接神经网络进行MNIST手写数字识别一致，仅在网络结构上进行修改：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>class</span> <span style=color:#50fa7b>Net</span>(nn<span style=color:#ff79c6>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> <span style=color:#50fa7b>__init__</span>(<span style=font-style:italic>self</span>):
</span></span><span style=display:flex><span>        <span style=color:#8be9fd;font-style:italic>super</span>(Net,<span style=font-style:italic>self</span>)<span style=color:#ff79c6>.</span><span style=color:#50fa7b>__init__</span>()  
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>conv1 <span style=color:#ff79c6>=</span> nn<span style=color:#ff79c6>.</span>Conv2d(<span style=color:#bd93f9>1</span>,<span style=color:#bd93f9>10</span>,kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>5</span>)     <span style=color:#6272a4>#灰度图像单通道</span>
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>conv2 <span style=color:#ff79c6>=</span> nn<span style=color:#ff79c6>.</span>Conv2d(<span style=color:#bd93f9>10</span>,<span style=color:#bd93f9>20</span>,kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>5</span>)
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>pooling <span style=color:#ff79c6>=</span> nn<span style=color:#ff79c6>.</span>MaxPool2d(<span style=color:#bd93f9>2</span>)     <span style=color:#6272a4>#kernel_size=2的最大池化</span>
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>fc1 <span style=color:#ff79c6>=</span> nn<span style=color:#ff79c6>.</span>Linear(<span style=color:#bd93f9>20</span><span style=color:#ff79c6>*</span><span style=color:#bd93f9>4</span><span style=color:#ff79c6>*</span><span style=color:#bd93f9>4</span>,<span style=color:#bd93f9>70</span>)
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>fc2 <span style=color:#ff79c6>=</span> nn<span style=color:#ff79c6>.</span>Linear(<span style=color:#bd93f9>70</span>,<span style=color:#bd93f9>10</span>)
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> <span style=color:#50fa7b>forward</span>(<span style=font-style:italic>self</span>,x):
</span></span><span style=display:flex><span>        batch_size <span style=color:#ff79c6>=</span> x<span style=color:#ff79c6>.</span>size(<span style=color:#bd93f9>0</span>)
</span></span><span style=display:flex><span>        x <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>pooling(F<span style=color:#ff79c6>.</span>relu(<span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>conv1(x)))
</span></span><span style=display:flex><span>        x <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>pooling(F<span style=color:#ff79c6>.</span>relu(<span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>conv2(x)))
</span></span><span style=display:flex><span>        x <span style=color:#ff79c6>=</span> x<span style=color:#ff79c6>.</span>view(batch_size,<span style=color:#ff79c6>-</span><span style=color:#bd93f9>1</span>)
</span></span><span style=display:flex><span>        x <span style=color:#ff79c6>=</span> F<span style=color:#ff79c6>.</span>relu(<span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>fc1(x))
</span></span><span style=display:flex><span>        x <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>fc2(x)
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>return</span> x
</span></span></code></pre></div><h1 id=参考资料>参考资料</h1><ul><li><p>邱锡鹏. 神经网络与深度学习. 北京: 机械工业出版社, 2020.</p></li><li><p>Khan A, Sohail A, Zahoora U, et al. A survey of the recent architectures of deep convolutional neural networks[J]. Artificial Intelligence Review, 2020, 53(8): 5455-5516.</p></li><li><p>卷积神经网络维基百科：https://en.wikipedia.org/wiki/Convolutional_neural_network</p></li><li><p>Pytorch实现手写数字识别（基于卷积神经网络）：https://blog.csdn.net/weixin_44851176/article/details/125902419?spm=1001.2014.3001.5502</p></li></ul><hr><ul class=pager><li class=previous><a href=/post/4-dl/dl2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/ data-toggle=tooltip data-placement=top title=深度学习：神经网络>&larr;
Previous Post</a></li><li class=next><a href=/post/4-dl/dl4-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/ data-toggle=tooltip data-placement=top title=深度学习：循环神经网络>Next
Post &rarr;</a></li></ul><script src=https://giscus.app/client.js data-repo=XiangdiWu/XiangdiWu.github.io data-repo-id=R_kgDOP0pDUQ data-category=Announcements data-category-id=DIC_kwDOP0pDUc4CvwjG data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=light data-lang=zh-CN crossorigin=anonymous async></script></div><div class="col-lg-2 col-lg-offset-0
visible-lg-block
sidebar-container
catalog-container"><div class=side-catalog><hr class="hidden-sm hidden-xs"><h5><a class=catalog-toggle href=#>CATALOG</a></h5><ul class=catalog-body></ul></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/deep-learning title="deep learning">deep learning
</a><a href=/tags/machine-learning title="machine learning">machine learning
</a><a href=/tags/math title=math>math
</a><a href=/tags/model title=model>model
</a><a href=/tags/nlp title=nlp>nlp
</a><a href=/tags/quant title=quant>quant</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href=https://www.factorwar.com/data/factor-models/>GetAstockFactors</a></li><li><a target=_blank href=https://datawhalechina.github.io/whale-quant/#/>Whale-Quant</a></li></ul></section></div></div></div></article><script type=module>  
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs'; 
    mermaid.initialize({ startOnLoad: true });  
</script><script>Array.from(document.getElementsByClassName("language-mermaid")).forEach(e=>{e.parentElement.outerHTML=`<div class="mermaid">${e.innerHTML}</div>`})</script><style>.mermaid svg{display:block;margin:auto}</style><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href=mailto:bernicewu2000@outlook.com><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/wechat_qrcode.jpg><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-weixin fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/xiangdiwu><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a href rel=alternate type=application/rss+xml title="Xiangdi Blog"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; Xiangdi Blog 2025</p></div></div></div></footer><script>function loadAsync(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(null,e)},!1),i.parentNode.insertBefore(n,i)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,a=$(_containerSelector),r=a.find("h1,h2,h3,h4,h5,h6");return $(e).html(""),r.each(function(){n=$(this).prop("tagName").toLowerCase(),o="#"+$(this).prop("id"),t=$(this).text(),i=$('<a href="'+o+'" rel="nofollow" title="'+t+'">'+t+"</a>"),s=$('<li class="'+n+'_nav"></li>').append(i),$(e).append(s)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script><style>.markmap>svg{width:100%;height:300px}</style><script>window.markmap={autoLoader:{manual:!0,onReady(){const{autoLoader:e,builtInPlugins:t}=window.markmap;e.transformPlugins=t.filter(e=>e.name!=="prism")}}}</script><script src=https://cdn.jsdelivr.net/npm/markmap-autoloader></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css integrity="sha512-r2+FkHzf1u0+SQbZOoIz2RxWOIWfdEzRuYybGjzKq18jG9zaSfEy9s3+jMqG/zPtRor/q4qaUCYQpmSjTw8M+g==" crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js integrity="sha512-INps9zQ2GUEMCQD7xiZQbGUVnqnzEvlynVy6eqcTcHN4+aQiLo9/uaQqckDpdJ8Zm3M0QBs+Pktg4pz0kEklUg==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/mhchem.min.js integrity="sha512-mxjNw/u1lIsFC09k/unscDRY3ofIYPVFbWkP8slrePcS36ht4d/OZ8rRu5yddB2uiqajhTcLD8+jupOWuYPebg==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js integrity="sha512-YJVxTjqttjsU3cSvaTRqsSl0wbRgZUNF+NGGCgto/MUbIvaLdXQzGTCQu4CvyJZbZctgflVB0PXw9LLmTWm5/w==" crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"},{display:!0,left:"\\[",right:"\\]"}],errorcolor:"#CD5C5C",throwonerror:!1})'></script></body></html>