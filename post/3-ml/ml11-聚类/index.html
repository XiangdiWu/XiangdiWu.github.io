<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="Xiangdi Blog"><meta property="og:type" content="article"><meta property="og:image" con ’tent=https://images.pexels.com/photos/220301/pexels-photo-220301.jpeg><meta property="twitter:image" content="https://images.pexels.com/photos/220301/pexels-photo-220301.jpeg"><meta name=title content="机器学习：聚类"><meta property="og:title" content="机器学习：聚类"><meta property="twitter:title" content="机器学习：聚类"><meta name=description content="本文主要介绍聚类，包括聚类的基本概念、聚类算法、聚类算法的拓展。"><meta property="og:description" content="本文主要介绍聚类，包括聚类的基本概念、聚类算法、聚类算法的拓展。"><meta property="twitter:description" content="本文主要介绍聚类，包括聚类的基本概念、聚类算法、聚类算法的拓展。"><meta property="twitter:card" content="summary"><meta property="og:url" content="https://xiangdiwu.github.io/post/3-ml/ml11-%E8%81%9A%E7%B1%BB/"><meta name=keyword content="吴湘菂, WuXiangdi, XiangdiWu, 吴湘菂的网络日志, 吴湘菂的博客, Xiangdi Blog, 博客, 个人网站, Quant, 量化投资, 金融, 投资, 理财, 股票, 期货, 基金, 期权, 外汇, 比特币"><link rel="shortcut icon" href=/img/favicon.ico><title>机器学习：聚类-吴湘菂的博客 | Xiangdi Blog</title><link rel=canonical href=/post/3-ml/ml11-%E8%81%9A%E7%B1%BB/><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=/css/zanshang.min.css><link rel=stylesheet href=/css/font-awesome.all.min.css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script><script src=/js/lazysizes.min.js></script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-R757MDJ6Y6"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-R757MDJ6Y6")}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"\\[",right:"\\]",display:!0},{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1})})</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type=text/javascript></script><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class=navbar-brand href=/>Xiangdi Blog</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>All Posts</a></li><li><a href=/categories/quant/>quant</a></li><li><a href=/categories/reading/>reading</a></li><li><a href=/categories/tech/>tech</a></li><li><a href=/archive//>ARCHIVE</a></li><li><a href=/vibe//>Vibe</a></li><li><a href=/travel//>TRAVEL</a></li><li><a href=/about//>ABOUT</a></li><li><a href=/search><i class="fa fa-search"></i></a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");$toggle.addEventListener("click",handleMagic);function handleMagic(){$navbar.className.indexOf("in")>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script><style type=text/css>header.intro-header{background-image:url(https://images.pexels.com/photos/220301/pexels-photo-220301.jpeg)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/quant title=Quant>Quant
</a><a class=tag href=/tags/model title=Model>Model
</a><a class=tag href=/tags/machine-learning title="Machine Learning">Machine Learning</a></div><h1>机器学习：聚类</h1><h2 class=subheading>Clustering</h2><span class=meta>Posted by
XiangdiWu
on
Wednesday, October 7, 2020</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><h1 id=聚类的基本概念>聚类的基本概念</h1><p>在<strong>无监督学习(unsupervised learning)</strong> 中，训练样本的标记信息是未知的，目标是通过对无标记样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础。聚类(clustering)任务是一种常见的无监督学习方法。</p><p>聚类试图将数据集中的样本划分为若干个不相交的子集，每个子集称为一个<strong>簇(cluster)</strong>。通过这样的划分，每个簇可能对应于一些<strong>潜在的概念(类别)</strong>。这些概念对聚类算法而言事先是未知的，聚类过程仅能自动形成簇结构，簇所对应的概念语义需由使用者来把握和命名。</p><p>聚类既能作为一个单独过程，用于寻找数据内在的分布结构，也可作为分类等其他学习任务的<strong>先驱过程</strong>。例如在一些商业应用中需对新用户的类型进行判别，但定义用户类型对商家来说却可能不太容易，此时往往可先对已有用户数据进行聚类，根据聚类结果<strong>将每个簇定义为一个类</strong>，然后再基于这些类训练分类模型，用于判别新用户的类型。</p><h2 id=相似度或距离>相似度或距离</h2><p>剧烈的核心概念是<strong>相似度(similarity)<strong>或</strong>距离(distance)</strong>。有多种相似度或距离的定义。因为相似度直接影响聚类的结果，所以其选择是聚类的根本问题。具体哪种相似度更合适取决于应用问题的特性。</p><p>(1) <strong>闵可夫斯基距离(Minkowski distance)</strong>：</p>$$
\operatorname{dist}_{m k}(x_{i}, x_{j})=(\sum_{u=1}^{n}|x_{i u}-x_{j u}|^{p})^{\frac{1}{p}}
$$<p>当$p=2$时，称为<strong>欧氏距离(Euclidean distance)</strong>；当$p=1$时称为曼哈顿距离(Manhattan distance)；当$p=\infty$时称为<strong>切比雪夫距离(Chebyshev distance)</strong>，即取各个坐标数值差的绝对值的最大值。</p><p>(2) <strong>马哈拉诺比斯距离(Mahalanobis distance)</strong>：简称马氏距离，也是一种常用的相似度，考虑各个分量(特征)之间的相关性并与各个分量的尺度无关。给定一个样本集合$X=(x_{ij})_{m \times n}$，其协方差矩阵记作$S$。样本$x_i$与样本$x_j$之间的马哈拉诺比斯距离$d_{ij}$定义为$d_{ij}=[(x_i-x_j)^{\text T}S^{-1}(x_i-x_j)]^{\frac{1}{2}}$。当$S$为单位矩阵时，即样本数据的各个分量相互独立且各个分量房差为1时，马氏距离等价于欧氏距离。因此马氏距离是欧氏距离的推广。</p><p>(3) 样本之间的相似性度量还有<strong>相关系数</strong>、<strong>夹角余弦</strong>等。</p><h2 id=类或簇>类或簇</h2><p>通过聚类得到的类或簇，本质是样本的子集。如果一个聚类方法假定一个样本只能属于一个类，那么该方法称为<strong>硬聚类(hard clustering)</strong> 方法；如果一个样本可以属于多个类，那么该方法称为<strong>软聚类(soft clustering)</strong> 方法。其中，硬聚类方法较为常用。用$G$表示类或簇，用$x_i,x_j$表示类中的样本，用$n_G$表示$G$中样本的个数，用$d_{ij}$表示样本$x_i$和$x_j$之间的距离。类或簇有多种定义：</p><p>(1) 设$T$为给定的正数，若集合$G$中任意两个样本$x_i$和$x_j$满足$d_{ij} \leqslant T$，则称$G$为一个类或簇。</p><p>(2) 设$T$为给定的正数，若对集合$G$中任一样本，必存在另一个样本$x_j$，使得$d_{ij} \leqslant T$，则称$G$为一个类或簇。</p><p>(3) 设$T$为给定的正数，若对集合$G$中任意一个样本$x_i$，$G$中的另一个样本$x_j$满足：</p>$$
\frac{1}{n_G-1}\sum_{x_i \in G} d_{ij} \leqslant T
$$<p>其中$n_G$为$G$中样本的个数，则称$G$为一个类或簇。</p><p>(4) 设$T$和$V$为给定的两个正数，如果集合$G$中任意两个样本$x_i,x_j$的距离$d_{ij}$满足：</p>$$
\frac{1}{n_G(n_G-1)}\sum_{x_i \in G} \sum_{x_j \in G}d_{ij} \leqslant T
$$<p>则称$G$为一个类或簇。以上四个定义中，第一个定义最为常用。类的特征可以通过不同角度来刻画，比如<strong>类的均值</strong>、<strong>类的直径(diameter, 任意两样本样本之间的最大距离)</strong>、类的样本散布矩阵以及协方差矩阵等。</p><h2 id=类与类之间的距离>类与类之间的距离</h2><p>类$G_p$与类$G_q$之间的距离$D(p,q)$，也称为<strong>连接(linkage)</strong>，有多重定义：</p><p>(1) <strong>最短距离或单连接</strong>：$D_{pq}=\min\{d_{ij}|x_i \in G_p,x_j \in G_q\}$，即两类样本间的最短距离。</p><p>(2) <strong>最长距离或完全连接</strong>：$D_{pq}=\max\{d_{ij}|x_i \in G_p,x_j \in G_q\}$，即两类样本间的最长距离。</p><p>(3) <strong>中心距离</strong>：$D_{pq}=d_{\bar x_p \bar x_q}$，即两个类中心之间的距离。</p><p>(4) <strong>平均距离</strong>：两类中任意两个样本之间距离的平均值。</p><h1 id=层次聚类>层次聚类</h1><p>层次聚类假设类别之间存在层次结构，将样本聚到层次化的类中。层次聚类又有<strong>聚合(agglomerative)</strong> 或<strong>自下而上(bottom-up)</strong> 聚类、<strong>分裂(divisive)</strong> 或<strong>自上而下(top-down)</strong> 聚类两种方法。因为每个样本只属于异类，所以层次聚类属于硬聚类。</p><p>聚合聚类开始将每个样本各自分到一个类；之后<strong>将相距最近的两类合并</strong>，建立一个新的类，重复此操作<strong>直到满足停止条件</strong>，得到层次化的类别。分裂聚类开始将所有样本分到一个类，之后<strong>将已有类中相距最远的样本分到两个新的类</strong>，重复此操作直到满足停止条件，得到层次化的类别。</p><p><strong>聚合聚类的具体算法步骤如下</strong>：</p><p>输入：$n$个样本组成的样本集合及样本之间的距离；</p><p>输出：对样本集合的一个层次化聚类。</p><p>(1) 计算$n$个样本两两之间的欧氏距离$d_{ij}$，记作矩阵$D=[d_{ij}]_{n \times n}$；</p><p>(2) 构造$n$个类，每个类只包含一个样本；</p><p>(3) 合并类间距离最小的两个类，构建一个新类；</p><p>(4) 计算新类与当前各类的距离。若类的个数为1，终止计算；否则，回到步骤(3)。</p><p>可以看出，聚合聚类算法的复杂度是$O(n^3m)$，其中$m$是样本特征数，$n$是样本个数。</p><h1 id=均值算法>$\boldsymbol k$均值算法</h1><p>$k$均值聚类是基于<strong>样本集合划分</strong>的聚类算法。$k$均值聚类将样本集合划分为$k$个子集，构成$k$个类，将$n$个样本分到$k$个类中，每个样本到其所属类的中心的距离最小。每个样本只能属于一个类，所以$k$均值为硬聚类算法。</p><div align=center><img src=/Kimages/2/image-20200527161106562.png style=zoom:40%></div><p>k-均值算法的步骤：</p><p>输入： $n$个样本的集合$X$；</p><p>输出：样本集合的聚类$C$。</p><p>(1) <strong>初始化</strong>。令$t=0$，随机选择$k$个样本点作为初始聚类中心$m^{(0)}=(m_1^{(0)},\cdots,m_l^{(0)},\cdots,m_k^{(0)})$。</p><p>(2) <strong>对样本进行聚类</strong>。对固定的类中心$m^{(t)}=(m_1^{(t)},\cdots,m_l^{(t)},\cdots,m_k^{(t)})$，其中$m_l^{(t)}$为类$G_l$的中心，计算每个样本到类中心的距离，将每个样本指派到于其最近的中心的类，构成聚类结果$C^{(t)}$。</p><p>(3) 计算<strong>新的类中心</strong>。对聚类结果$C^{(t)}$，计算当前各个类中的样本的均值，作为新的类中心$m^{(t+1)}=(m_1^{(t+1)},\cdots,m_l^{(t+1)},\cdots,m_k^{(t+1)})$。</p><p>(4) 如果迭代收敛或者符合停止条件，输出$C^{(t)}$。否则$t=t+1$，返回步骤(2)。</p><p>$k$均值算法的复杂度是$O(mnk)$，其中$m$是样本的特征数，$n$是样本个数，$k$是类别个数。</p><p>$k$均值算法有以下特性：</p><p>(1) <strong>总体特点</strong>：$k$均值算法是基于划分的聚类方法，类别数$k$事先指定，以欧氏距离平方表示样本之间的距离，以中心或样本的均值表示类别，<strong>以样本和其所属类的中心之间的距离的总和为最优化的目标函数</strong>，得到而类别是平坦的、非层次化的，算法是迭代算法，<strong>不能保证全局最优</strong>。</p><p>(2) <strong>收敛性</strong>：$k$均值聚类属于启发式算法，不能保证收敛到全局最优，初始中心的选择会直接影响聚类结果。</p><p>(3) <strong>类别数$\boldsymbol k$的选择</strong>：$k$均值聚类中的类别数$k$值需要预先指定，而在实际应用中最优的$k$值是不知道的。解决这个问题的一个方法是尝试用不同的$k$值聚类，检验各自得到聚类结果的质量，推测最优的$k$值。<strong>聚类结果的质量可以用类的平均直径来衡量</strong>。一般地，类别数变小时，平均直径会增加；类别数变大超过某个值以后，平均直径会不变乐然这个临界值正式最优的$k$值。该方法也称为肘部法则。</p><h1 id=聚类算法拓展>聚类算法拓展</h1><p>聚类算法的类别：</p><p>(1) <strong>原型聚类</strong>：此类算法假设聚类结构能通过一组原型刻画，在现实聚类任务中很常用。通常算法先对原型进行初始化，然后对原型进行迭代更新求解。包括<strong>k-均值算法(k-means)</strong>、学习向量量化(learning vector quantization, LVQ)、<strong>高斯混合聚类(mixture-of-gaussian)</strong> 等。</p><p>(2) <strong>密度聚类</strong>：此类算法假设聚类结构能通过样本分布的紧密程度确定。通常情况下，密度聚类算法从样本密度的角度考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇以获得最终的聚类结果。最著名的密度聚类算法为<strong>DBSCAN</strong>，它通过邻域参数来刻画样本分布的紧密程度。</p><p>(3) <strong>层次聚类</strong>：在不同层次上对数据集进行划分，从而形成树形的聚类结构。数据集的划分可采用自底向上或自顶向下的结合策略。最著名的层次聚类算法为AGNES。</p><p><strong>聚类集成(clustering ensemble)</strong> 通过对多个聚类学习器进行集成，能有效降低聚类假设与真实聚类结构不符、聚类过程中的随机性等因素带来的不利影响。<strong>异常检测(anomaly detection)</strong> 常借助聚类或距离计算进行，如将远离所有簇中心的样本作为异常点，或将密度极低处的样本作为异常点。</p><h1 id=基于numpy的k均值聚类算法实现>基于numpy的k均值聚类算法实现</h1><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> numpy <span style=color:#ff79c6>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 定义欧式距离</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>euclidean_distance</span>(x1, x2):
</span></span><span style=display:flex><span>    distance <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 距离的平方项再开根号</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> i <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(<span style=color:#8be9fd;font-style:italic>len</span>(x1)):
</span></span><span style=display:flex><span>        distance <span style=color:#ff79c6>+=</span> <span style=color:#8be9fd;font-style:italic>pow</span>((x1[i] <span style=color:#ff79c6>-</span> x2[i]), <span style=color:#bd93f9>2</span>)
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> np<span style=color:#ff79c6>.</span>sqrt(distance)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>X <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>array([[<span style=color:#bd93f9>0</span>,<span style=color:#bd93f9>2</span>],[<span style=color:#bd93f9>0</span>,<span style=color:#bd93f9>0</span>],[<span style=color:#bd93f9>1</span>,<span style=color:#bd93f9>0</span>],[<span style=color:#bd93f9>5</span>,<span style=color:#bd93f9>0</span>],[<span style=color:#bd93f9>5</span>,<span style=color:#bd93f9>2</span>]])
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(euclidean_distance(X[<span style=color:#bd93f9>0</span>], X[<span style=color:#bd93f9>4</span>]))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 定义中心初始化函数</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>centroids_init</span>(k, X):
</span></span><span style=display:flex><span>    m, n <span style=color:#ff79c6>=</span> X<span style=color:#ff79c6>.</span>shape
</span></span><span style=display:flex><span>    centroids <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>zeros((k, n))
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> i <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(k):
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 每一次循环随机选择一个类别中心</span>
</span></span><span style=display:flex><span>        centroid <span style=color:#ff79c6>=</span> X[np<span style=color:#ff79c6>.</span>random<span style=color:#ff79c6>.</span>choice(<span style=color:#8be9fd;font-style:italic>range</span>(m))]
</span></span><span style=display:flex><span>        centroids[i] <span style=color:#ff79c6>=</span> centroid
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> centroids
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 定义样本的最近质心点所属的类别索引</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>closest_centroid</span>(sample, centroids):
</span></span><span style=display:flex><span>    closest_i <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>
</span></span><span style=display:flex><span>    closest_dist <span style=color:#ff79c6>=</span> <span style=color:#8be9fd;font-style:italic>float</span>(<span style=color:#f1fa8c>&#39;inf&#39;</span>)
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> i, centroid <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>enumerate</span>(centroids):
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 根据欧式距离判断，选择最小距离的中心点所属类别</span>
</span></span><span style=display:flex><span>        distance <span style=color:#ff79c6>=</span> euclidean_distance(sample, centroid)
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>if</span> distance <span style=color:#ff79c6>&lt;</span> closest_dist:
</span></span><span style=display:flex><span>            closest_i <span style=color:#ff79c6>=</span> i
</span></span><span style=display:flex><span>            closest_dist <span style=color:#ff79c6>=</span> distance
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> closest_i
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 定义构建类别过程</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>build_clusters</span>(centroids, k, X):
</span></span><span style=display:flex><span>    clusters <span style=color:#ff79c6>=</span> [[] <span style=color:#ff79c6>for</span> _ <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(k)]
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> x_i, x <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>enumerate</span>(X):
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 将样本划分到最近的类别区域</span>
</span></span><span style=display:flex><span>        centroid_i <span style=color:#ff79c6>=</span> closest_centroid(x, centroids)
</span></span><span style=display:flex><span>        clusters[centroid_i]<span style=color:#ff79c6>.</span>append(x_i)
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> clusters
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 根据上一步聚类结果计算新的中心点</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>calculate_centroids</span>(clusters, k, X):
</span></span><span style=display:flex><span>    n <span style=color:#ff79c6>=</span> X<span style=color:#ff79c6>.</span>shape[<span style=color:#bd93f9>1</span>]
</span></span><span style=display:flex><span>    centroids <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>zeros((k, n))
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 以当前每个类样本的均值为新的中心点</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> i, cluster <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>enumerate</span>(clusters):
</span></span><span style=display:flex><span>        centroid <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>mean(X[cluster], axis<span style=color:#ff79c6>=</span><span style=color:#bd93f9>0</span>)
</span></span><span style=display:flex><span>        centroids[i] <span style=color:#ff79c6>=</span> centroid
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> centroids
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 获取每个样本所属的聚类类别</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>get_cluster_labels</span>(clusters, X):
</span></span><span style=display:flex><span>    y_pred <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>zeros(X<span style=color:#ff79c6>.</span>shape[<span style=color:#bd93f9>0</span>])
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> cluster_i, cluster <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>enumerate</span>(clusters):
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>for</span> X_i <span style=color:#ff79c6>in</span> cluster:
</span></span><span style=display:flex><span>            y_pred[X_i] <span style=color:#ff79c6>=</span> cluster_i
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> y_pred
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 根据上述各流程定义kmeans算法流程</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>kmeans</span>(X, k, max_iterations):
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 1.初始化中心点</span>
</span></span><span style=display:flex><span>    centroids <span style=color:#ff79c6>=</span> centroids_init(k, X)
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 遍历迭代求解</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> _ <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(max_iterations):
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 2.根据当前中心点进行聚类</span>
</span></span><span style=display:flex><span>        clusters <span style=color:#ff79c6>=</span> build_clusters(centroids, k, X)
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 保存当前中心点</span>
</span></span><span style=display:flex><span>        prev_centroids <span style=color:#ff79c6>=</span> centroids
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 3.根据聚类结果计算新的中心点</span>
</span></span><span style=display:flex><span>        centroids <span style=color:#ff79c6>=</span> calculate_centroids(clusters, k, X)
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 4.设定收敛条件为中心点是否发生变化</span>
</span></span><span style=display:flex><span>        diff <span style=color:#ff79c6>=</span> centroids <span style=color:#ff79c6>-</span> prev_centroids
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>if</span> <span style=color:#ff79c6>not</span> diff<span style=color:#ff79c6>.</span>any():
</span></span><span style=display:flex><span>            <span style=color:#ff79c6>break</span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 返回最终的聚类标签</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> get_cluster_labels(clusters, X)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 测试数据</span>
</span></span><span style=display:flex><span>X <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>array([[<span style=color:#bd93f9>0</span>, <span style=color:#bd93f9>2</span>], [<span style=color:#bd93f9>0</span>, <span style=color:#bd93f9>0</span>], [<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>0</span>], [<span style=color:#bd93f9>5</span>, <span style=color:#bd93f9>0</span>], [<span style=color:#bd93f9>5</span>, <span style=color:#bd93f9>2</span>]])
</span></span><span style=display:flex><span><span style=color:#6272a4># 设定聚类类别为2个，最大迭代次数为10次</span>
</span></span><span style=display:flex><span>labels <span style=color:#ff79c6>=</span> kmeans(X, <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>10</span>)
</span></span><span style=display:flex><span><span style=color:#6272a4># 打印每个样本所属的类别标签</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(labels)
</span></span></code></pre></div><h1 id=对比scikit-learn中不同的聚类算法并将聚类结果可视化>对比scikit-learn中不同的聚类算法并将聚类结果可视化</h1><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> time
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> warnings
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> numpy <span style=color:#ff79c6>as</span> np
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> matplotlib.pyplot <span style=color:#ff79c6>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> sklearn <span style=color:#ff79c6>import</span> cluster, datasets, mixture
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> sklearn.neighbors <span style=color:#ff79c6>import</span> kneighbors_graph
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> sklearn.preprocessing <span style=color:#ff79c6>import</span> StandardScaler
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> itertools <span style=color:#ff79c6>import</span> cycle, islice
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>np<span style=color:#ff79c6>.</span>random<span style=color:#ff79c6>.</span>seed(<span style=color:#bd93f9>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 生成数据集</span>
</span></span><span style=display:flex><span>n_samples <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>1500</span>
</span></span><span style=display:flex><span>noisy_circles <span style=color:#ff79c6>=</span> datasets<span style=color:#ff79c6>.</span>make_circles(n_samples<span style=color:#ff79c6>=</span>n_samples, factor<span style=color:#ff79c6>=</span><span style=color:#bd93f9>.5</span>,
</span></span><span style=display:flex><span>                                      noise<span style=color:#ff79c6>=</span><span style=color:#bd93f9>.05</span>)
</span></span><span style=display:flex><span>noisy_moons <span style=color:#ff79c6>=</span> datasets<span style=color:#ff79c6>.</span>make_moons(n_samples<span style=color:#ff79c6>=</span>n_samples, noise<span style=color:#ff79c6>=</span><span style=color:#bd93f9>.05</span>)
</span></span><span style=display:flex><span>blobs <span style=color:#ff79c6>=</span> datasets<span style=color:#ff79c6>.</span>make_blobs(n_samples<span style=color:#ff79c6>=</span>n_samples, random_state<span style=color:#ff79c6>=</span><span style=color:#bd93f9>8</span>)
</span></span><span style=display:flex><span>no_structure <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>random<span style=color:#ff79c6>.</span>rand(n_samples, <span style=color:#bd93f9>2</span>), <span style=color:#ff79c6>None</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>random_state <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>170</span>
</span></span><span style=display:flex><span>X, y <span style=color:#ff79c6>=</span> datasets<span style=color:#ff79c6>.</span>make_blobs(n_samples<span style=color:#ff79c6>=</span>n_samples, random_state<span style=color:#ff79c6>=</span>random_state)
</span></span><span style=display:flex><span>transformation <span style=color:#ff79c6>=</span> [[<span style=color:#bd93f9>0.6</span>, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>0.6</span>], [<span style=color:#ff79c6>-</span><span style=color:#bd93f9>0.4</span>, <span style=color:#bd93f9>0.8</span>]]
</span></span><span style=display:flex><span>X_aniso <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>dot(X, transformation)
</span></span><span style=display:flex><span>aniso <span style=color:#ff79c6>=</span> (X_aniso, y)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>varied <span style=color:#ff79c6>=</span> datasets<span style=color:#ff79c6>.</span>make_blobs(n_samples<span style=color:#ff79c6>=</span>n_samples,
</span></span><span style=display:flex><span>                             cluster_std<span style=color:#ff79c6>=</span>[<span style=color:#bd93f9>1.0</span>, <span style=color:#bd93f9>2.5</span>, <span style=color:#bd93f9>0.5</span>],
</span></span><span style=display:flex><span>                             random_state<span style=color:#ff79c6>=</span>random_state)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 设置聚类参数</span>
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>figure(figsize<span style=color:#ff79c6>=</span>(<span style=color:#bd93f9>9</span> <span style=color:#ff79c6>*</span> <span style=color:#bd93f9>2</span> <span style=color:#ff79c6>+</span> <span style=color:#bd93f9>3</span>, <span style=color:#bd93f9>12.5</span>))
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>subplots_adjust(left<span style=color:#ff79c6>=</span><span style=color:#bd93f9>.02</span>, right<span style=color:#ff79c6>=</span><span style=color:#bd93f9>.98</span>, bottom<span style=color:#ff79c6>=</span><span style=color:#bd93f9>.001</span>, top<span style=color:#ff79c6>=</span><span style=color:#bd93f9>.96</span>, wspace<span style=color:#ff79c6>=</span><span style=color:#bd93f9>.05</span>,
</span></span><span style=display:flex><span>                    hspace<span style=color:#ff79c6>=</span><span style=color:#bd93f9>.01</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plot_num <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>default_base <span style=color:#ff79c6>=</span> {<span style=color:#f1fa8c>&#39;quantile&#39;</span>: <span style=color:#bd93f9>.3</span>,
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#39;eps&#39;</span>: <span style=color:#bd93f9>.3</span>,
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#39;damping&#39;</span>: <span style=color:#bd93f9>.9</span>,
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#39;preference&#39;</span>: <span style=color:#ff79c6>-</span><span style=color:#bd93f9>200</span>,
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#39;n_neighbors&#39;</span>: <span style=color:#bd93f9>10</span>,
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#39;n_clusters&#39;</span>: <span style=color:#bd93f9>3</span>,
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#39;min_samples&#39;</span>: <span style=color:#bd93f9>20</span>,
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#39;xi&#39;</span>: <span style=color:#bd93f9>0.05</span>,
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#39;min_cluster_size&#39;</span>: <span style=color:#bd93f9>0.1</span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>datasets <span style=color:#ff79c6>=</span> [
</span></span><span style=display:flex><span>    (noisy_circles, {<span style=color:#f1fa8c>&#39;damping&#39;</span>: <span style=color:#bd93f9>.77</span>, <span style=color:#f1fa8c>&#39;preference&#39;</span>: <span style=color:#ff79c6>-</span><span style=color:#bd93f9>240</span>,
</span></span><span style=display:flex><span>                     <span style=color:#f1fa8c>&#39;quantile&#39;</span>: <span style=color:#bd93f9>.2</span>, <span style=color:#f1fa8c>&#39;n_clusters&#39;</span>: <span style=color:#bd93f9>2</span>,
</span></span><span style=display:flex><span>                     <span style=color:#f1fa8c>&#39;min_samples&#39;</span>: <span style=color:#bd93f9>20</span>, <span style=color:#f1fa8c>&#39;xi&#39;</span>: <span style=color:#bd93f9>0.25</span>}),
</span></span><span style=display:flex><span>    (noisy_moons, {<span style=color:#f1fa8c>&#39;damping&#39;</span>: <span style=color:#bd93f9>.75</span>, <span style=color:#f1fa8c>&#39;preference&#39;</span>: <span style=color:#ff79c6>-</span><span style=color:#bd93f9>220</span>, <span style=color:#f1fa8c>&#39;n_clusters&#39;</span>: <span style=color:#bd93f9>2</span>}),
</span></span><span style=display:flex><span>    (varied, {<span style=color:#f1fa8c>&#39;eps&#39;</span>: <span style=color:#bd93f9>.18</span>, <span style=color:#f1fa8c>&#39;n_neighbors&#39;</span>: <span style=color:#bd93f9>2</span>,
</span></span><span style=display:flex><span>              <span style=color:#f1fa8c>&#39;min_samples&#39;</span>: <span style=color:#bd93f9>5</span>, <span style=color:#f1fa8c>&#39;xi&#39;</span>: <span style=color:#bd93f9>0.035</span>, <span style=color:#f1fa8c>&#39;min_cluster_size&#39;</span>: <span style=color:#bd93f9>.2</span>}),
</span></span><span style=display:flex><span>    (aniso, {<span style=color:#f1fa8c>&#39;eps&#39;</span>: <span style=color:#bd93f9>.15</span>, <span style=color:#f1fa8c>&#39;n_neighbors&#39;</span>: <span style=color:#bd93f9>2</span>,
</span></span><span style=display:flex><span>             <span style=color:#f1fa8c>&#39;min_samples&#39;</span>: <span style=color:#bd93f9>20</span>, <span style=color:#f1fa8c>&#39;xi&#39;</span>: <span style=color:#bd93f9>0.1</span>, <span style=color:#f1fa8c>&#39;min_cluster_size&#39;</span>: <span style=color:#bd93f9>.2</span>}),
</span></span><span style=display:flex><span>    (blobs, {}),
</span></span><span style=display:flex><span>    (no_structure, {})]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>for</span> i_dataset, (dataset, algo_params) <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>enumerate</span>(datasets):
</span></span><span style=display:flex><span>    params <span style=color:#ff79c6>=</span> default_base<span style=color:#ff79c6>.</span>copy()
</span></span><span style=display:flex><span>    params<span style=color:#ff79c6>.</span>update(algo_params)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    X, y <span style=color:#ff79c6>=</span> dataset
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 数据标准归一化</span>
</span></span><span style=display:flex><span>    X <span style=color:#ff79c6>=</span> StandardScaler()<span style=color:#ff79c6>.</span>fit_transform(X)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    bandwidth <span style=color:#ff79c6>=</span> cluster<span style=color:#ff79c6>.</span>estimate_bandwidth(X, quantile<span style=color:#ff79c6>=</span>params[<span style=color:#f1fa8c>&#39;quantile&#39;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    connectivity <span style=color:#ff79c6>=</span> kneighbors_graph(
</span></span><span style=display:flex><span>        X, n_neighbors<span style=color:#ff79c6>=</span>params[<span style=color:#f1fa8c>&#39;n_neighbors&#39;</span>], include_self<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    connectivity <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0.5</span> <span style=color:#ff79c6>*</span> (connectivity <span style=color:#ff79c6>+</span> connectivity<span style=color:#ff79c6>.</span>T)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 创建聚类对象</span>
</span></span><span style=display:flex><span>    ms <span style=color:#ff79c6>=</span> cluster<span style=color:#ff79c6>.</span>MeanShift(bandwidth<span style=color:#ff79c6>=</span>bandwidth, bin_seeding<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>    two_means <span style=color:#ff79c6>=</span> cluster<span style=color:#ff79c6>.</span>MiniBatchKMeans(n_clusters<span style=color:#ff79c6>=</span>params[<span style=color:#f1fa8c>&#39;n_clusters&#39;</span>])
</span></span><span style=display:flex><span>    ward <span style=color:#ff79c6>=</span> cluster<span style=color:#ff79c6>.</span>AgglomerativeClustering(
</span></span><span style=display:flex><span>        n_clusters<span style=color:#ff79c6>=</span>params[<span style=color:#f1fa8c>&#39;n_clusters&#39;</span>], linkage<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;ward&#39;</span>,
</span></span><span style=display:flex><span>        connectivity<span style=color:#ff79c6>=</span>connectivity)
</span></span><span style=display:flex><span>    spectral <span style=color:#ff79c6>=</span> cluster<span style=color:#ff79c6>.</span>SpectralClustering(
</span></span><span style=display:flex><span>        n_clusters<span style=color:#ff79c6>=</span>params[<span style=color:#f1fa8c>&#39;n_clusters&#39;</span>], eigen_solver<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;arpack&#39;</span>,
</span></span><span style=display:flex><span>        affinity<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;nearest_neighbors&#34;</span>)
</span></span><span style=display:flex><span>    dbscan <span style=color:#ff79c6>=</span> cluster<span style=color:#ff79c6>.</span>DBSCAN(eps<span style=color:#ff79c6>=</span>params[<span style=color:#f1fa8c>&#39;eps&#39;</span>])
</span></span><span style=display:flex><span>    affinity_propagation <span style=color:#ff79c6>=</span> cluster<span style=color:#ff79c6>.</span>AffinityPropagation(
</span></span><span style=display:flex><span>        damping<span style=color:#ff79c6>=</span>params[<span style=color:#f1fa8c>&#39;damping&#39;</span>], preference<span style=color:#ff79c6>=</span>params[<span style=color:#f1fa8c>&#39;preference&#39;</span>])
</span></span><span style=display:flex><span>    average_linkage <span style=color:#ff79c6>=</span> cluster<span style=color:#ff79c6>.</span>AgglomerativeClustering(
</span></span><span style=display:flex><span>        linkage<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;average&#34;</span>, affinity<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;cityblock&#34;</span>,
</span></span><span style=display:flex><span>        n_clusters<span style=color:#ff79c6>=</span>params[<span style=color:#f1fa8c>&#39;n_clusters&#39;</span>], connectivity<span style=color:#ff79c6>=</span>connectivity)
</span></span><span style=display:flex><span>    birch <span style=color:#ff79c6>=</span> cluster<span style=color:#ff79c6>.</span>Birch(n_clusters<span style=color:#ff79c6>=</span>params[<span style=color:#f1fa8c>&#39;n_clusters&#39;</span>])
</span></span><span style=display:flex><span>    gmm <span style=color:#ff79c6>=</span> mixture<span style=color:#ff79c6>.</span>GaussianMixture(
</span></span><span style=display:flex><span>        n_components<span style=color:#ff79c6>=</span>params[<span style=color:#f1fa8c>&#39;n_clusters&#39;</span>], covariance_type<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;full&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    clustering_algorithms <span style=color:#ff79c6>=</span> (
</span></span><span style=display:flex><span>        (<span style=color:#f1fa8c>&#39;MiniBatchKMeans&#39;</span>, two_means),
</span></span><span style=display:flex><span>        (<span style=color:#f1fa8c>&#39;AffinityPropagation&#39;</span>, affinity_propagation),
</span></span><span style=display:flex><span>        (<span style=color:#f1fa8c>&#39;MeanShift&#39;</span>, ms),
</span></span><span style=display:flex><span>        (<span style=color:#f1fa8c>&#39;SpectralClustering&#39;</span>, spectral),
</span></span><span style=display:flex><span>        (<span style=color:#f1fa8c>&#39;Ward&#39;</span>, ward),
</span></span><span style=display:flex><span>        (<span style=color:#f1fa8c>&#39;AgglomerativeClustering&#39;</span>, average_linkage),
</span></span><span style=display:flex><span>        (<span style=color:#f1fa8c>&#39;DBSCAN&#39;</span>, dbscan),
</span></span><span style=display:flex><span>        (<span style=color:#f1fa8c>&#39;Birch&#39;</span>, birch),
</span></span><span style=display:flex><span>        (<span style=color:#f1fa8c>&#39;GaussianMixture&#39;</span>, gmm)
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> name, algorithm <span style=color:#ff79c6>in</span> clustering_algorithms:
</span></span><span style=display:flex><span>        t0 <span style=color:#ff79c6>=</span> time<span style=color:#ff79c6>.</span>time()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>with</span> warnings<span style=color:#ff79c6>.</span>catch_warnings():
</span></span><span style=display:flex><span>            warnings<span style=color:#ff79c6>.</span>filterwarnings(
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;ignore&#34;</span>,
</span></span><span style=display:flex><span>                message<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;the number of connected components of the &#34;</span> <span style=color:#ff79c6>+</span>
</span></span><span style=display:flex><span>                        <span style=color:#f1fa8c>&#34;connectivity matrix is [0-9]{1,2}&#34;</span> <span style=color:#ff79c6>+</span>
</span></span><span style=display:flex><span>                        <span style=color:#f1fa8c>&#34; &gt; 1. Completing it to avoid stopping the tree early.&#34;</span>,
</span></span><span style=display:flex><span>                category<span style=color:#ff79c6>=</span>UserWarning)
</span></span><span style=display:flex><span>            warnings<span style=color:#ff79c6>.</span>filterwarnings(
</span></span><span style=display:flex><span>                <span style=color:#f1fa8c>&#34;ignore&#34;</span>,
</span></span><span style=display:flex><span>                message<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;Graph is not fully connected, spectral embedding&#34;</span> <span style=color:#ff79c6>+</span>
</span></span><span style=display:flex><span>                        <span style=color:#f1fa8c>&#34; may not work as expected.&#34;</span>,
</span></span><span style=display:flex><span>                category<span style=color:#ff79c6>=</span>UserWarning)
</span></span><span style=display:flex><span>            algorithm<span style=color:#ff79c6>.</span>fit(X)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        t1 <span style=color:#ff79c6>=</span> time<span style=color:#ff79c6>.</span>time()
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>if</span> <span style=color:#8be9fd;font-style:italic>hasattr</span>(algorithm, <span style=color:#f1fa8c>&#39;labels_&#39;</span>):
</span></span><span style=display:flex><span>            y_pred <span style=color:#ff79c6>=</span> algorithm<span style=color:#ff79c6>.</span>labels_<span style=color:#ff79c6>.</span>astype(np<span style=color:#ff79c6>.</span>int)
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>else</span>:
</span></span><span style=display:flex><span>            y_pred <span style=color:#ff79c6>=</span> algorithm<span style=color:#ff79c6>.</span>predict(X)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        plt<span style=color:#ff79c6>.</span>subplot(<span style=color:#8be9fd;font-style:italic>len</span>(datasets), <span style=color:#8be9fd;font-style:italic>len</span>(clustering_algorithms), plot_num)
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>if</span> i_dataset <span style=color:#ff79c6>==</span> <span style=color:#bd93f9>0</span>:
</span></span><span style=display:flex><span>            plt<span style=color:#ff79c6>.</span>title(name, size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>18</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        colors <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>array(<span style=color:#8be9fd;font-style:italic>list</span>(islice(cycle([<span style=color:#f1fa8c>&#39;#377eb8&#39;</span>, <span style=color:#f1fa8c>&#39;#ff7f00&#39;</span>, <span style=color:#f1fa8c>&#39;#4daf4a&#39;</span>,
</span></span><span style=display:flex><span>                                             <span style=color:#f1fa8c>&#39;#f781bf&#39;</span>, <span style=color:#f1fa8c>&#39;#a65628&#39;</span>, <span style=color:#f1fa8c>&#39;#984ea3&#39;</span>,
</span></span><span style=display:flex><span>                                             <span style=color:#f1fa8c>&#39;#999999&#39;</span>, <span style=color:#f1fa8c>&#39;#e41a1c&#39;</span>, <span style=color:#f1fa8c>&#39;#dede00&#39;</span>]),
</span></span><span style=display:flex><span>                                      <span style=color:#8be9fd;font-style:italic>int</span>(<span style=color:#8be9fd;font-style:italic>max</span>(y_pred) <span style=color:#ff79c6>+</span> <span style=color:#bd93f9>1</span>))))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        colors <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>append(colors, [<span style=color:#f1fa8c>&#34;#000000&#34;</span>])
</span></span><span style=display:flex><span>        plt<span style=color:#ff79c6>.</span>scatter(X[:, <span style=color:#bd93f9>0</span>], X[:, <span style=color:#bd93f9>1</span>], s<span style=color:#ff79c6>=</span><span style=color:#bd93f9>10</span>, color<span style=color:#ff79c6>=</span>colors[y_pred])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        plt<span style=color:#ff79c6>.</span>xlim(<span style=color:#ff79c6>-</span><span style=color:#bd93f9>2.5</span>, <span style=color:#bd93f9>2.5</span>)
</span></span><span style=display:flex><span>        plt<span style=color:#ff79c6>.</span>ylim(<span style=color:#ff79c6>-</span><span style=color:#bd93f9>2.5</span>, <span style=color:#bd93f9>2.5</span>)
</span></span><span style=display:flex><span>        plt<span style=color:#ff79c6>.</span>xticks(())
</span></span><span style=display:flex><span>        plt<span style=color:#ff79c6>.</span>yticks(())
</span></span><span style=display:flex><span>        plt<span style=color:#ff79c6>.</span>text(<span style=color:#bd93f9>.99</span>, <span style=color:#bd93f9>.01</span>, (<span style=color:#f1fa8c>&#39;</span><span style=color:#f1fa8c>%.2f</span><span style=color:#f1fa8c>s&#39;</span> <span style=color:#ff79c6>%</span> (t1 <span style=color:#ff79c6>-</span> t0))<span style=color:#ff79c6>.</span>lstrip(<span style=color:#f1fa8c>&#39;0&#39;</span>), transform<span style=color:#ff79c6>=</span>plt<span style=color:#ff79c6>.</span>gca()<span style=color:#ff79c6>.</span>transAxes, size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>15</span>,
</span></span><span style=display:flex><span>                 horizontalalignment<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;right&#39;</span>)
</span></span><span style=display:flex><span>        plot_num <span style=color:#ff79c6>+=</span> <span style=color:#bd93f9>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>show()
</span></span></code></pre></div><h1 id=参考资料>参考资料</h1><ul><li>周志华. 机器学习. 北京: 清华大学出版社, 2016.</li><li>李航. 统计学习方法. 北京: 清华大学出版社, 2019.</li><li>鲁伟. 机器学习：公式推导与代码实现. 北京: 人民邮电出版社, 2022.</li><li>Stanford University机器学习笔记：https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-unsupervised-learning</li></ul><hr><ul class=pager><li class=previous><a href=/post/3-ml/ml12-%E9%99%8D%E7%BB%B4/ data-toggle=tooltip data-placement=top title=机器学习：降维>&larr;
Previous Post</a></li><li class=next><a href=/post/3-ml/ml13-%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/ data-toggle=tooltip data-placement=top title=机器学习：特征选择>Next
Post &rarr;</a></li></ul><script src=https://giscus.app/client.js data-repo=XiangdiWu/XiangdiWu.github.io data-repo-id=R_kgDOP0pDUQ data-category=Announcements data-category-id=DIC_kwDOP0pDUc4CvwjG data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=light data-lang=zh-CN crossorigin=anonymous async></script></div><div class="col-lg-2 col-lg-offset-0
visible-lg-block
sidebar-container
catalog-container"><div class=side-catalog><hr class="hidden-sm hidden-xs"><h5><a class=catalog-toggle href=#>CATALOG</a></h5><ul class=catalog-body></ul></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/deep-learning title="deep learning">deep learning
</a><a href=/tags/machine-learning title="machine learning">machine learning
</a><a href=/tags/math title=math>math
</a><a href=/tags/model title=model>model
</a><a href=/tags/nlp title=nlp>nlp
</a><a href=/tags/quant title=quant>quant</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href=https://www.factorwar.com/data/factor-models/>GetAstockFactors</a></li><li><a target=_blank href=https://datawhalechina.github.io/whale-quant/#/>Whale-Quant</a></li></ul></section></div></div></div></article><script type=module>  
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs'; 
    mermaid.initialize({ startOnLoad: true });  
</script><script>Array.from(document.getElementsByClassName("language-mermaid")).forEach(e=>{e.parentElement.outerHTML=`<div class="mermaid">${e.innerHTML}</div>`})</script><style>.mermaid svg{display:block;margin:auto}</style><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href=mailto:bernicewu2000@outlook.com><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/wechat_qrcode.jpg><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-weixin fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/xiangdiwu><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a href rel=alternate type=application/rss+xml title="Xiangdi Blog"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; Xiangdi Blog 2025</p></div></div></div></footer><script>function loadAsync(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(null,e)},!1),i.parentNode.insertBefore(n,i)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,a=$(_containerSelector),r=a.find("h1,h2,h3,h4,h5,h6");return $(e).html(""),r.each(function(){n=$(this).prop("tagName").toLowerCase(),o="#"+$(this).prop("id"),t=$(this).text(),i=$('<a href="'+o+'" rel="nofollow" title="'+t+'">'+t+"</a>"),s=$('<li class="'+n+'_nav"></li>').append(i),$(e).append(s)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script><style>.markmap>svg{width:100%;height:300px}</style><script>window.markmap={autoLoader:{manual:!0,onReady(){const{autoLoader:e,builtInPlugins:t}=window.markmap;e.transformPlugins=t.filter(e=>e.name!=="prism")}}}</script><script src=https://cdn.jsdelivr.net/npm/markmap-autoloader></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css integrity="sha512-r2+FkHzf1u0+SQbZOoIz2RxWOIWfdEzRuYybGjzKq18jG9zaSfEy9s3+jMqG/zPtRor/q4qaUCYQpmSjTw8M+g==" crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js integrity="sha512-INps9zQ2GUEMCQD7xiZQbGUVnqnzEvlynVy6eqcTcHN4+aQiLo9/uaQqckDpdJ8Zm3M0QBs+Pktg4pz0kEklUg==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/mhchem.min.js integrity="sha512-mxjNw/u1lIsFC09k/unscDRY3ofIYPVFbWkP8slrePcS36ht4d/OZ8rRu5yddB2uiqajhTcLD8+jupOWuYPebg==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js integrity="sha512-YJVxTjqttjsU3cSvaTRqsSl0wbRgZUNF+NGGCgto/MUbIvaLdXQzGTCQu4CvyJZbZctgflVB0PXw9LLmTWm5/w==" crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"},{display:!0,left:"\\[",right:"\\]"}],errorcolor:"#CD5C5C",throwonerror:!1})'></script></body></html>