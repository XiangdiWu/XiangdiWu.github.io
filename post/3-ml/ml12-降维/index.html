<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="Xiangdi Blog"><meta property="og:type" content="article"><meta property="og:image" con ’tent=https://images.pexels.com/photos/220301/pexels-photo-220301.jpeg><meta property="twitter:image" content="https://images.pexels.com/photos/220301/pexels-photo-220301.jpeg"><meta name=title content="机器学习：降维"><meta property="og:title" content="机器学习：降维"><meta property="twitter:title" content="机器学习：降维"><meta name=description content="本文主要介绍降维的相关算法，包括主成分分析、流形学习、t-SNE等。"><meta property="og:description" content="本文主要介绍降维的相关算法，包括主成分分析、流形学习、t-SNE等。"><meta property="twitter:description" content="本文主要介绍降维的相关算法，包括主成分分析、流形学习、t-SNE等。"><meta property="twitter:card" content="summary"><meta property="og:url" content="https://xiangdiwu.github.io/post/3-ml/ml12-%E9%99%8D%E7%BB%B4/"><meta name=keyword content="吴湘菂, WuXiangdi, XiangdiWu, 吴湘菂的网络日志, 吴湘菂的博客, Xiangdi Blog, 博客, 个人网站, Quant, 量化投资, 金融, 投资, 理财, 股票, 期货, 基金, 期权, 外汇, 比特币"><link rel="shortcut icon" href=/img/favicon.ico><title>机器学习：降维-吴湘菂的博客 | Xiangdi Blog</title><link rel=canonical href=/post/3-ml/ml12-%E9%99%8D%E7%BB%B4/><link rel=stylesheet href=/css/bootstrap.min.css><link rel=stylesheet href=/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=/css/zanshang.min.css><link rel=stylesheet href=/css/font-awesome.all.min.css><script src=/js/jquery.min.js></script><script src=/js/bootstrap.min.js></script><script src=/js/hux-blog.min.js></script><script src=/js/lazysizes.min.js></script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-R757MDJ6Y6"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-R757MDJ6Y6")}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"\\[",right:"\\]",display:!0},{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1})})</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type=text/javascript></script><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class=navbar-brand href=/>Xiangdi Blog</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>All Posts</a></li><li><a href=/categories/quant/>quant</a></li><li><a href=/categories/reading/>reading</a></li><li><a href=/categories/tech/>tech</a></li><li><a href=/archive//>ARCHIVE</a></li><li><a href=/vibe//>Vibe</a></li><li><a href=/travel//>TRAVEL</a></li><li><a href=/about//>ABOUT</a></li><li><a href=/search><i class="fa fa-search"></i></a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");$toggle.addEventListener("click",handleMagic);function handleMagic(){$navbar.className.indexOf("in")>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script><style type=text/css>header.intro-header{background-image:url(https://images.pexels.com/photos/220301/pexels-photo-220301.jpeg)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/quant title=Quant>Quant
</a><a class=tag href=/tags/model title=Model>Model
</a><a class=tag href=/tags/machine-learning title="Machine Learning">Machine Learning</a></div><h1>机器学习：降维</h1><h2 class=subheading>Dimensionality Reduction</h2><span class=meta>Posted by
XiangdiWu
on
Wednesday, October 7, 2020</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><h1 id=主成分分析>主成分分析</h1><p><strong>主成分分析(principal component analysis, PCA)</strong> 是一种最常用的数据降维方法，使得在转换后的空间中数据的方差最大。如下图所示的二维数据，如果将这些数据投影到一维空间，选择数据方差最大的方向进行投影(蓝轴)，才能最大化数据的差异性，保留更多的原始数据信息。</p><div align=center><img src=/Kimages/2/image-20200528202055368.png style=zoom:30%></div><p>假设有一组$d$维样本$\boldsymbol x^{(n)} \in \mathbb R^d, 1 \leqslant n \leqslant N$，我们希望将其投影到一维空间中，投影向量为$\boldsymbol w \in \mathbb R^d$。不失一般性，限制$\boldsymbol w$的模为1，即$\boldsymbol w^\text T \boldsymbol w=1$。每个样本点$\boldsymbol x^{(n)}$投影之后的表示为$z^{(n)}=\boldsymbol w^\text T \boldsymbol x^{(n)}$。</p><p>用矩阵$X=\left[\boldsymbol{x}^{(1)}, \boldsymbol{x}^{(2)}, \cdots, \boldsymbol{x}^{(N)}\right]$表示输入样本，$\bar{\boldsymbol{x}}=\frac{1}{N} \sum_{n=1}^{N} \boldsymbol{x}^{(n)}$为原始样本点的中心店，所有样本<strong>投影后的方差</strong>为：</p>$$
\begin{aligned}
\sigma(X ; \boldsymbol{w}) &=\frac{1}{N} \sum_{n=1}^{N}(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}^{(n)}-\boldsymbol{w}^{\mathrm{T}} \bar{\boldsymbol{x}})^{2} \\
&=\frac{1}{N}(\boldsymbol{w}^{\mathrm{T}} X-\boldsymbol{w}^{\mathrm{T}} \bar{X})(\boldsymbol{w}^{\mathrm{T}} X-\boldsymbol{w}^{\mathrm{T}} \bar{X})^{\mathrm{T}} \\
&=\boldsymbol{w}^{\mathrm{T}} \boldsymbol{S} \boldsymbol{w}
\end{aligned}
$$<p>其中，$\bar X=\bar{\boldsymbol x} \boldsymbol 1_d^\text T$为$d$列$\bar{\boldsymbol x}$组成的矩阵，$S=\frac{1}{N}(X-\bar{X})(X-\bar{X})^{\mathrm{T}}$是<strong>原始样本的协方差矩阵</strong>。</p><p>最大化投影方差$\sigma(X;\boldsymbol w)$，并满足$\boldsymbol w^\text T \boldsymbol w=1$，<strong>利用拉格朗日方法转换为无约束优化问题</strong>：</p>$$
\max _{\boldsymbol{w}} \boldsymbol{w}^{\mathrm{T}} S \boldsymbol{w}+\lambda(1-\boldsymbol{w}^{\mathrm{T}} \boldsymbol{w})
$$<p>其中$\lambda$为拉格朗日乘子。对上式求导并令导数为0，可得$S \boldsymbol{w}=\lambda \boldsymbol{w}$。</p><p>从上式可知，$\boldsymbol w$是协方差矩阵$S$的特征向量，$\lambda$为特征值。同时，$\sigma(X ; w)=\boldsymbol{w}^{\mathrm{T}} S \boldsymbol{w}=\boldsymbol{w}^{\mathrm{T}} \lambda \boldsymbol{w}=\lambda$。</p><p>$\lambda$也是投影后样本的方差。因此，主成分分析可以转换成一个矩阵特征值分解问题，投影向量$\boldsymbol w$为矩阵$S$的<strong>最大特征值对应的特征向量</strong>。</p><p>如果要通过投影矩阵$W \in R^{d \times d^{\prime}}$将样本投到$d^\prime$维空间，投影矩阵满足$W^\text T W=\boldsymbol I$，只需要将$S$的<strong>特征值从大到小排列</strong>，保留前$d^\prime$个特征值，<strong>其对应的特征向量即是最优的投影矩阵</strong>。</p><p>主成分分析是一种无监督学习方法，可以作为监督学习的数据预处理方法，用来<strong>去除噪声并减少特征之间的相关性</strong>，但是它<strong>不能保证投影后数据的类别可分性更好</strong>。提高两类可分性的方法一般为监督学习方法，比如<strong>线性判别分析(linear discriminant analysis, LDA)</strong>。</p><h1 id=基于numpy的主成分分析算法实现>基于numpy的主成分分析算法实现</h1><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> numpy <span style=color:#ff79c6>as</span> np
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> sklearn <span style=color:#ff79c6>import</span> datasets
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> matplotlib.pyplot <span style=color:#ff79c6>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>class</span> <span style=color:#50fa7b>PCA</span>():
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 计算协方差矩阵</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> <span style=color:#50fa7b>calc_cov</span>(<span style=font-style:italic>self</span>, X):
</span></span><span style=display:flex><span>        m <span style=color:#ff79c6>=</span> X<span style=color:#ff79c6>.</span>shape[<span style=color:#bd93f9>0</span>]
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 数据标准化</span>
</span></span><span style=display:flex><span>        X <span style=color:#ff79c6>=</span> (X <span style=color:#ff79c6>-</span> np<span style=color:#ff79c6>.</span>mean(X, axis<span style=color:#ff79c6>=</span><span style=color:#bd93f9>0</span>)) <span style=color:#ff79c6>/</span> np<span style=color:#ff79c6>.</span>var(X, axis<span style=color:#ff79c6>=</span><span style=color:#bd93f9>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>return</span> <span style=color:#bd93f9>1</span> <span style=color:#ff79c6>/</span> m <span style=color:#ff79c6>*</span> np<span style=color:#ff79c6>.</span>matmul(X<span style=color:#ff79c6>.</span>T, X)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> <span style=color:#50fa7b>pca</span>(<span style=font-style:italic>self</span>, X, n_components):
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 计算协方差矩阵</span>
</span></span><span style=display:flex><span>        cov_matrix <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>calc_cov(X)
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 计算协方差矩阵的特征值和对应特征向量</span>
</span></span><span style=display:flex><span>        eigenvalues, eigenvectors <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>linalg<span style=color:#ff79c6>.</span>eig(cov_matrix)
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 对特征值排序</span>
</span></span><span style=display:flex><span>        idx <span style=color:#ff79c6>=</span> eigenvalues<span style=color:#ff79c6>.</span>argsort()[::<span style=color:#ff79c6>-</span><span style=color:#bd93f9>1</span>]
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 取最大的前n_component组</span>
</span></span><span style=display:flex><span>        eigenvectors <span style=color:#ff79c6>=</span> eigenvectors[:, idx]
</span></span><span style=display:flex><span>        eigenvectors <span style=color:#ff79c6>=</span> eigenvectors[:, :n_components]
</span></span><span style=display:flex><span>        <span style=color:#6272a4># Y=PX转换</span>
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>return</span> np<span style=color:#ff79c6>.</span>matmul(X, eigenvectors)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 导入sklearn的鸢尾花数据集</span>
</span></span><span style=display:flex><span>iris <span style=color:#ff79c6>=</span> datasets<span style=color:#ff79c6>.</span>load_iris()
</span></span><span style=display:flex><span>X <span style=color:#ff79c6>=</span> iris<span style=color:#ff79c6>.</span>data
</span></span><span style=display:flex><span>y <span style=color:#ff79c6>=</span> iris<span style=color:#ff79c6>.</span>target
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 将数据降维到3个主成分</span>
</span></span><span style=display:flex><span>X_trans <span style=color:#ff79c6>=</span> PCA()<span style=color:#ff79c6>.</span>pca(X, <span style=color:#bd93f9>3</span>)
</span></span><span style=display:flex><span>colors <span style=color:#ff79c6>=</span> [<span style=color:#f1fa8c>&#39;navy&#39;</span>, <span style=color:#f1fa8c>&#39;turquoise&#39;</span>, <span style=color:#f1fa8c>&#39;darkorange&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 绘制不同类别</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>for</span> c, i, target_name <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>zip</span>(colors, [<span style=color:#bd93f9>0</span>, <span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>2</span>], iris<span style=color:#ff79c6>.</span>target_names):
</span></span><span style=display:flex><span>    plt<span style=color:#ff79c6>.</span>scatter(X_trans[y <span style=color:#ff79c6>==</span> i, <span style=color:#bd93f9>0</span>], X_trans[y <span style=color:#ff79c6>==</span> i, <span style=color:#bd93f9>1</span>],
</span></span><span style=display:flex><span>                color<span style=color:#ff79c6>=</span>c, lw<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>, label<span style=color:#ff79c6>=</span>target_name)
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>legend()
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>show()
</span></span></code></pre></div><h1 id=使用scikit-learn中的主成分分析算法对olivetti人脸数据集进行降维及特征脸的提取>使用scikit-learn中的主成分分析算法对Olivetti人脸数据集进行降维及特征脸的提取</h1><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> numpy <span style=color:#ff79c6>as</span> np
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> matplotlib.pyplot <span style=color:#ff79c6>as</span> plt
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> sklearn.datasets <span style=color:#ff79c6>import</span> fetch_olivetti_faces
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> sklearn.decomposition <span style=color:#ff79c6>import</span> PCA
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>dataset <span style=color:#ff79c6>=</span> fetch_olivetti_faces(shuffle<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>data <span style=color:#ff79c6>=</span> dataset[<span style=color:#f1fa8c>&#39;data&#39;</span>]
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(data<span style=color:#ff79c6>.</span>shape)  <span style=color:#6272a4># 原始数据的形状</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>pca <span style=color:#ff79c6>=</span> PCA(n_components<span style=color:#ff79c6>=</span><span style=color:#bd93f9>128</span>)
</span></span><span style=display:flex><span>pca<span style=color:#ff79c6>.</span>fit(data)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>subplot(<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>1</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>title(<span style=color:#f1fa8c>&#39;raw first figure&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>imshow(data[<span style=color:#bd93f9>0</span>]<span style=color:#ff79c6>.</span>reshape((<span style=color:#bd93f9>64</span>, <span style=color:#bd93f9>64</span>)))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data_pca <span style=color:#ff79c6>=</span> pca<span style=color:#ff79c6>.</span>transform(data)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(data_pca<span style=color:#ff79c6>.</span>shape)  <span style=color:#6272a4># 降维后数据的形状</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data_recover <span style=color:#ff79c6>=</span> pca<span style=color:#ff79c6>.</span>inverse_transform(data_pca)<span style=color:#ff79c6>.</span>reshape(<span style=color:#bd93f9>400</span>, <span style=color:#bd93f9>64</span>, <span style=color:#bd93f9>64</span>)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(data_recover<span style=color:#ff79c6>.</span>shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>subplot(<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>2</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>title(<span style=color:#f1fa8c>&#39;recovered first figure (n_components=128)&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>imshow(data_recover[<span style=color:#bd93f9>0</span>])
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>show()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 获取主成分，即特征脸</span>
</span></span><span style=display:flex><span>comp <span style=color:#ff79c6>=</span> pca<span style=color:#ff79c6>.</span>components_
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(comp<span style=color:#ff79c6>.</span>shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>for</span> i <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(<span style=color:#bd93f9>16</span>):
</span></span><span style=display:flex><span>    plt<span style=color:#ff79c6>.</span>subplot(<span style=color:#bd93f9>4</span>, <span style=color:#bd93f9>4</span>, i <span style=color:#ff79c6>+</span> <span style=color:#bd93f9>1</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#ff79c6>.</span>imshow(comp[i]<span style=color:#ff79c6>.</span>reshape((<span style=color:#bd93f9>64</span>, <span style=color:#bd93f9>64</span>)))
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>show()
</span></span></code></pre></div><h1 id=流形学习>流形学习</h1><p><strong>欧几里得空间(Euclidean space)</strong> 也称为平直空间。基础物理、数学都是建立在欧氏空间基础上的。在欧氏空间中，0维的欧几里得空间是一个点；1维的欧几里得空间是一条线；2维的欧几里得空间是一个平面；3维的欧几里得空间是立体空间，它们都满足两点间的最短距离是一条直线。基于欧氏空间的几何学称为欧几里得几何。</p><p>欧几里得几何的局限性：它不能包含两点间最短距离是曲线的情况，如球面上的两点间最短距离。故对于更加宏观的航海、天体物理等研究而言，通过欧几里得空间来研究它们是不适合的。由此引入了<strong>黎曼几何</strong>，而黎曼几何研究的对象就是<strong>流形(manifold)</strong>。</p><p>流形整体而言是“扭曲的”，然而其局部又类似于欧几里得空间。因此，我们可以利用欧几里得几何里已知的方法去研究流形的局部。然后再将这些局部信息拼接起来，以达到研究流形的目的。这和微分的思想很像：直接计算一条曲线的长度比较难，那我将其切分成若干小段，每段近似于一条直线，这些直线的长度相加的总和就是这条曲线的长度。</p><img src=Kimages\image-20211226191024009.png style=zoom:50%><p><strong>流形学习(manifold learing)</strong> 是机器学习、模式识别中的一种方法，在维数约简方面具有广泛的应用。它的主要思想是将高维的数据映射到低维，使该低维的数据能够反映原高维数据的某些本质结构特征。流形学习的前提是有一种假设，即<strong>某些高维数据，实际是一种低维的流形结构嵌入在高维空间中</strong>。流形学习的目的是将其映射回低维空间中，揭示其本质。</p><p>通过流形学习来实现降维的方法有很多，其基本思想也类似：假设数据在高维具有某种结构特征，希望降到低维后，仍能保持该结构。比较常见的有<strong>局部线性嵌入(local linear embedding, LLE)</strong>、<strong>拉普拉斯特征映射(Laplacian eigenmaps, LE)</strong>、<strong>等距映射(Isomap)</strong> 等。</p><p><strong>SNE(stochastic neighbor embedding)</strong> 算法于2002年提出，其出发点是：在高维空间相似的数据点，映射到低维空间距离也是相似的。常规的做法是用欧式距离表示这种相似性，而SNE把这种距离关系转换为一种条件概率来表示相似性。</p><p>SNE存在拥挤问题：降维后不同类别的数据簇挤在一起，无法区分开来。为了解决该问题，t-SNE在SNE的基础上做了两点改进：(1) 把SNE变为<strong>对称SNE</strong>，(2) 在低维空间中采用了$t$分布代替原来的高斯分布，高维空间不变。</p><h1 id=使用scikit-learn中的t-sne算法完成恒星光谱数据的降维>使用scikit-learn中的t-SNE算法完成恒星光谱数据的降维</h1><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> numpy <span style=color:#ff79c6>as</span> np
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> matplotlib.pyplot <span style=color:#ff79c6>as</span> plt
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> scipy.io <span style=color:#ff79c6>as</span> sio
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> sklearn.manifold <span style=color:#ff79c6>import</span> TSNE
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 数据获取 (需要预先将数据导入当前目录下)</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># A F K M类恒星数据各1000条</span>
</span></span><span style=display:flex><span>X_a <span style=color:#ff79c6>=</span> sio<span style=color:#ff79c6>.</span>loadmat(<span style=color:#f1fa8c>&#39;spectra_data\A.mat&#39;</span>)[<span style=color:#f1fa8c>&#39;P1&#39;</span>][:<span style=color:#bd93f9>1000</span>]
</span></span><span style=display:flex><span>X_f <span style=color:#ff79c6>=</span> sio<span style=color:#ff79c6>.</span>loadmat(<span style=color:#f1fa8c>&#39;spectra_data\F.mat&#39;</span>)[<span style=color:#f1fa8c>&#39;P1&#39;</span>][:<span style=color:#bd93f9>1000</span>]
</span></span><span style=display:flex><span>X_k <span style=color:#ff79c6>=</span> sio<span style=color:#ff79c6>.</span>loadmat(<span style=color:#f1fa8c>&#39;spectra_data\K.mat&#39;</span>)[<span style=color:#f1fa8c>&#39;P1&#39;</span>][:<span style=color:#bd93f9>1000</span>]
</span></span><span style=display:flex><span>X_m <span style=color:#ff79c6>=</span> sio<span style=color:#ff79c6>.</span>loadmat(<span style=color:#f1fa8c>&#39;spectra_data\M.mat&#39;</span>)[<span style=color:#f1fa8c>&#39;P1&#39;</span>][:<span style=color:#bd93f9>1000</span>]
</span></span><span style=display:flex><span>X_label <span style=color:#ff79c6>=</span> [<span style=color:#f1fa8c>&#39;A&#39;</span>, <span style=color:#f1fa8c>&#39;F&#39;</span>, <span style=color:#f1fa8c>&#39;K&#39;</span>, <span style=color:#f1fa8c>&#39;M&#39;</span>]
</span></span><span style=display:flex><span>X <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>vstack((X_a, X_f, X_k, X_m))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 类别标签</span>
</span></span><span style=display:flex><span>y_a <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>full((X_a<span style=color:#ff79c6>.</span>shape[<span style=color:#bd93f9>0</span>],), <span style=color:#bd93f9>0</span>)
</span></span><span style=display:flex><span>y_f <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>full((X_f<span style=color:#ff79c6>.</span>shape[<span style=color:#bd93f9>0</span>],), <span style=color:#bd93f9>1</span>)
</span></span><span style=display:flex><span>y_k <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>full((X_k<span style=color:#ff79c6>.</span>shape[<span style=color:#bd93f9>0</span>],), <span style=color:#bd93f9>2</span>)
</span></span><span style=display:flex><span>y_m <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>full((X_m<span style=color:#ff79c6>.</span>shape[<span style=color:#bd93f9>0</span>],), <span style=color:#bd93f9>3</span>)
</span></span><span style=display:flex><span>y <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>hstack((y_a, y_f, y_k, y_m))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 数据归一化</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>for</span> i <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(X<span style=color:#ff79c6>.</span>shape[<span style=color:#bd93f9>0</span>]):
</span></span><span style=display:flex><span>    X[i] <span style=color:#ff79c6>-=</span> np<span style=color:#ff79c6>.</span>min(X[i])
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>if</span> np<span style=color:#ff79c6>.</span>max(X[i]) <span style=color:#ff79c6>!=</span> <span style=color:#bd93f9>0</span>:
</span></span><span style=display:flex><span>        X[i] <span style=color:#ff79c6>/=</span> np<span style=color:#ff79c6>.</span>max(X[i])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(<span style=color:#f1fa8c>&#39;Data shape: &#39;</span>, X<span style=color:#ff79c6>.</span>shape)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(<span style=color:#f1fa8c>&#39;Label shape: &#39;</span>, y<span style=color:#ff79c6>.</span>shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 降维</span>
</span></span><span style=display:flex><span>tsne <span style=color:#ff79c6>=</span> TSNE()
</span></span><span style=display:flex><span>X_tsne <span style=color:#ff79c6>=</span> tsne<span style=color:#ff79c6>.</span>fit_transform(X)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 绘制降维结果</span>
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>scatter(X_tsne[y <span style=color:#ff79c6>==</span> <span style=color:#bd93f9>0</span>, <span style=color:#bd93f9>0</span>], X_tsne[y <span style=color:#ff79c6>==</span> <span style=color:#bd93f9>0</span>, <span style=color:#bd93f9>1</span>], label<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;A&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>scatter(X_tsne[y <span style=color:#ff79c6>==</span> <span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>0</span>], X_tsne[y <span style=color:#ff79c6>==</span> <span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>1</span>], label<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;F&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>scatter(X_tsne[y <span style=color:#ff79c6>==</span> <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>0</span>], X_tsne[y <span style=color:#ff79c6>==</span> <span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>1</span>], label<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;K&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>scatter(X_tsne[y <span style=color:#ff79c6>==</span> <span style=color:#bd93f9>3</span>, <span style=color:#bd93f9>0</span>], X_tsne[y <span style=color:#ff79c6>==</span> <span style=color:#bd93f9>3</span>, <span style=color:#bd93f9>1</span>], label<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;M&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>legend()
</span></span><span style=display:flex><span>plt<span style=color:#ff79c6>.</span>show()
</span></span></code></pre></div><h1 id=参考资料>参考资料</h1><ul><li>周志华. 机器学习. 北京: 清华大学出版社, 2016.</li><li>李航. 统计学习方法. 北京: 清华大学出版社, 2019.</li><li>邱锡鹏. 神经网络与深度学习. 北京: 机械工业出版社, 2020.</li><li>鲁伟. 机器学习：公式推导与代码实现. 北京: 人民邮电出版社, 2022.</li><li>流形学习：https://www.zhihu.com/question/24015486</li><li>SNE与t-SNE：http://bindog.github.io/blog/2016/06/04/from-sne-to-tsne-to-largevis/</li></ul><hr><ul class=pager><li class=previous><a href=/post/3-ml/ml10-em%E7%AE%97%E6%B3%95/ data-toggle=tooltip data-placement=top title=机器学习：EM算法>&larr;
Previous Post</a></li><li class=next><a href=/post/3-ml/ml11-%E8%81%9A%E7%B1%BB/ data-toggle=tooltip data-placement=top title=机器学习：聚类>Next
Post &rarr;</a></li></ul><script src=https://giscus.app/client.js data-repo=XiangdiWu/XiangdiWu.github.io data-repo-id=R_kgDOP0pDUQ data-category=Announcements data-category-id=DIC_kwDOP0pDUc4CvwjG data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=light data-lang=zh-CN crossorigin=anonymous async></script></div><div class="col-lg-2 col-lg-offset-0
visible-lg-block
sidebar-container
catalog-container"><div class=side-catalog><hr class="hidden-sm hidden-xs"><h5><a class=catalog-toggle href=#>CATALOG</a></h5><ul class=catalog-body></ul></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/deep-learning title="deep learning">deep learning
</a><a href=/tags/machine-learning title="machine learning">machine learning
</a><a href=/tags/math title=math>math
</a><a href=/tags/model title=model>model
</a><a href=/tags/nlp title=nlp>nlp
</a><a href=/tags/quant title=quant>quant</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href=https://www.factorwar.com/data/factor-models/>GetAstockFactors</a></li><li><a target=_blank href=https://datawhalechina.github.io/whale-quant/#/>Whale-Quant</a></li></ul></section></div></div></div></article><script type=module>  
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs'; 
    mermaid.initialize({ startOnLoad: true });  
</script><script>Array.from(document.getElementsByClassName("language-mermaid")).forEach(e=>{e.parentElement.outerHTML=`<div class="mermaid">${e.innerHTML}</div>`})</script><style>.mermaid svg{display:block;margin:auto}</style><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href=mailto:bernicewu2000@outlook.com><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/img/wechat_qrcode.jpg><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-weixin fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/xiangdiwu><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a href rel=alternate type=application/rss+xml title="Xiangdi Blog"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; Xiangdi Blog 2025</p></div></div></div></footer><script>function loadAsync(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(null,e)},!1),i.parentNode.insertBefore(n,i)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,a=$(_containerSelector),r=a.find("h1,h2,h3,h4,h5,h6");return $(e).html(""),r.each(function(){n=$(this).prop("tagName").toLowerCase(),o="#"+$(this).prop("id"),t=$(this).text(),i=$('<a href="'+o+'" rel="nofollow" title="'+t+'">'+t+"</a>"),s=$('<li class="'+n+'_nav"></li>').append(i),$(e).append(s)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script><style>.markmap>svg{width:100%;height:300px}</style><script>window.markmap={autoLoader:{manual:!0,onReady(){const{autoLoader:e,builtInPlugins:t}=window.markmap;e.transformPlugins=t.filter(e=>e.name!=="prism")}}}</script><script src=https://cdn.jsdelivr.net/npm/markmap-autoloader></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css integrity="sha512-r2+FkHzf1u0+SQbZOoIz2RxWOIWfdEzRuYybGjzKq18jG9zaSfEy9s3+jMqG/zPtRor/q4qaUCYQpmSjTw8M+g==" crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js integrity="sha512-INps9zQ2GUEMCQD7xiZQbGUVnqnzEvlynVy6eqcTcHN4+aQiLo9/uaQqckDpdJ8Zm3M0QBs+Pktg4pz0kEklUg==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/mhchem.min.js integrity="sha512-mxjNw/u1lIsFC09k/unscDRY3ofIYPVFbWkP8slrePcS36ht4d/OZ8rRu5yddB2uiqajhTcLD8+jupOWuYPebg==" crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js integrity="sha512-YJVxTjqttjsU3cSvaTRqsSl0wbRgZUNF+NGGCgto/MUbIvaLdXQzGTCQu4CvyJZbZctgflVB0PXw9LLmTWm5/w==" crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"},{display:!0,left:"\\[",right:"\\]"}],errorcolor:"#CD5C5C",throwonerror:!1})'></script></body></html>