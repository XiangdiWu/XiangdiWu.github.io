<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>NLP on Xiangdi Blog</title><link>https://xiangdiwu.github.io/tags/nlp/</link><description>Recent content in NLP on Xiangdi Blog</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 25 Oct 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://xiangdiwu.github.io/tags/nlp/index.xml" rel="self" type="application/rss+xml"/><item><title>自然语言处理：自然语言处理应用</title><link>https://xiangdiwu.github.io/post/5-nlp/nlp6-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%BA%94%E7%94%A8/</link><pubDate>Sun, 25 Oct 2020 00:00:00 +0000</pubDate><guid>https://xiangdiwu.github.io/post/5-nlp/nlp6-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%BA%94%E7%94%A8/</guid><description>&lt;p&gt;自然语言处理的应用（即NLP任务）分布非常广泛。本章节以任务的形式进行划分，主要介绍三类具有代表性的自然语言处理应用，包括文本分类（序列-编码-类别）、文本摘要（序列-编码-解码-序列）、以及机器阅读理解（序列-编码-同步序列）。每个部分首先介绍了应用的概念及挑战，然后介绍了一些具有代表性的论文工作。&lt;strong&gt;注意，从接触一个领域的具体任务开始，已经初步进入到了对该科研领域的探索之中。每个领域都有一些具体的任务，而确定一个任务往往就是着手开展一项研究工作的第一步。&lt;/strong&gt;&lt;/p&gt;</description></item><item><title>自然语言处理：预训练模型</title><link>https://xiangdiwu.github.io/post/5-nlp/nlp5-%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/</link><pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate><guid>https://xiangdiwu.github.io/post/5-nlp/nlp5-%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/</guid><description>&lt;h1 id="elmo"&gt;ELMo&lt;/h1&gt;
&lt;p&gt;预训练词向量(如word2vec和GloVe等)通常只能为一个单词产生一个特定的词向量，而忽略了该单词的&lt;strong&gt;上下文(context)&lt;/strong&gt; 关系，因而无法解决&lt;strong&gt;一词多义&lt;/strong&gt;或&lt;strong&gt;一义多词&lt;/strong&gt;的问题。&lt;strong&gt;ELMo(embeddings from language models)&lt;/strong&gt; 本质上是一个深度双向LSTM模型，用于为一个句子中的每个单词生成上下文相关的词向量。将这些上下文相关词向量编码了单词的深层次语义和句法信息，因此当ELMo应用到许多NLP任务中，这些任务的效果相对于使用静态的词向量往往能得到很大的提升。&lt;/p&gt;</description></item><item><title>自然语言处理：“序列到序列”与“注意力机制”</title><link>https://xiangdiwu.github.io/post/5-nlp/nlp4-seq2seq%E4%B8%8Eattention/</link><pubDate>Fri, 23 Oct 2020 00:00:00 +0000</pubDate><guid>https://xiangdiwu.github.io/post/5-nlp/nlp4-seq2seq%E4%B8%8Eattention/</guid><description>&lt;h1 id="序列到序列模型"&gt;序列到序列模型&lt;/h1&gt;
&lt;p&gt;许多单输出问题得以解决，比如命名实体识别、单词预测等。然而许多任务的输出是一个&lt;strong&gt;序列&lt;/strong&gt;，比如机器翻译、对话系统以及自动摘要等。这种问题应当使用seq2seq实现。&lt;/p&gt;</description></item><item><title>自然语言处理：语言模型</title><link>https://xiangdiwu.github.io/post/5-nlp/nlp3-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</link><pubDate>Thu, 22 Oct 2020 00:00:00 +0000</pubDate><guid>https://xiangdiwu.github.io/post/5-nlp/nlp3-%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</guid><description>&lt;h1 id="n元语法"&gt;N元语法&lt;/h1&gt;
&lt;p&gt;N元语言模型可以用来&lt;strong&gt;预测一个句子的下一个单词的概率&lt;/strong&gt;，或者&lt;strong&gt;计算一个句子的概率&lt;/strong&gt;。该模型常用于语音识别、拼写检查以及语法检查等领域。&lt;/p&gt;
&lt;p&gt;首先，&lt;strong&gt;一个句子“its water is so transparent that”后出现某一单词“the”的概率&lt;/strong&gt;为：&lt;/p&gt;</description></item><item><title>自然语言处理：词向量</title><link>https://xiangdiwu.github.io/post/5-nlp/nlp2-%E8%AF%8D%E5%90%91%E9%87%8F/</link><pubDate>Wed, 21 Oct 2020 00:00:00 +0000</pubDate><guid>https://xiangdiwu.github.io/post/5-nlp/nlp2-%E8%AF%8D%E5%90%91%E9%87%8F/</guid><description>&lt;h1 id="词向量概述"&gt;词向量概述&lt;/h1&gt;
&lt;p&gt;在自然语言处理领域，词的&lt;strong&gt;表示(representation)&lt;/strong&gt; 是一个核心问题。我们希望将单词通过某种嵌入的形式表示，以捕获词的&lt;strong&gt;含义(meaning)&lt;strong&gt;以及词和词之间的&lt;/strong&gt;关系(relationship)&lt;/strong&gt;。一个解决方法是，使用wordnet(a thesaurus containing lists of &lt;strong&gt;synonym sets&lt;/strong&gt; and &lt;strong&gt;hypernyms&lt;/strong&gt;)，如下所示：&lt;/p&gt;</description></item><item><title>自然语言处理概述</title><link>https://xiangdiwu.github.io/post/5-nlp/nlp1-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A6%82%E8%BF%B0/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://xiangdiwu.github.io/post/5-nlp/nlp1-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A6%82%E8%BF%B0/</guid><description>&lt;h1 id="自然语言与编程语言"&gt;自然语言与编程语言&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;自然语言处理(natural language processing, NLP)&lt;/strong&gt; 是一门融合了计算机科学、人工智能以及语言学的交叉学科(interdisciplinary field)。这门学科研究的是如何通过机器学习等技术，让计算机学会处理人类语言，乃至实现最终目标：&lt;strong&gt;理解人类语言或人工智能&lt;/strong&gt;。&lt;/p&gt;</description></item></channel></rss>